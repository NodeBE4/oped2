<!DOCTYPE html>
<html>
  <head>
  <title>生存或者毁灭：超级人工智能将给人类带来什么？ – 觀點2 – 高頻版 git.io/JUJZT</title>

      <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="
  
    
    
       生存或者毁灭：超级人工智能将给人类带来什么？ 
    
  
  
    
    
    结果表明，通用强化学习算法能够从一块白板出发，学会任何事物。AI 不需要依靠知识，也不需要来自人类的特定经验
       
      
 
      
    
    人工智能领域的科学家已经取得了一项惊人的成就。戴维·希尔弗 (David Silver) 是 DeepMind 团队的负责人，他和团队共同研发的  AlphaZero 从掌握初步规则开始，通过自己与自己对战，独立学会了国际象棋、围棋和将棋 (日本棋类游戏)。对于这三种棋类游戏，AlphaZero 已经超过了最好的人类棋手  。
    这一进步非常了不起。  1997 年，计算机深蓝 (Deep Blue) 打败了国际象棋世界冠军加里·卡斯帕罗夫 (Gary Kasparov)  ，它结合了优秀的算法与对棋局的出色理解。最好的人类棋手也贡献了关于开局、残局和局面评估的专业知识，从某种意义上来说，是人类将这些知识「教」给了程序。
     而 AlphaZero 不同，不需要由人类专家向它传授自己掌握的知识。对于这样的棋类游戏，AI 可以独立学习，快速达到人类需要几个世纪才能累积的高度。AlphaZero 的研发人员表示：「无论对于国际象棋、将棋还是围棋， AlphaZero 使用的都是同样的算法，同样的网络结构。结果表明，通用强化学习算法 (即能够胜出的决策将被算法优先选择) 能够从一块白板出发，学会任何事物。它不需要依靠知识，也不需要来自人类的特定经验。」 
    随着人工智能快速发展，这个领域也开始面临越来越迫切的问题。研究人员、哲学家还有技术预言家纷纷开始辩论，设想未来可能出现的种种矛盾。  无论是感到期待还是恐慌，没有人会怀疑人工智能将主导我们的未来。这种主导作用也许是通过互联网，也许是与人类融合。 
    许多思想家都曾经深入思考过超级人工智能 (以及它对人类的态度)，试图以此预测未来的趋势。我们将探讨尼克·博斯特罗姆 (Nick Bostrom)、雷·库兹韦尔 (Ray Kurzweil)、本 (Ben) 和泰德·戈尔泽尔父子 (Ted Goertzel)、汉斯·莫拉维克 (Hans Moravec)、弗朗西斯·海利根 (Francis Heylighen)、雨果·德·加里斯 (Hugode Garis) 和克莱蒙·维达尔 (Clement Vidal) 的思考。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
           评论的风口浪尖 

     当我们还不了解一件事物时，往往会作出夸张的设想，讨论它的性质时也会出现两极分化的观点。但是，正如剧作家拉辛 (Racine) 借他笔下人物所说，AI 无法承担我们过分施加的荣耀，也不至于因为它引发的忧虑而遭受羞辱。 
    尽管我们对 AI 取得的成就感到震惊，也意识到它可能会造成巨大的影响，但不能被狂热冲昏头脑。  AI 在许多高度专业化的任务中都取得了惊人的成绩，但它仍然难以胜任所有需要常识的任务，例如翻译文学作品。  自动驾驶也被寄予厚望，但是专家仍然保持谨慎，认为我们至少需要 50 年的时间，才可能制造出完全自主驾驶的汽车，让乘客能够安心在后排看书。
    在我撰写的专栏中，曾经提到过一些能够欺骗图片识别软件 (基于深度神经网络的算法) 的方法。比如，所有人都能一眼看出这是一门大炮的照片，算法却把它识别成了鸵鸟。
    虽然人工智能已经在越来越多的专业任务中取得了令人瞩目的成就，但它却面临两方面的障碍。首先，对于同样的任务，AI 获得结果的方式与人类的方式完全不同，它借助技术设备和计算，不需要人类介入。例如，部分自动驾驶汽车上装配的雷达和激光，它们计算和存储海量信息的能力远远超过人脑；另一方面，尽管取得了这样的成就，  AI 仍然无法将多种专业能力结合起来，形成一个自洽的、具备常识的系统  。我们无法合理地推测它们是否具备自我意识，拥有感知能力、幽默感，甚至是完备而稳定的「人格」。
           总是失误的预测 

    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    1958 年，赫伯特·西蒙 (Herbert Simon，1978 年诺贝尔经济学奖得主) 宣称，在未来 10 年中，计算机将在国际象棋中打败人类冠军。他正确预言了我们将取得的成就，却弄错了等待的时间——他的预言过了 40 年才实现。
    1966 年，英国著名统计学家欧文·古德 (Irving Good) 为斯坦利·库布里克 (Stanley Kubrick) 的电影《2001 太空漫游》担任顾问，他设想在 2000 年将出现一个强大的人工智能，达到甚至超越人类的智力水平。现在的人工智能还没有达到这个水平，期待强大人工智能的人们只好推迟这个期限。谷歌工程技术总监库兹韦尔和奇点大学 (位于美国加州的一所私立学校) 联合创始人及董事长彼得·戴曼迪斯 (Peter Diamandis) 认为这个期限是 2030 年，而 AI 研究者泰德·戈尔泽尔和本·戈尔泽尔则认为要等到 2040 年，甚至 2100 年。
    这很可能会像国际象棋 AI 的发展一样：我们实现了目标，只是晚得多。因为这个问题非常困难，我们只有经过年复一年的努力才会实现这一点。如今，最合理的预测也许是不要作出任何预测！
     对于必将到来的超级人工智能，人们提出了一个叫做「奇点」的概念，尽管谁也无法真正了解它究竟是什么。也许是某个日期，到时候地球上人工智能的能力曲线将以接近垂直的方式增长？也许是某个事件，机器毁灭人类，夺取了权力？也许是某一时刻，由于超越人类的人工智能带来了翻天覆地的变化，人类再也无法理解这个世界？ 
    即便考虑著名的「摩尔定律」(计算设备的能力每 18 个月到 2 年就会翻倍，过去 50 年的发展基本符合这一定律)，「奇点」理论也不会很快成为严重的威胁。一方面，摩尔定律预测的增长是一个指数函数，它不会趋于直线；另一方面，在我们的物理世界中，所有的指数增长都会很快遇到阻碍，进而停滞不前。没有人认为摩尔定律会无限延续下去 (它已经遇到了困难)。最后，尽管计算和存储能力持续增长，也无法确保我们始终知道如何使用这些能力，创造出足以和我们对抗的通用型人工智能。
    对于谷歌、苹果、脸书、亚马逊和微软在这方面发出的宣言，我们应该审慎地看待。和这些技术公司的发言人相比，一些研究人员的态度要谨慎和清醒得多，例如法国国家科学研究中心 (CNRS) 伦理委员会主席、人工智能专家让-加布里埃尓·加纳西亚 (Jean-Gabriel Ganascia)。加纳西亚认为，那些人想要发起一个由企业主导、超越国界的大型项目，可能只是出于无尽的贪欲。奇点的概念被用来转移注意力、制造恐慌，但实际上这主要是为了劝阻其他人，并掩饰自己想要占据统治地位的野心。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    尽管无法确切地知道超级人工智能出现时是什么情形，但也无法阻止我们深入探讨、投下赌注。我们可以想象多个不同的场景，不设定具体期限，甚至考虑任何猜想都不正确。
    尼克·博斯特罗姆在他的书中定义了超级人工智能，并设定这种智能在任何一个方面都大大超过人类的认知能力。他还提出了两个截然不同的假设。
    (a) 基于硅的机器 (包括量子计算机) 进入实用领域并不断发展，最终这些人造设备在一切可能的智力活动中达到甚至超过人类水平，就像 AlphaZero 一样。而我们与它们的功能没有发生直接联系，也没有在肢体上与人工智能设备融合或相连接。
    (b) 基于生物性元素 (人类或其他的) 与信息技术设备结合的产物。简单地说，就是人类发明的高级技术与生物体有机地结合在了一起，他们之间是相互融合的。这种形式也有可能发展出超级人工智能。
           势力分化？ 

    研究人工智能的加里斯则将满足假设 (a) 的智慧生物称为「人工大脑」，并设想了一种基于这类技术的未来，我们将在下一部分讨论这种场景。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    而长久以来，科幻作品都采用了假设 (b)，并将这类结合了生物和信息技术，具备超级智能的混合体称为赛博格 (cyborgs，或改造人)。例如，假设为了弥补记忆局限，我们给自己插入容量高达到数太字节 (TB) 的芯片，从而能够直接在大脑中读取整部维基百科的信息。与此同时，借助一种能够通过可以瞬间读取的数学计算模块，我们能立刻回答「720 等于几」或「sin(cos(x)) 的五阶导数是什么」之类的问题。我们的智力将大幅提升。
    有时也会提到第三个假设：一台全球化的大脑，各地的机器通过网络交换信息，构成了某种去中心化、具有思想的存在。我们稍后再回到这个假设。
           悲观的加里斯 

    加里斯认为：「社会将会分成三个哲学派别，派别之间将发生激烈的斗争。第一个派别由宇宙主义者构成，他们支持建造人工大脑；第二派别由地球主义者构成，他们反对建造人工大脑；而第三派别则支持赛博格，他们希望对大脑进行改造，从而把自己变成赛博格。」
    加里斯的著作《人工大脑之战》(The Artilect War) 介于科幻小说和严肃的未来学著作之间。在这部作品中，他认为三个派别之间的战争不可避免，并且在他看来，这场战争将比地球上发生过的任何战争都更惨烈，将在 21 世纪造成超过十亿人死亡。地球主义者在这场战争中获胜的希望非常渺茫，如果他们要取得胜利，就必须赶在另外两个可能结盟的派别察觉到威胁之前采取行动。在接受探索频道的访谈时，加里斯就曾表达过他的忧虑：「我很高兴能活在这个时代，我很有可能会平静地躺在自己的床上死去。但是我为我的孙辈感到担忧，他们可能被卷入人工大脑的战争，并且很可能因此丧命。」
    有趣的是，尽管超人类主义者在法国不受待见，加里斯也在书中对他们表达了谴责或嘲笑，但他们却非常乐观地捍卫自己的主张。超人类主义者认为应当毫无保留地发展增强技术，对人类进行改造——不能止步于眼镜、助听器和心脏起搏器，而是要采用一切可能的技术延长寿命、提升智力和强化身体机能。简而言之，他们支持赛博格的思想，属于赛博格主义者的阵营。他们将和宇宙主义者结盟，避免被地球主义者消灭。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    至于赛博格主义者和宇宙主义者之间会发生什么，超人类主义者和加里斯发生了分歧。大多数超人类主义者认为，人类赛博格将与具备超级智能的机械设备共存，不会发生生物学上的结合；而超人类主义者相信，将生物性元素 (特指他们自己) 和电子技术元素深度结合能够增强人类获得长生不死的能力，这才是人类未来的关键。
    加里斯的设想恰好相反：和人工大脑可能取得的成就相比，超人类主义简直无足轻重。在他看来，将生命体和未来的信息技术相融合只是一种幻想：人工大脑将对改造人这样的怪物不屑一顾，它只会毁灭改造人。
    而作为世界超人类主义者协会 (World Transhumanist Association) 联合创始人，博斯特罗姆也不认为人工大脑会对人类 (人工大脑的创造者，最终会成为赛博格) 采取和平友善的态度。他催促人们审视未来的智能产物，将它们视为一种威胁。博斯特罗姆的作品得到了埃隆·马斯克 (Elon Musk)、比尔·盖茨 (Bill Gates) 和李彦宏的推崇，这种看法似乎打动了他们，使他们开始传播恐慌信息 (也就是所谓的人工智能威胁论)。
    在加里斯看来，人工大脑 (具备意识的人工智能，或极其智能的机器) 不会友好地容忍人类甚至赛博格的存在，他说：「这个想法就像是尾巴摇狗一样，显然很荒谬。狗可比它的尾巴大得多，尾巴根本无法摇动狗。但超人类主义者认为人工大脑会和人类保持友好，这就犯了同样的逻辑错误……我认为这种观念是狂妄而天真的。它假设人类足够智能，即便面对一个能力超出人类几十亿倍的个体，也能正确判断它的动机。」
           其他可能 

    加里斯忽略了另一种思潮：世界上所有的个体并不一定要互相竞争，而是相互连接，成为一种全球尺度的超级有机体。这种观点直接排除了「终结者之战」的可能。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    这种全球大融合的观点常常被认为是宗教性的。它存在于佛教的哲学中，也出现在天主教耶稣会哲学家德日进 (Pierre Teilhard de Chardin，1881–1955) 的思想中。德日进提出了「智慧圈」，这种「一体性的思想由人类的交流形成，覆盖了地球表面」。
    比利时哲学家弗朗西斯·海利根坚定地认为：超级人工智能将通过互联网传播，形成一个类似超级大脑的存在。他指出：「这个全球化的大脑将克服全球性超级有机体可能遭遇的挑战。它的能力将远远超过我们现有的水平，将具备某些神性的特质：无所不知 (知道我们的一切问题的答案)、无处不在 (存在于任何时间和地点)、无所不能 (能够以最高效的方式生产任何物品或服务)、博爱众生 (致力于为最多的人带来最大的幸福)。」
    比利时布鲁塞尔自由大学的哲学家克莱蒙·维达尔研究宇宙主义，他引用了威廉·斯塔福德 (William Stafford) 的诗句「所有的战争都有两个失败者」，指出暴力往往是非理性的。而斯蒂芬·平克 (Steven Pinker) 详细论述了世界会越来越和平，尽管我们觉得这个过程过于漫长，但它仍然是可被测量和解释的。一方面，无论我们是否愿意，所有人对所有人的相互依赖都使我们彼此产生联系。博弈论和对囚徒困境模型计算模拟的结果都支持这样的分析。这表明，合作才是多个社会和政治团体理性的选择。
           殊途同归 

    「复杂性的伦理」是最后一个论据，可以证明「地球上不同动机的群体最终会结成一个利益共同体」的想法并不荒谬。如果按照这个伦理的预测，所有的智慧生物都会选择为一个普世价值共同体服务，将向着共同的目标行动，不再有发动战争的动机。
    尽管不同的讨论显示可能存在某种共同的方向，但这并不能保证当超级人工智能出现时 (如果它们会出现的话)，将与我们这些或多或少变成赛博格的人类和平结盟，并且在这个过程中没有任何一方试图消灭其他群体。在我看来，我们或许可以坚持一种极其简单的信念：并不是地球上生物性的躯体才具有人性，他们生产和制造的一切事物也应该有，甚至让这些事物得以存在的一切也有。地球在未来演化出的超级集合体会更加智能，内部之间的联系也越来越团结和紧密，尤其是在地球上刚刚出现的几个不同派别之间。这种讨论会永久避免加里斯设想的内部战争，因为战争变成了某种形式的自残甚至自杀行为。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    到这里我们已经超出了科幻小说的范畴。目前看来，我们要小心避免抨击任何对这个问题的思考，不要断言它们是愚蠢和不成熟的。AlphaZero 已经证明，我们能够借助机器取得不可思议的成就：人工智能再也不是一个遥远的梦。另一方面，物联网的快速发展将把全世界所有的参与者联系起来，构成一个致密的茧。毫无疑问，它将形成一个全新的结构，所有的事物都依赖于所有的因素。而我们就像我们的人工智能一样，不过是其中的组成部分。
    
      
             
              
            
 
      
    
  

" />
    <meta property="og:description" content="
  
    
    
       生存或者毁灭：超级人工智能将给人类带来什么？ 
    
  
  
    
    
    结果表明，通用强化学习算法能够从一块白板出发，学会任何事物。AI 不需要依靠知识，也不需要来自人类的特定经验
       
      
 
      
    
    人工智能领域的科学家已经取得了一项惊人的成就。戴维·希尔弗 (David Silver) 是 DeepMind 团队的负责人，他和团队共同研发的  AlphaZero 从掌握初步规则开始，通过自己与自己对战，独立学会了国际象棋、围棋和将棋 (日本棋类游戏)。对于这三种棋类游戏，AlphaZero 已经超过了最好的人类棋手  。
    这一进步非常了不起。  1997 年，计算机深蓝 (Deep Blue) 打败了国际象棋世界冠军加里·卡斯帕罗夫 (Gary Kasparov)  ，它结合了优秀的算法与对棋局的出色理解。最好的人类棋手也贡献了关于开局、残局和局面评估的专业知识，从某种意义上来说，是人类将这些知识「教」给了程序。
     而 AlphaZero 不同，不需要由人类专家向它传授自己掌握的知识。对于这样的棋类游戏，AI 可以独立学习，快速达到人类需要几个世纪才能累积的高度。AlphaZero 的研发人员表示：「无论对于国际象棋、将棋还是围棋， AlphaZero 使用的都是同样的算法，同样的网络结构。结果表明，通用强化学习算法 (即能够胜出的决策将被算法优先选择) 能够从一块白板出发，学会任何事物。它不需要依靠知识，也不需要来自人类的特定经验。」 
    随着人工智能快速发展，这个领域也开始面临越来越迫切的问题。研究人员、哲学家还有技术预言家纷纷开始辩论，设想未来可能出现的种种矛盾。  无论是感到期待还是恐慌，没有人会怀疑人工智能将主导我们的未来。这种主导作用也许是通过互联网，也许是与人类融合。 
    许多思想家都曾经深入思考过超级人工智能 (以及它对人类的态度)，试图以此预测未来的趋势。我们将探讨尼克·博斯特罗姆 (Nick Bostrom)、雷·库兹韦尔 (Ray Kurzweil)、本 (Ben) 和泰德·戈尔泽尔父子 (Ted Goertzel)、汉斯·莫拉维克 (Hans Moravec)、弗朗西斯·海利根 (Francis Heylighen)、雨果·德·加里斯 (Hugode Garis) 和克莱蒙·维达尔 (Clement Vidal) 的思考。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
           评论的风口浪尖 

     当我们还不了解一件事物时，往往会作出夸张的设想，讨论它的性质时也会出现两极分化的观点。但是，正如剧作家拉辛 (Racine) 借他笔下人物所说，AI 无法承担我们过分施加的荣耀，也不至于因为它引发的忧虑而遭受羞辱。 
    尽管我们对 AI 取得的成就感到震惊，也意识到它可能会造成巨大的影响，但不能被狂热冲昏头脑。  AI 在许多高度专业化的任务中都取得了惊人的成绩，但它仍然难以胜任所有需要常识的任务，例如翻译文学作品。  自动驾驶也被寄予厚望，但是专家仍然保持谨慎，认为我们至少需要 50 年的时间，才可能制造出完全自主驾驶的汽车，让乘客能够安心在后排看书。
    在我撰写的专栏中，曾经提到过一些能够欺骗图片识别软件 (基于深度神经网络的算法) 的方法。比如，所有人都能一眼看出这是一门大炮的照片，算法却把它识别成了鸵鸟。
    虽然人工智能已经在越来越多的专业任务中取得了令人瞩目的成就，但它却面临两方面的障碍。首先，对于同样的任务，AI 获得结果的方式与人类的方式完全不同，它借助技术设备和计算，不需要人类介入。例如，部分自动驾驶汽车上装配的雷达和激光，它们计算和存储海量信息的能力远远超过人脑；另一方面，尽管取得了这样的成就，  AI 仍然无法将多种专业能力结合起来，形成一个自洽的、具备常识的系统  。我们无法合理地推测它们是否具备自我意识，拥有感知能力、幽默感，甚至是完备而稳定的「人格」。
           总是失误的预测 

    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    1958 年，赫伯特·西蒙 (Herbert Simon，1978 年诺贝尔经济学奖得主) 宣称，在未来 10 年中，计算机将在国际象棋中打败人类冠军。他正确预言了我们将取得的成就，却弄错了等待的时间——他的预言过了 40 年才实现。
    1966 年，英国著名统计学家欧文·古德 (Irving Good) 为斯坦利·库布里克 (Stanley Kubrick) 的电影《2001 太空漫游》担任顾问，他设想在 2000 年将出现一个强大的人工智能，达到甚至超越人类的智力水平。现在的人工智能还没有达到这个水平，期待强大人工智能的人们只好推迟这个期限。谷歌工程技术总监库兹韦尔和奇点大学 (位于美国加州的一所私立学校) 联合创始人及董事长彼得·戴曼迪斯 (Peter Diamandis) 认为这个期限是 2030 年，而 AI 研究者泰德·戈尔泽尔和本·戈尔泽尔则认为要等到 2040 年，甚至 2100 年。
    这很可能会像国际象棋 AI 的发展一样：我们实现了目标，只是晚得多。因为这个问题非常困难，我们只有经过年复一年的努力才会实现这一点。如今，最合理的预测也许是不要作出任何预测！
     对于必将到来的超级人工智能，人们提出了一个叫做「奇点」的概念，尽管谁也无法真正了解它究竟是什么。也许是某个日期，到时候地球上人工智能的能力曲线将以接近垂直的方式增长？也许是某个事件，机器毁灭人类，夺取了权力？也许是某一时刻，由于超越人类的人工智能带来了翻天覆地的变化，人类再也无法理解这个世界？ 
    即便考虑著名的「摩尔定律」(计算设备的能力每 18 个月到 2 年就会翻倍，过去 50 年的发展基本符合这一定律)，「奇点」理论也不会很快成为严重的威胁。一方面，摩尔定律预测的增长是一个指数函数，它不会趋于直线；另一方面，在我们的物理世界中，所有的指数增长都会很快遇到阻碍，进而停滞不前。没有人认为摩尔定律会无限延续下去 (它已经遇到了困难)。最后，尽管计算和存储能力持续增长，也无法确保我们始终知道如何使用这些能力，创造出足以和我们对抗的通用型人工智能。
    对于谷歌、苹果、脸书、亚马逊和微软在这方面发出的宣言，我们应该审慎地看待。和这些技术公司的发言人相比，一些研究人员的态度要谨慎和清醒得多，例如法国国家科学研究中心 (CNRS) 伦理委员会主席、人工智能专家让-加布里埃尓·加纳西亚 (Jean-Gabriel Ganascia)。加纳西亚认为，那些人想要发起一个由企业主导、超越国界的大型项目，可能只是出于无尽的贪欲。奇点的概念被用来转移注意力、制造恐慌，但实际上这主要是为了劝阻其他人，并掩饰自己想要占据统治地位的野心。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    尽管无法确切地知道超级人工智能出现时是什么情形，但也无法阻止我们深入探讨、投下赌注。我们可以想象多个不同的场景，不设定具体期限，甚至考虑任何猜想都不正确。
    尼克·博斯特罗姆在他的书中定义了超级人工智能，并设定这种智能在任何一个方面都大大超过人类的认知能力。他还提出了两个截然不同的假设。
    (a) 基于硅的机器 (包括量子计算机) 进入实用领域并不断发展，最终这些人造设备在一切可能的智力活动中达到甚至超过人类水平，就像 AlphaZero 一样。而我们与它们的功能没有发生直接联系，也没有在肢体上与人工智能设备融合或相连接。
    (b) 基于生物性元素 (人类或其他的) 与信息技术设备结合的产物。简单地说，就是人类发明的高级技术与生物体有机地结合在了一起，他们之间是相互融合的。这种形式也有可能发展出超级人工智能。
           势力分化？ 

    研究人工智能的加里斯则将满足假设 (a) 的智慧生物称为「人工大脑」，并设想了一种基于这类技术的未来，我们将在下一部分讨论这种场景。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    而长久以来，科幻作品都采用了假设 (b)，并将这类结合了生物和信息技术，具备超级智能的混合体称为赛博格 (cyborgs，或改造人)。例如，假设为了弥补记忆局限，我们给自己插入容量高达到数太字节 (TB) 的芯片，从而能够直接在大脑中读取整部维基百科的信息。与此同时，借助一种能够通过可以瞬间读取的数学计算模块，我们能立刻回答「720 等于几」或「sin(cos(x)) 的五阶导数是什么」之类的问题。我们的智力将大幅提升。
    有时也会提到第三个假设：一台全球化的大脑，各地的机器通过网络交换信息，构成了某种去中心化、具有思想的存在。我们稍后再回到这个假设。
           悲观的加里斯 

    加里斯认为：「社会将会分成三个哲学派别，派别之间将发生激烈的斗争。第一个派别由宇宙主义者构成，他们支持建造人工大脑；第二派别由地球主义者构成，他们反对建造人工大脑；而第三派别则支持赛博格，他们希望对大脑进行改造，从而把自己变成赛博格。」
    加里斯的著作《人工大脑之战》(The Artilect War) 介于科幻小说和严肃的未来学著作之间。在这部作品中，他认为三个派别之间的战争不可避免，并且在他看来，这场战争将比地球上发生过的任何战争都更惨烈，将在 21 世纪造成超过十亿人死亡。地球主义者在这场战争中获胜的希望非常渺茫，如果他们要取得胜利，就必须赶在另外两个可能结盟的派别察觉到威胁之前采取行动。在接受探索频道的访谈时，加里斯就曾表达过他的忧虑：「我很高兴能活在这个时代，我很有可能会平静地躺在自己的床上死去。但是我为我的孙辈感到担忧，他们可能被卷入人工大脑的战争，并且很可能因此丧命。」
    有趣的是，尽管超人类主义者在法国不受待见，加里斯也在书中对他们表达了谴责或嘲笑，但他们却非常乐观地捍卫自己的主张。超人类主义者认为应当毫无保留地发展增强技术，对人类进行改造——不能止步于眼镜、助听器和心脏起搏器，而是要采用一切可能的技术延长寿命、提升智力和强化身体机能。简而言之，他们支持赛博格的思想，属于赛博格主义者的阵营。他们将和宇宙主义者结盟，避免被地球主义者消灭。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    至于赛博格主义者和宇宙主义者之间会发生什么，超人类主义者和加里斯发生了分歧。大多数超人类主义者认为，人类赛博格将与具备超级智能的机械设备共存，不会发生生物学上的结合；而超人类主义者相信，将生物性元素 (特指他们自己) 和电子技术元素深度结合能够增强人类获得长生不死的能力，这才是人类未来的关键。
    加里斯的设想恰好相反：和人工大脑可能取得的成就相比，超人类主义简直无足轻重。在他看来，将生命体和未来的信息技术相融合只是一种幻想：人工大脑将对改造人这样的怪物不屑一顾，它只会毁灭改造人。
    而作为世界超人类主义者协会 (World Transhumanist Association) 联合创始人，博斯特罗姆也不认为人工大脑会对人类 (人工大脑的创造者，最终会成为赛博格) 采取和平友善的态度。他催促人们审视未来的智能产物，将它们视为一种威胁。博斯特罗姆的作品得到了埃隆·马斯克 (Elon Musk)、比尔·盖茨 (Bill Gates) 和李彦宏的推崇，这种看法似乎打动了他们，使他们开始传播恐慌信息 (也就是所谓的人工智能威胁论)。
    在加里斯看来，人工大脑 (具备意识的人工智能，或极其智能的机器) 不会友好地容忍人类甚至赛博格的存在，他说：「这个想法就像是尾巴摇狗一样，显然很荒谬。狗可比它的尾巴大得多，尾巴根本无法摇动狗。但超人类主义者认为人工大脑会和人类保持友好，这就犯了同样的逻辑错误……我认为这种观念是狂妄而天真的。它假设人类足够智能，即便面对一个能力超出人类几十亿倍的个体，也能正确判断它的动机。」
           其他可能 

    加里斯忽略了另一种思潮：世界上所有的个体并不一定要互相竞争，而是相互连接，成为一种全球尺度的超级有机体。这种观点直接排除了「终结者之战」的可能。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    这种全球大融合的观点常常被认为是宗教性的。它存在于佛教的哲学中，也出现在天主教耶稣会哲学家德日进 (Pierre Teilhard de Chardin，1881–1955) 的思想中。德日进提出了「智慧圈」，这种「一体性的思想由人类的交流形成，覆盖了地球表面」。
    比利时哲学家弗朗西斯·海利根坚定地认为：超级人工智能将通过互联网传播，形成一个类似超级大脑的存在。他指出：「这个全球化的大脑将克服全球性超级有机体可能遭遇的挑战。它的能力将远远超过我们现有的水平，将具备某些神性的特质：无所不知 (知道我们的一切问题的答案)、无处不在 (存在于任何时间和地点)、无所不能 (能够以最高效的方式生产任何物品或服务)、博爱众生 (致力于为最多的人带来最大的幸福)。」
    比利时布鲁塞尔自由大学的哲学家克莱蒙·维达尔研究宇宙主义，他引用了威廉·斯塔福德 (William Stafford) 的诗句「所有的战争都有两个失败者」，指出暴力往往是非理性的。而斯蒂芬·平克 (Steven Pinker) 详细论述了世界会越来越和平，尽管我们觉得这个过程过于漫长，但它仍然是可被测量和解释的。一方面，无论我们是否愿意，所有人对所有人的相互依赖都使我们彼此产生联系。博弈论和对囚徒困境模型计算模拟的结果都支持这样的分析。这表明，合作才是多个社会和政治团体理性的选择。
           殊途同归 

    「复杂性的伦理」是最后一个论据，可以证明「地球上不同动机的群体最终会结成一个利益共同体」的想法并不荒谬。如果按照这个伦理的预测，所有的智慧生物都会选择为一个普世价值共同体服务，将向着共同的目标行动，不再有发动战争的动机。
    尽管不同的讨论显示可能存在某种共同的方向，但这并不能保证当超级人工智能出现时 (如果它们会出现的话)，将与我们这些或多或少变成赛博格的人类和平结盟，并且在这个过程中没有任何一方试图消灭其他群体。在我看来，我们或许可以坚持一种极其简单的信念：并不是地球上生物性的躯体才具有人性，他们生产和制造的一切事物也应该有，甚至让这些事物得以存在的一切也有。地球在未来演化出的超级集合体会更加智能，内部之间的联系也越来越团结和紧密，尤其是在地球上刚刚出现的几个不同派别之间。这种讨论会永久避免加里斯设想的内部战争，因为战争变成了某种形式的自残甚至自杀行为。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    到这里我们已经超出了科幻小说的范畴。目前看来，我们要小心避免抨击任何对这个问题的思考，不要断言它们是愚蠢和不成熟的。AlphaZero 已经证明，我们能够借助机器取得不可思议的成就：人工智能再也不是一个遥远的梦。另一方面，物联网的快速发展将把全世界所有的参与者联系起来，构成一个致密的茧。毫无疑问，它将形成一个全新的结构，所有的事物都依赖于所有的因素。而我们就像我们的人工智能一样，不过是其中的组成部分。
    
      
             
              
            
 
      
    
  

" />
    
    <meta name="author" content="觀點2" />

    
    <meta property="og:title" content="生存或者毁灭：超级人工智能将给人类带来什么？" />
    <meta property="twitter:title" content="生存或者毁灭：超级人工智能将给人类带来什么？" />
    

  <link rel="stylesheet" type="text/css" href="/oped2/style.css" />
  <link rel="alternate" type="application/rss+xml" title="觀點2 - 高頻版 git.io/JUJZT" href="/oped2/feed.xml" />

  <!-- Social Share Kit CSS -->
  <link rel="stylesheet" href="/oped2/assets/css/social-share-kit.css" type="text/css">
  <link rel="stylesheet" href="/oped2/assets/css/font-awesome.min.css" type="text/css">
  <link rel="stylesheet" href="/oped2/assets/css/bootstrap.min.css" type="text/css">
  <script type="text/javascript" src="/oped2/assets/js/jquery-3.5.1.js"></script>
  <script type="text/javascript" src="/oped2/assets/js/page.js"></script>

</head>

  <body>
    <div class="wrapper-masthead">
  <div class="container">
    <header class="masthead clearfix">
      

      <div class="site-info">
        <h1 class="site-name" style="display: inline-block;"><a href="/oped2/">觀點2</a></h1>
        <i class="site-description" style="font-size: 12px;">高頻版 git.io/JUJZT</i>
      </div>

      <nav>
        <span id="search-container" >
          <a href="/oped2/tools"><i class="fa fa-bookmark twitter" title="百宝箱"></i></a>
        <a><i class="fa fa-search" title="限前100結果"></i></a><input type="text" id="search-input" placeholder="標題 作者 來源 日期 (5685)"
          style="margin: 10px 0px 0px 0px; height: 30px;width: auto" title="本站最正確的打開方式">
        </span>
        
        
        <a href="/oped2/categories" style="color: Tomato;"><i class="fa fa-tags" title="分类"></i></a>
        
        
        
        <a href="https://be4.herokuapp.com/" style="color: #003366;"><i class="fa fa-comments" title="论坛"></i></a>
        
        
        
        <a href="/oped2/about"><i class="fa fa-info-circle" title="关于"></i></a>
        
        
        <a title="电脑热键：&larr;上一篇(页), &rarr;下一篇(页), ins同来源新一篇，del同来源旧一篇" onclick="toggle_visibility('help')"><i class="fa fa-question-circle"></i></a>
        <a id="fa-home" href="https://nodebe4.github.io" title="BE4服务列表" onclick="//toggle_visibility('site-list')"><i class="fa fa-home" aria-hidden="true"></i></a>
      </nav>

    </header>
    <div id="site-list" class="tags" style="display: block;text-align: right;border-bottom: 1px solid lightGray;"><noscript><span style="background-color: #e8e8e8;color: #d10000;font-size: 14px;">开启浏览器JavaScript以获取搜索功能和更好的浏览体验</span></noscript></div>
    <p id="help" style="font-size: 14px;display: none;text-align: right;"><span style="color:green;">电脑热键：&larr;上一篇(页), &rarr;下一篇(页), ins同来源新一篇, del同来源旧一篇</span>; <span style="color:orange">对应触屏FAB：上下右左</span>; 轉Markdown<a href="https://euangoddard.github.io/clipboard2markdown/"><i class="fa fa-file-text-o"></i></a></p>
  </div>
</div>

<script type="text/javascript" >
  function toggle_visibility(id){
    var help = document.getElementById(id)
    if (help.style.display=='none'){
      help.style.display='block';
    }else{
      help.style.display='none';
    }
  }

  const url = "https://nodebe4.github.io/sitelist.json"

  document.addEventListener("DOMContentLoaded", function(event){
    // var homebtn = document.getElementById("fa-home")
    // homebtn.removeAttribute("href")
    var content = document.getElementById("site-list");
    content.innerHTML = ''
    var ul = document.createElement("ul")
    ul.classList.add("label")
    content.appendChild(ul)
    var cnt = 0

    $.getJSON(url, function(allsites) {

      allsites.map(item =>{
        var li = document.createElement('li')
        li.classList.add("tag")
        li.id = 'site-' + cnt
        ul.appendChild(li)
        var a0 = document.createElement('a')
        li.appendChild(a0)
        a0.href = item.url[0]
        var span = document.createElement('span')
        a0.appendChild(span)
        span.innerText = item['name']
        // span.style.backgroundColor = item['background-color']
        // span.style.color='#E4CBC3'
        span.style.color = item['background-color']
        span.style['font-size'] = '14px'
        cnt += 1
        // test_alive(li.id, a0.href)
      })
    })
  })

function test_alive(id, url){
  var divstatus = document.getElementById(id)
  const base = 'https://textance.herokuapp.com/title/'
  var fullurl = base + url
  $.ajax({
      url: fullurl,
      complete: function(data) {
        if (data.responseText.includes('502')){
          // divstatus.style.color='#FBB7B7'
          // divstatus.style.color='gray'
          // divstatus.title = "服务器无响应"
          divstatus.parentNode.removeChild(divstatus)
        }else{
          // divstatus.style.color='#B6FAC8'
          divstatus.title = data.responseText
        }
      }
  });
  return divstatus
}
</script>



    <!-- Left & centered positioning -->

<div class="ssk-sticky ssk-right ssk-center ssk-sticky-hide-xs ssk-group ssk-round">
  
    <a href="https://be4news.pythonanywhere.com/archivenow/ia/https%3A%2F%2Fnei.st%2Fmedium%2Fsouthern%2Fnfzm-1859e" class="ssk ssk-link" title="存到互联网档案馆" target="_blank"></a>
    <a href="https://www.facebook.com/sharer.php?u=https://nei.st/medium/southern/nfzm-1859e" class="ssk ssk-facebook"></a>
    <a href="https://twitter.com/intent/tweet?url=https://nei.st/medium/southern/nfzm-1859e&text=生存或者毁灭：超级人工智能将给人类带来什么？&hashtags=觀點2" class="ssk ssk-twitter"></a>
    <a href="https://reddit.com/submit?url=https://nei.st/medium/southern/nfzm-1859e&title=生存或者毁灭：超级人工智能将给人类带来什么？" class="ssk ssk-reddit"></a>
    <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://nei.st/medium/southern/nfzm-1859e&title=生存或者毁灭：超级人工智能将给人类带来什么？" class="ssk ssk-linkedin"></a>
    <a href="mailto:{email_address}?subject=生存或者毁灭：超级人工智能将给人类带来什么？&body=
  
    
    
       生存或者毁灭：超级人工智能将给人类带来什么？ 
    
  
  
    
    
    结果表明，通用强化学习算法能够从一块白板出发，学会任何事物。AI 不需要依靠知识，也不需要来自人类的特定经验
       
      
 
      
    
    人工智能领域的科学家已经取得了一项惊人的成就。戴维·希尔弗 (David Silver) 是 DeepMind 团队的负责人，他和团队共同研发的  AlphaZero 从掌握初步规则开始，通过自己与自己对战，独立学会了国际象棋、围棋和将棋 (日本棋类游戏)。对于这三种棋类游戏，AlphaZero 已经超过了最好的人类棋手  。
    这一进步非常了不起。  1997 年，计算机深蓝 (Deep Blue) 打败了国际象棋世界冠军加里·卡斯帕罗夫 (Gary Kasparov)  ，它结合了优秀的算法与对棋局的出色理解。最好的人类棋手也贡献了关于开局、残局和局面评估的专业知识，从某种意义上来说，是人类将这些知识「教」给了程序。
     而 AlphaZero 不同，不需要由人类专家向它传授自己掌握的知识。对于这样的棋类游戏，AI 可以独立学习，快速达到人类需要几个世纪才能累积的高度。AlphaZero 的研发人员表示：「无论对于国际象棋、将棋还是围棋， AlphaZero 使用的都是同样的算法，同样的网络结构。结果表明，通用强化学习算法 (即能够胜出的决策将被算法优先选择) 能够从一块白板出发，学会任何事物。它不需要依靠知识，也不需要来自人类的特定经验。」 
    随着人工智能快速发展，这个领域也开始面临越来越迫切的问题。研究人员、哲学家还有技术预言家纷纷开始辩论，设想未来可能出现的种种矛盾。  无论是感到期待还是恐慌，没有人会怀疑人工智能将主导我们的未来。这种主导作用也许是通过互联网，也许是与人类融合。 
    许多思想家都曾经深入思考过超级人工智能 (以及它对人类的态度)，试图以此预测未来的趋势。我们将探讨尼克·博斯特罗姆 (Nick Bostrom)、雷·库兹韦尔 (Ray Kurzweil)、本 (Ben) 和泰德·戈尔泽尔父子 (Ted Goertzel)、汉斯·莫拉维克 (Hans Moravec)、弗朗西斯·海利根 (Francis Heylighen)、雨果·德·加里斯 (Hugode Garis) 和克莱蒙·维达尔 (Clement Vidal) 的思考。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
           评论的风口浪尖 

     当我们还不了解一件事物时，往往会作出夸张的设想，讨论它的性质时也会出现两极分化的观点。但是，正如剧作家拉辛 (Racine) 借他笔下人物所说，AI 无法承担我们过分施加的荣耀，也不至于因为它引发的忧虑而遭受羞辱。 
    尽管我们对 AI 取得的成就感到震惊，也意识到它可能会造成巨大的影响，但不能被狂热冲昏头脑。  AI 在许多高度专业化的任务中都取得了惊人的成绩，但它仍然难以胜任所有需要常识的任务，例如翻译文学作品。  自动驾驶也被寄予厚望，但是专家仍然保持谨慎，认为我们至少需要 50 年的时间，才可能制造出完全自主驾驶的汽车，让乘客能够安心在后排看书。
    在我撰写的专栏中，曾经提到过一些能够欺骗图片识别软件 (基于深度神经网络的算法) 的方法。比如，所有人都能一眼看出这是一门大炮的照片，算法却把它识别成了鸵鸟。
    虽然人工智能已经在越来越多的专业任务中取得了令人瞩目的成就，但它却面临两方面的障碍。首先，对于同样的任务，AI 获得结果的方式与人类的方式完全不同，它借助技术设备和计算，不需要人类介入。例如，部分自动驾驶汽车上装配的雷达和激光，它们计算和存储海量信息的能力远远超过人脑；另一方面，尽管取得了这样的成就，  AI 仍然无法将多种专业能力结合起来，形成一个自洽的、具备常识的系统  。我们无法合理地推测它们是否具备自我意识，拥有感知能力、幽默感，甚至是完备而稳定的「人格」。
           总是失误的预测 

    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    1958 年，赫伯特·西蒙 (Herbert Simon，1978 年诺贝尔经济学奖得主) 宣称，在未来 10 年中，计算机将在国际象棋中打败人类冠军。他正确预言了我们将取得的成就，却弄错了等待的时间——他的预言过了 40 年才实现。
    1966 年，英国著名统计学家欧文·古德 (Irving Good) 为斯坦利·库布里克 (Stanley Kubrick) 的电影《2001 太空漫游》担任顾问，他设想在 2000 年将出现一个强大的人工智能，达到甚至超越人类的智力水平。现在的人工智能还没有达到这个水平，期待强大人工智能的人们只好推迟这个期限。谷歌工程技术总监库兹韦尔和奇点大学 (位于美国加州的一所私立学校) 联合创始人及董事长彼得·戴曼迪斯 (Peter Diamandis) 认为这个期限是 2030 年，而 AI 研究者泰德·戈尔泽尔和本·戈尔泽尔则认为要等到 2040 年，甚至 2100 年。
    这很可能会像国际象棋 AI 的发展一样：我们实现了目标，只是晚得多。因为这个问题非常困难，我们只有经过年复一年的努力才会实现这一点。如今，最合理的预测也许是不要作出任何预测！
     对于必将到来的超级人工智能，人们提出了一个叫做「奇点」的概念，尽管谁也无法真正了解它究竟是什么。也许是某个日期，到时候地球上人工智能的能力曲线将以接近垂直的方式增长？也许是某个事件，机器毁灭人类，夺取了权力？也许是某一时刻，由于超越人类的人工智能带来了翻天覆地的变化，人类再也无法理解这个世界？ 
    即便考虑著名的「摩尔定律」(计算设备的能力每 18 个月到 2 年就会翻倍，过去 50 年的发展基本符合这一定律)，「奇点」理论也不会很快成为严重的威胁。一方面，摩尔定律预测的增长是一个指数函数，它不会趋于直线；另一方面，在我们的物理世界中，所有的指数增长都会很快遇到阻碍，进而停滞不前。没有人认为摩尔定律会无限延续下去 (它已经遇到了困难)。最后，尽管计算和存储能力持续增长，也无法确保我们始终知道如何使用这些能力，创造出足以和我们对抗的通用型人工智能。
    对于谷歌、苹果、脸书、亚马逊和微软在这方面发出的宣言，我们应该审慎地看待。和这些技术公司的发言人相比，一些研究人员的态度要谨慎和清醒得多，例如法国国家科学研究中心 (CNRS) 伦理委员会主席、人工智能专家让-加布里埃尓·加纳西亚 (Jean-Gabriel Ganascia)。加纳西亚认为，那些人想要发起一个由企业主导、超越国界的大型项目，可能只是出于无尽的贪欲。奇点的概念被用来转移注意力、制造恐慌，但实际上这主要是为了劝阻其他人，并掩饰自己想要占据统治地位的野心。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    尽管无法确切地知道超级人工智能出现时是什么情形，但也无法阻止我们深入探讨、投下赌注。我们可以想象多个不同的场景，不设定具体期限，甚至考虑任何猜想都不正确。
    尼克·博斯特罗姆在他的书中定义了超级人工智能，并设定这种智能在任何一个方面都大大超过人类的认知能力。他还提出了两个截然不同的假设。
    (a) 基于硅的机器 (包括量子计算机) 进入实用领域并不断发展，最终这些人造设备在一切可能的智力活动中达到甚至超过人类水平，就像 AlphaZero 一样。而我们与它们的功能没有发生直接联系，也没有在肢体上与人工智能设备融合或相连接。
    (b) 基于生物性元素 (人类或其他的) 与信息技术设备结合的产物。简单地说，就是人类发明的高级技术与生物体有机地结合在了一起，他们之间是相互融合的。这种形式也有可能发展出超级人工智能。
           势力分化？ 

    研究人工智能的加里斯则将满足假设 (a) 的智慧生物称为「人工大脑」，并设想了一种基于这类技术的未来，我们将在下一部分讨论这种场景。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    而长久以来，科幻作品都采用了假设 (b)，并将这类结合了生物和信息技术，具备超级智能的混合体称为赛博格 (cyborgs，或改造人)。例如，假设为了弥补记忆局限，我们给自己插入容量高达到数太字节 (TB) 的芯片，从而能够直接在大脑中读取整部维基百科的信息。与此同时，借助一种能够通过可以瞬间读取的数学计算模块，我们能立刻回答「720 等于几」或「sin(cos(x)) 的五阶导数是什么」之类的问题。我们的智力将大幅提升。
    有时也会提到第三个假设：一台全球化的大脑，各地的机器通过网络交换信息，构成了某种去中心化、具有思想的存在。我们稍后再回到这个假设。
           悲观的加里斯 

    加里斯认为：「社会将会分成三个哲学派别，派别之间将发生激烈的斗争。第一个派别由宇宙主义者构成，他们支持建造人工大脑；第二派别由地球主义者构成，他们反对建造人工大脑；而第三派别则支持赛博格，他们希望对大脑进行改造，从而把自己变成赛博格。」
    加里斯的著作《人工大脑之战》(The Artilect War) 介于科幻小说和严肃的未来学著作之间。在这部作品中，他认为三个派别之间的战争不可避免，并且在他看来，这场战争将比地球上发生过的任何战争都更惨烈，将在 21 世纪造成超过十亿人死亡。地球主义者在这场战争中获胜的希望非常渺茫，如果他们要取得胜利，就必须赶在另外两个可能结盟的派别察觉到威胁之前采取行动。在接受探索频道的访谈时，加里斯就曾表达过他的忧虑：「我很高兴能活在这个时代，我很有可能会平静地躺在自己的床上死去。但是我为我的孙辈感到担忧，他们可能被卷入人工大脑的战争，并且很可能因此丧命。」
    有趣的是，尽管超人类主义者在法国不受待见，加里斯也在书中对他们表达了谴责或嘲笑，但他们却非常乐观地捍卫自己的主张。超人类主义者认为应当毫无保留地发展增强技术，对人类进行改造——不能止步于眼镜、助听器和心脏起搏器，而是要采用一切可能的技术延长寿命、提升智力和强化身体机能。简而言之，他们支持赛博格的思想，属于赛博格主义者的阵营。他们将和宇宙主义者结盟，避免被地球主义者消灭。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    至于赛博格主义者和宇宙主义者之间会发生什么，超人类主义者和加里斯发生了分歧。大多数超人类主义者认为，人类赛博格将与具备超级智能的机械设备共存，不会发生生物学上的结合；而超人类主义者相信，将生物性元素 (特指他们自己) 和电子技术元素深度结合能够增强人类获得长生不死的能力，这才是人类未来的关键。
    加里斯的设想恰好相反：和人工大脑可能取得的成就相比，超人类主义简直无足轻重。在他看来，将生命体和未来的信息技术相融合只是一种幻想：人工大脑将对改造人这样的怪物不屑一顾，它只会毁灭改造人。
    而作为世界超人类主义者协会 (World Transhumanist Association) 联合创始人，博斯特罗姆也不认为人工大脑会对人类 (人工大脑的创造者，最终会成为赛博格) 采取和平友善的态度。他催促人们审视未来的智能产物，将它们视为一种威胁。博斯特罗姆的作品得到了埃隆·马斯克 (Elon Musk)、比尔·盖茨 (Bill Gates) 和李彦宏的推崇，这种看法似乎打动了他们，使他们开始传播恐慌信息 (也就是所谓的人工智能威胁论)。
    在加里斯看来，人工大脑 (具备意识的人工智能，或极其智能的机器) 不会友好地容忍人类甚至赛博格的存在，他说：「这个想法就像是尾巴摇狗一样，显然很荒谬。狗可比它的尾巴大得多，尾巴根本无法摇动狗。但超人类主义者认为人工大脑会和人类保持友好，这就犯了同样的逻辑错误……我认为这种观念是狂妄而天真的。它假设人类足够智能，即便面对一个能力超出人类几十亿倍的个体，也能正确判断它的动机。」
           其他可能 

    加里斯忽略了另一种思潮：世界上所有的个体并不一定要互相竞争，而是相互连接，成为一种全球尺度的超级有机体。这种观点直接排除了「终结者之战」的可能。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    这种全球大融合的观点常常被认为是宗教性的。它存在于佛教的哲学中，也出现在天主教耶稣会哲学家德日进 (Pierre Teilhard de Chardin，1881–1955) 的思想中。德日进提出了「智慧圈」，这种「一体性的思想由人类的交流形成，覆盖了地球表面」。
    比利时哲学家弗朗西斯·海利根坚定地认为：超级人工智能将通过互联网传播，形成一个类似超级大脑的存在。他指出：「这个全球化的大脑将克服全球性超级有机体可能遭遇的挑战。它的能力将远远超过我们现有的水平，将具备某些神性的特质：无所不知 (知道我们的一切问题的答案)、无处不在 (存在于任何时间和地点)、无所不能 (能够以最高效的方式生产任何物品或服务)、博爱众生 (致力于为最多的人带来最大的幸福)。」
    比利时布鲁塞尔自由大学的哲学家克莱蒙·维达尔研究宇宙主义，他引用了威廉·斯塔福德 (William Stafford) 的诗句「所有的战争都有两个失败者」，指出暴力往往是非理性的。而斯蒂芬·平克 (Steven Pinker) 详细论述了世界会越来越和平，尽管我们觉得这个过程过于漫长，但它仍然是可被测量和解释的。一方面，无论我们是否愿意，所有人对所有人的相互依赖都使我们彼此产生联系。博弈论和对囚徒困境模型计算模拟的结果都支持这样的分析。这表明，合作才是多个社会和政治团体理性的选择。
           殊途同归 

    「复杂性的伦理」是最后一个论据，可以证明「地球上不同动机的群体最终会结成一个利益共同体」的想法并不荒谬。如果按照这个伦理的预测，所有的智慧生物都会选择为一个普世价值共同体服务，将向着共同的目标行动，不再有发动战争的动机。
    尽管不同的讨论显示可能存在某种共同的方向，但这并不能保证当超级人工智能出现时 (如果它们会出现的话)，将与我们这些或多或少变成赛博格的人类和平结盟，并且在这个过程中没有任何一方试图消灭其他群体。在我看来，我们或许可以坚持一种极其简单的信念：并不是地球上生物性的躯体才具有人性，他们生产和制造的一切事物也应该有，甚至让这些事物得以存在的一切也有。地球在未来演化出的超级集合体会更加智能，内部之间的联系也越来越团结和紧密，尤其是在地球上刚刚出现的几个不同派别之间。这种讨论会永久避免加里斯设想的内部战争，因为战争变成了某种形式的自残甚至自杀行为。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    到这里我们已经超出了科幻小说的范畴。目前看来，我们要小心避免抨击任何对这个问题的思考，不要断言它们是愚蠢和不成熟的。AlphaZero 已经证明，我们能够借助机器取得不可思议的成就：人工智能再也不是一个遥远的梦。另一方面，物联网的快速发展将把全世界所有的参与者联系起来，构成一个致密的茧。毫无疑问，它将形成一个全新的结构，所有的事物都依赖于所有的因素。而我们就像我们的人工智能一样，不过是其中的组成部分。
    
      
             
              
            
 
      
    
  

" class="ssk ssk-email"></a>
    <a href="http://pinterest.com/pin/create/link/?url=https://nei.st/medium/southern/nfzm-1859e" class="ssk ssk-pinterest"></a>
    <a href="https://www.tumblr.com/widgets/share/tool?canonicalUrl=https://nei.st/medium/southern/nfzm-1859e&title=生存或者毁灭：超级人工智能将给人类带来什么？&caption=
  
    
    
       生存或者毁灭：超级人工智能将给人类带来什么？ 
    
  
  
    
    
    结果表明，通用强化学习算法能够从一块白板出发，学会任何事物。AI 不需要依靠知识，也不需要来自人类的特定经验
       
      
 
      
    
    人工智能领域的科学家已经取得了一项惊人的成就。戴维·希尔弗 (David Silver) 是 DeepMind 团队的负责人，他和团队共同研发的  AlphaZero 从掌握初步规则开始，通过自己与自己对战，独立学会了国际象棋、围棋和将棋 (日本棋类游戏)。对于这三种棋类游戏，AlphaZero 已经超过了最好的人类棋手  。
    这一进步非常了不起。  1997 年，计算机深蓝 (Deep Blue) 打败了国际象棋世界冠军加里·卡斯帕罗夫 (Gary Kasparov)  ，它结合了优秀的算法与对棋局的出色理解。最好的人类棋手也贡献了关于开局、残局和局面评估的专业知识，从某种意义上来说，是人类将这些知识「教」给了程序。
     而 AlphaZero 不同，不需要由人类专家向它传授自己掌握的知识。对于这样的棋类游戏，AI 可以独立学习，快速达到人类需要几个世纪才能累积的高度。AlphaZero 的研发人员表示：「无论对于国际象棋、将棋还是围棋， AlphaZero 使用的都是同样的算法，同样的网络结构。结果表明，通用强化学习算法 (即能够胜出的决策将被算法优先选择) 能够从一块白板出发，学会任何事物。它不需要依靠知识，也不需要来自人类的特定经验。」 
    随着人工智能快速发展，这个领域也开始面临越来越迫切的问题。研究人员、哲学家还有技术预言家纷纷开始辩论，设想未来可能出现的种种矛盾。  无论是感到期待还是恐慌，没有人会怀疑人工智能将主导我们的未来。这种主导作用也许是通过互联网，也许是与人类融合。 
    许多思想家都曾经深入思考过超级人工智能 (以及它对人类的态度)，试图以此预测未来的趋势。我们将探讨尼克·博斯特罗姆 (Nick Bostrom)、雷·库兹韦尔 (Ray Kurzweil)、本 (Ben) 和泰德·戈尔泽尔父子 (Ted Goertzel)、汉斯·莫拉维克 (Hans Moravec)、弗朗西斯·海利根 (Francis Heylighen)、雨果·德·加里斯 (Hugode Garis) 和克莱蒙·维达尔 (Clement Vidal) 的思考。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
           评论的风口浪尖 

     当我们还不了解一件事物时，往往会作出夸张的设想，讨论它的性质时也会出现两极分化的观点。但是，正如剧作家拉辛 (Racine) 借他笔下人物所说，AI 无法承担我们过分施加的荣耀，也不至于因为它引发的忧虑而遭受羞辱。 
    尽管我们对 AI 取得的成就感到震惊，也意识到它可能会造成巨大的影响，但不能被狂热冲昏头脑。  AI 在许多高度专业化的任务中都取得了惊人的成绩，但它仍然难以胜任所有需要常识的任务，例如翻译文学作品。  自动驾驶也被寄予厚望，但是专家仍然保持谨慎，认为我们至少需要 50 年的时间，才可能制造出完全自主驾驶的汽车，让乘客能够安心在后排看书。
    在我撰写的专栏中，曾经提到过一些能够欺骗图片识别软件 (基于深度神经网络的算法) 的方法。比如，所有人都能一眼看出这是一门大炮的照片，算法却把它识别成了鸵鸟。
    虽然人工智能已经在越来越多的专业任务中取得了令人瞩目的成就，但它却面临两方面的障碍。首先，对于同样的任务，AI 获得结果的方式与人类的方式完全不同，它借助技术设备和计算，不需要人类介入。例如，部分自动驾驶汽车上装配的雷达和激光，它们计算和存储海量信息的能力远远超过人脑；另一方面，尽管取得了这样的成就，  AI 仍然无法将多种专业能力结合起来，形成一个自洽的、具备常识的系统  。我们无法合理地推测它们是否具备自我意识，拥有感知能力、幽默感，甚至是完备而稳定的「人格」。
           总是失误的预测 

    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    1958 年，赫伯特·西蒙 (Herbert Simon，1978 年诺贝尔经济学奖得主) 宣称，在未来 10 年中，计算机将在国际象棋中打败人类冠军。他正确预言了我们将取得的成就，却弄错了等待的时间——他的预言过了 40 年才实现。
    1966 年，英国著名统计学家欧文·古德 (Irving Good) 为斯坦利·库布里克 (Stanley Kubrick) 的电影《2001 太空漫游》担任顾问，他设想在 2000 年将出现一个强大的人工智能，达到甚至超越人类的智力水平。现在的人工智能还没有达到这个水平，期待强大人工智能的人们只好推迟这个期限。谷歌工程技术总监库兹韦尔和奇点大学 (位于美国加州的一所私立学校) 联合创始人及董事长彼得·戴曼迪斯 (Peter Diamandis) 认为这个期限是 2030 年，而 AI 研究者泰德·戈尔泽尔和本·戈尔泽尔则认为要等到 2040 年，甚至 2100 年。
    这很可能会像国际象棋 AI 的发展一样：我们实现了目标，只是晚得多。因为这个问题非常困难，我们只有经过年复一年的努力才会实现这一点。如今，最合理的预测也许是不要作出任何预测！
     对于必将到来的超级人工智能，人们提出了一个叫做「奇点」的概念，尽管谁也无法真正了解它究竟是什么。也许是某个日期，到时候地球上人工智能的能力曲线将以接近垂直的方式增长？也许是某个事件，机器毁灭人类，夺取了权力？也许是某一时刻，由于超越人类的人工智能带来了翻天覆地的变化，人类再也无法理解这个世界？ 
    即便考虑著名的「摩尔定律」(计算设备的能力每 18 个月到 2 年就会翻倍，过去 50 年的发展基本符合这一定律)，「奇点」理论也不会很快成为严重的威胁。一方面，摩尔定律预测的增长是一个指数函数，它不会趋于直线；另一方面，在我们的物理世界中，所有的指数增长都会很快遇到阻碍，进而停滞不前。没有人认为摩尔定律会无限延续下去 (它已经遇到了困难)。最后，尽管计算和存储能力持续增长，也无法确保我们始终知道如何使用这些能力，创造出足以和我们对抗的通用型人工智能。
    对于谷歌、苹果、脸书、亚马逊和微软在这方面发出的宣言，我们应该审慎地看待。和这些技术公司的发言人相比，一些研究人员的态度要谨慎和清醒得多，例如法国国家科学研究中心 (CNRS) 伦理委员会主席、人工智能专家让-加布里埃尓·加纳西亚 (Jean-Gabriel Ganascia)。加纳西亚认为，那些人想要发起一个由企业主导、超越国界的大型项目，可能只是出于无尽的贪欲。奇点的概念被用来转移注意力、制造恐慌，但实际上这主要是为了劝阻其他人，并掩饰自己想要占据统治地位的野心。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    尽管无法确切地知道超级人工智能出现时是什么情形，但也无法阻止我们深入探讨、投下赌注。我们可以想象多个不同的场景，不设定具体期限，甚至考虑任何猜想都不正确。
    尼克·博斯特罗姆在他的书中定义了超级人工智能，并设定这种智能在任何一个方面都大大超过人类的认知能力。他还提出了两个截然不同的假设。
    (a) 基于硅的机器 (包括量子计算机) 进入实用领域并不断发展，最终这些人造设备在一切可能的智力活动中达到甚至超过人类水平，就像 AlphaZero 一样。而我们与它们的功能没有发生直接联系，也没有在肢体上与人工智能设备融合或相连接。
    (b) 基于生物性元素 (人类或其他的) 与信息技术设备结合的产物。简单地说，就是人类发明的高级技术与生物体有机地结合在了一起，他们之间是相互融合的。这种形式也有可能发展出超级人工智能。
           势力分化？ 

    研究人工智能的加里斯则将满足假设 (a) 的智慧生物称为「人工大脑」，并设想了一种基于这类技术的未来，我们将在下一部分讨论这种场景。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    而长久以来，科幻作品都采用了假设 (b)，并将这类结合了生物和信息技术，具备超级智能的混合体称为赛博格 (cyborgs，或改造人)。例如，假设为了弥补记忆局限，我们给自己插入容量高达到数太字节 (TB) 的芯片，从而能够直接在大脑中读取整部维基百科的信息。与此同时，借助一种能够通过可以瞬间读取的数学计算模块，我们能立刻回答「720 等于几」或「sin(cos(x)) 的五阶导数是什么」之类的问题。我们的智力将大幅提升。
    有时也会提到第三个假设：一台全球化的大脑，各地的机器通过网络交换信息，构成了某种去中心化、具有思想的存在。我们稍后再回到这个假设。
           悲观的加里斯 

    加里斯认为：「社会将会分成三个哲学派别，派别之间将发生激烈的斗争。第一个派别由宇宙主义者构成，他们支持建造人工大脑；第二派别由地球主义者构成，他们反对建造人工大脑；而第三派别则支持赛博格，他们希望对大脑进行改造，从而把自己变成赛博格。」
    加里斯的著作《人工大脑之战》(The Artilect War) 介于科幻小说和严肃的未来学著作之间。在这部作品中，他认为三个派别之间的战争不可避免，并且在他看来，这场战争将比地球上发生过的任何战争都更惨烈，将在 21 世纪造成超过十亿人死亡。地球主义者在这场战争中获胜的希望非常渺茫，如果他们要取得胜利，就必须赶在另外两个可能结盟的派别察觉到威胁之前采取行动。在接受探索频道的访谈时，加里斯就曾表达过他的忧虑：「我很高兴能活在这个时代，我很有可能会平静地躺在自己的床上死去。但是我为我的孙辈感到担忧，他们可能被卷入人工大脑的战争，并且很可能因此丧命。」
    有趣的是，尽管超人类主义者在法国不受待见，加里斯也在书中对他们表达了谴责或嘲笑，但他们却非常乐观地捍卫自己的主张。超人类主义者认为应当毫无保留地发展增强技术，对人类进行改造——不能止步于眼镜、助听器和心脏起搏器，而是要采用一切可能的技术延长寿命、提升智力和强化身体机能。简而言之，他们支持赛博格的思想，属于赛博格主义者的阵营。他们将和宇宙主义者结盟，避免被地球主义者消灭。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    至于赛博格主义者和宇宙主义者之间会发生什么，超人类主义者和加里斯发生了分歧。大多数超人类主义者认为，人类赛博格将与具备超级智能的机械设备共存，不会发生生物学上的结合；而超人类主义者相信，将生物性元素 (特指他们自己) 和电子技术元素深度结合能够增强人类获得长生不死的能力，这才是人类未来的关键。
    加里斯的设想恰好相反：和人工大脑可能取得的成就相比，超人类主义简直无足轻重。在他看来，将生命体和未来的信息技术相融合只是一种幻想：人工大脑将对改造人这样的怪物不屑一顾，它只会毁灭改造人。
    而作为世界超人类主义者协会 (World Transhumanist Association) 联合创始人，博斯特罗姆也不认为人工大脑会对人类 (人工大脑的创造者，最终会成为赛博格) 采取和平友善的态度。他催促人们审视未来的智能产物，将它们视为一种威胁。博斯特罗姆的作品得到了埃隆·马斯克 (Elon Musk)、比尔·盖茨 (Bill Gates) 和李彦宏的推崇，这种看法似乎打动了他们，使他们开始传播恐慌信息 (也就是所谓的人工智能威胁论)。
    在加里斯看来，人工大脑 (具备意识的人工智能，或极其智能的机器) 不会友好地容忍人类甚至赛博格的存在，他说：「这个想法就像是尾巴摇狗一样，显然很荒谬。狗可比它的尾巴大得多，尾巴根本无法摇动狗。但超人类主义者认为人工大脑会和人类保持友好，这就犯了同样的逻辑错误……我认为这种观念是狂妄而天真的。它假设人类足够智能，即便面对一个能力超出人类几十亿倍的个体，也能正确判断它的动机。」
           其他可能 

    加里斯忽略了另一种思潮：世界上所有的个体并不一定要互相竞争，而是相互连接，成为一种全球尺度的超级有机体。这种观点直接排除了「终结者之战」的可能。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    这种全球大融合的观点常常被认为是宗教性的。它存在于佛教的哲学中，也出现在天主教耶稣会哲学家德日进 (Pierre Teilhard de Chardin，1881–1955) 的思想中。德日进提出了「智慧圈」，这种「一体性的思想由人类的交流形成，覆盖了地球表面」。
    比利时哲学家弗朗西斯·海利根坚定地认为：超级人工智能将通过互联网传播，形成一个类似超级大脑的存在。他指出：「这个全球化的大脑将克服全球性超级有机体可能遭遇的挑战。它的能力将远远超过我们现有的水平，将具备某些神性的特质：无所不知 (知道我们的一切问题的答案)、无处不在 (存在于任何时间和地点)、无所不能 (能够以最高效的方式生产任何物品或服务)、博爱众生 (致力于为最多的人带来最大的幸福)。」
    比利时布鲁塞尔自由大学的哲学家克莱蒙·维达尔研究宇宙主义，他引用了威廉·斯塔福德 (William Stafford) 的诗句「所有的战争都有两个失败者」，指出暴力往往是非理性的。而斯蒂芬·平克 (Steven Pinker) 详细论述了世界会越来越和平，尽管我们觉得这个过程过于漫长，但它仍然是可被测量和解释的。一方面，无论我们是否愿意，所有人对所有人的相互依赖都使我们彼此产生联系。博弈论和对囚徒困境模型计算模拟的结果都支持这样的分析。这表明，合作才是多个社会和政治团体理性的选择。
           殊途同归 

    「复杂性的伦理」是最后一个论据，可以证明「地球上不同动机的群体最终会结成一个利益共同体」的想法并不荒谬。如果按照这个伦理的预测，所有的智慧生物都会选择为一个普世价值共同体服务，将向着共同的目标行动，不再有发动战争的动机。
    尽管不同的讨论显示可能存在某种共同的方向，但这并不能保证当超级人工智能出现时 (如果它们会出现的话)，将与我们这些或多或少变成赛博格的人类和平结盟，并且在这个过程中没有任何一方试图消灭其他群体。在我看来，我们或许可以坚持一种极其简单的信念：并不是地球上生物性的躯体才具有人性，他们生产和制造的一切事物也应该有，甚至让这些事物得以存在的一切也有。地球在未来演化出的超级集合体会更加智能，内部之间的联系也越来越团结和紧密，尤其是在地球上刚刚出现的几个不同派别之间。这种讨论会永久避免加里斯设想的内部战争，因为战争变成了某种形式的自残甚至自杀行为。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    到这里我们已经超出了科幻小说的范畴。目前看来，我们要小心避免抨击任何对这个问题的思考，不要断言它们是愚蠢和不成熟的。AlphaZero 已经证明，我们能够借助机器取得不可思议的成就：人工智能再也不是一个遥远的梦。另一方面，物联网的快速发展将把全世界所有的参与者联系起来，构成一个致密的茧。毫无疑问，它将形成一个全新的结构，所有的事物都依赖于所有的因素。而我们就像我们的人工智能一样，不过是其中的组成部分。
    
      
             
              
            
 
      
    
  

&tags=觀點2" class="ssk ssk-tumblr"></a>
    <a href="https://buffer.com/add?text=生存或者毁灭：超级人工智能将给人类带来什么？&url=https://nei.st/medium/southern/nfzm-1859e" class="ssk ssk-buffer"></a>
</div>


    <div id="main" role="main" class="container">
      
  <!-- Html Elements for Search -->
  <ul id="results-container" class="searched" style="color: #2980B9;"></ul>

  <script src="/oped2/assets/js/simple-jekyll-search.min.js"></script>

  <!-- Configuration -->
  <script>
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('results-container'),
    json: '/oped2/search.json',
    searchResultTemplate: '<li><a href="{url}" title="{desc}">{title}</a><time>{date}</time><a class="tag">{category}</a></li>',
    noResultsText: '没找到',
    limit: 100,
    fuzzy: false,
    exclude: ['Welcome']
  })

  </script>

      







  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
    


  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
    



<article class="post">
  <h1>生存或者毁灭：超级人工智能将给人类带来什么？</h1>
  <!-- Look the author details up from the site config. -->
  

  <div>
    <span class="date">
      2019-10-11
    </span>

    <!-- Output author details if some exist. -->
    
      
    


    <ul class="tag">
      <li>
        <a href="https://nodebe4.github.io/oped2/categories/#Nei.st">
          Nei.st
        </a>
      </li>
    </ul>

    
        <span>
            <!-- Personal Info. -->
            <a href="https://nei.st/medium/southern/nfzm-1859e" style="font-size:14px;">原文</a>
        </span>
    

    <span style="float: right;" title="Nei.st的其它文章">
      <a style="font-size: 14px;" rel="nofollow" href="#sametag" class="tags">#Nei.st 的其它文章</a>
    </span>

  </div>

  <div class="entry">
    
    
    
    <article class="post-6142 post type-post status-publish format-standard hentry category-southern" id="post-6142">
  <header class="page-header medium Archives">
    <div class="page-header__image"></div>
    <div class="page-header__content">
      <h1 class="page-title text-align-center" id="section"> 生存或者毁灭：超级人工智能将给人类带来什么？ </h1>
    </div>
  </header>
  <div class="entry-content aesop-entry-content" id="post-6142-content">
    <link as="font" crossorigin="anonymous" href="//cdn.jsdelivr.net/gh/0nd1jyU39XQ/_/glyph/font-face/0uIzqoZjSuJfvSBnvgXTcApMtcVhMcpr.woff" rel="preload" type="font/woff" />
    <link as="font" crossorigin="anonymous" href="//cdn.jsdelivr.net/gh/0nd1jyU39XQ/_/glyph/font-face/1sTnSLZWDKucPX6SAk.woff" rel="preload" type="font/woff" />
    <p class="blog-post__description">结果表明，通用强化学习算法能够从一块白板出发，学会任何事物。AI 不需要依靠知识，也不需要来自人类的特定经验</p>
 <span id="more-6142"> </span>     <div class="container infzm">
      <div class="infzm-flex0">
<a class="infzm __link-logo" dir="auto" href="https://nei.st/medium/southern-weekly"> </a>
      </div>
    </div>
    <p>人工智能领域的科学家已经取得了一项惊人的成就。戴维·希尔弗 (David Silver) 是 DeepMind 团队的负责人，他和团队共同研发的 <span class="markup--p"> AlphaZero 从掌握初步规则开始，通过自己与自己对战，独立学会了国际象棋、围棋和将棋 (日本棋类游戏)。对于这三种棋类游戏，AlphaZero 已经超过了最好的人类棋手 </span> 。</p>
    <p>这一进步非常了不起。 <span class="markup--p"> 1997 年，计算机深蓝 (Deep Blue) 打败了国际象棋世界冠军加里·卡斯帕罗夫 (Gary Kasparov) </span> ，它结合了优秀的算法与对棋局的出色理解。最好的人类棋手也贡献了关于开局、残局和局面评估的专业知识，从某种意义上来说，是人类将这些知识「教」给了程序。</p>
    <p><span class="markup--p"> 而 AlphaZero 不同，不需要由人类专家向它传授自己掌握的知识。对于这样的棋类游戏，AI 可以独立学习，快速达到人类需要几个世纪才能累积的高度。AlphaZero 的研发人员表示：「无论对于国际象棋、将棋还是围棋， AlphaZero 使用的都是同样的算法，同样的网络结构。结果表明，通用强化学习算法 (即能够胜出的决策将被算法优先选择) 能够从一块白板出发，学会任何事物。它不需要依靠知识，也不需要来自人类的特定经验。」 </span></p>
    <p>随着人工智能快速发展，这个领域也开始面临越来越迫切的问题。研究人员、哲学家还有技术预言家纷纷开始辩论，设想未来可能出现的种种矛盾。 <span class="markup--p"> 无论是感到期待还是恐慌，没有人会怀疑人工智能将主导我们的未来。这种主导作用也许是通过互联网，也许是与人类融合。 </span></p>
    <p>许多思想家都曾经深入思考过超级人工智能 (以及它对人类的态度)，试图以此预测未来的趋势。我们将探讨尼克·博斯特罗姆 (Nick Bostrom)、雷·库兹韦尔 (Ray Kurzweil)、本 (Ben) 和泰德·戈尔泽尔父子 (Ted Goertzel)、汉斯·莫拉维克 (Hans Moravec)、弗朗西斯·海利根 (Francis Heylighen)、雨果·德·加里斯 (Hugode Garis) 和克莱蒙·维达尔 (Clement Vidal) 的思考。</p>
    <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
      <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
    <p>      <h2 id="section-1"> 评论的风口浪尖 </h2>
</p>
    <p><span class="markup--p"> 当我们还不了解一件事物时，往往会作出夸张的设想，讨论它的性质时也会出现两极分化的观点。但是，正如剧作家拉辛 (Racine) 借他笔下人物所说，AI 无法承担我们过分施加的荣耀，也不至于因为它引发的忧虑而遭受羞辱。 </span></p>
    <p>尽管我们对 AI 取得的成就感到震惊，也意识到它可能会造成巨大的影响，但不能被狂热冲昏头脑。 <span class="markup--p"> AI 在许多高度专业化的任务中都取得了惊人的成绩，但它仍然难以胜任所有需要常识的任务，例如翻译文学作品。 </span> 自动驾驶也被寄予厚望，但是专家仍然保持谨慎，认为我们至少需要 50 年的时间，才可能制造出完全自主驾驶的汽车，让乘客能够安心在后排看书。</p>
    <p>在我撰写的专栏中，曾经提到过一些能够欺骗图片识别软件 (基于深度神经网络的算法) 的方法。比如，所有人都能一眼看出这是一门大炮的照片，算法却把它识别成了鸵鸟。</p>
    <p>虽然人工智能已经在越来越多的专业任务中取得了令人瞩目的成就，但它却面临两方面的障碍。首先，对于同样的任务，AI 获得结果的方式与人类的方式完全不同，它借助技术设备和计算，不需要人类介入。例如，部分自动驾驶汽车上装配的雷达和激光，它们计算和存储海量信息的能力远远超过人脑；另一方面，尽管取得了这样的成就， <span class="markup--p"> AI 仍然无法将多种专业能力结合起来，形成一个自洽的、具备常识的系统 </span> 。我们无法合理地推测它们是否具备自我意识，拥有感知能力、幽默感，甚至是完备而稳定的「人格」。</p>
    <p>      <h2 id="section-2"> 总是失误的预测 </h2>
</p>
    <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
      <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
    <p>1958 年，赫伯特·西蒙 (Herbert Simon，1978 年诺贝尔经济学奖得主) 宣称，在未来 10 年中，计算机将在国际象棋中打败人类冠军。他正确预言了我们将取得的成就，却弄错了等待的时间——他的预言过了 40 年才实现。</p>
    <p>1966 年，英国著名统计学家欧文·古德 (Irving Good) 为斯坦利·库布里克 (Stanley Kubrick) 的电影《2001 太空漫游》担任顾问，他设想在 2000 年将出现一个强大的人工智能，达到甚至超越人类的智力水平。现在的人工智能还没有达到这个水平，期待强大人工智能的人们只好推迟这个期限。谷歌工程技术总监库兹韦尔和奇点大学 (位于美国加州的一所私立学校) 联合创始人及董事长彼得·戴曼迪斯 (Peter Diamandis) 认为这个期限是 2030 年，而 AI 研究者泰德·戈尔泽尔和本·戈尔泽尔则认为要等到 2040 年，甚至 2100 年。</p>
    <p>这很可能会像国际象棋 AI 的发展一样：我们实现了目标，只是晚得多。因为这个问题非常困难，我们只有经过年复一年的努力才会实现这一点。如今，最合理的预测也许是不要作出任何预测！</p>
    <p><span class="markup--p"> 对于必将到来的超级人工智能，人们提出了一个叫做「奇点」的概念，尽管谁也无法真正了解它究竟是什么。也许是某个日期，到时候地球上人工智能的能力曲线将以接近垂直的方式增长？也许是某个事件，机器毁灭人类，夺取了权力？也许是某一时刻，由于超越人类的人工智能带来了翻天覆地的变化，人类再也无法理解这个世界？ </span></p>
    <p>即便考虑著名的「摩尔定律」(计算设备的能力每 18 个月到 2 年就会翻倍，过去 50 年的发展基本符合这一定律)，「奇点」理论也不会很快成为严重的威胁。一方面，摩尔定律预测的增长是一个指数函数，它不会趋于直线；另一方面，在我们的物理世界中，所有的指数增长都会很快遇到阻碍，进而停滞不前。没有人认为摩尔定律会无限延续下去 (它已经遇到了困难)。最后，尽管计算和存储能力持续增长，也无法确保我们始终知道如何使用这些能力，创造出足以和我们对抗的通用型人工智能。</p>
    <p>对于谷歌、苹果、脸书、亚马逊和微软在这方面发出的宣言，我们应该审慎地看待。和这些技术公司的发言人相比，一些研究人员的态度要谨慎和清醒得多，例如法国国家科学研究中心 (CNRS) 伦理委员会主席、人工智能专家让-加布里埃尓·加纳西亚 (Jean-Gabriel Ganascia)。加纳西亚认为，那些人想要发起一个由企业主导、超越国界的大型项目，可能只是出于无尽的贪欲。奇点的概念被用来转移注意力、制造恐慌，但实际上这主要是为了劝阻其他人，并掩饰自己想要占据统治地位的野心。</p>
    <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
      <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
    <p>尽管无法确切地知道超级人工智能出现时是什么情形，但也无法阻止我们深入探讨、投下赌注。我们可以想象多个不同的场景，不设定具体期限，甚至考虑任何猜想都不正确。</p>
    <p>尼克·博斯特罗姆在他的书中定义了超级人工智能，并设定这种智能在任何一个方面都大大超过人类的认知能力。他还提出了两个截然不同的假设。</p>
    <p>(a) 基于硅的机器 (包括量子计算机) 进入实用领域并不断发展，最终这些人造设备在一切可能的智力活动中达到甚至超过人类水平，就像 AlphaZero 一样。而我们与它们的功能没有发生直接联系，也没有在肢体上与人工智能设备融合或相连接。</p>
    <p>(b) 基于生物性元素 (人类或其他的) 与信息技术设备结合的产物。简单地说，就是人类发明的高级技术与生物体有机地结合在了一起，他们之间是相互融合的。这种形式也有可能发展出超级人工智能。</p>
    <p>      <h2 id="section-3"> 势力分化？ </h2>
</p>
    <p>研究人工智能的加里斯则将满足假设 (a) 的智慧生物称为「人工大脑」，并设想了一种基于这类技术的未来，我们将在下一部分讨论这种场景。</p>
    <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
      <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
    <p>而长久以来，科幻作品都采用了假设 (b)，并将这类结合了生物和信息技术，具备超级智能的混合体称为赛博格 (cyborgs，或改造人)。例如，假设为了弥补记忆局限，我们给自己插入容量高达到数太字节 (TB) 的芯片，从而能够直接在大脑中读取整部维基百科的信息。与此同时，借助一种能够通过可以瞬间读取的数学计算模块，我们能立刻回答「720 等于几」或「sin(cos(x)) 的五阶导数是什么」之类的问题。我们的智力将大幅提升。</p>
    <p>有时也会提到第三个假设：一台全球化的大脑，各地的机器通过网络交换信息，构成了某种去中心化、具有思想的存在。我们稍后再回到这个假设。</p>
    <p>      <h2 id="section-4"> 悲观的加里斯 </h2>
</p>
    <p>加里斯认为：「社会将会分成三个哲学派别，派别之间将发生激烈的斗争。第一个派别由宇宙主义者构成，他们支持建造人工大脑；第二派别由地球主义者构成，他们反对建造人工大脑；而第三派别则支持赛博格，他们希望对大脑进行改造，从而把自己变成赛博格。」</p>
    <p>加里斯的著作《人工大脑之战》(The Artilect War) 介于科幻小说和严肃的未来学著作之间。在这部作品中，他认为三个派别之间的战争不可避免，并且在他看来，这场战争将比地球上发生过的任何战争都更惨烈，将在 21 世纪造成超过十亿人死亡。地球主义者在这场战争中获胜的希望非常渺茫，如果他们要取得胜利，就必须赶在另外两个可能结盟的派别察觉到威胁之前采取行动。在接受探索频道的访谈时，加里斯就曾表达过他的忧虑：「我很高兴能活在这个时代，我很有可能会平静地躺在自己的床上死去。但是我为我的孙辈感到担忧，他们可能被卷入人工大脑的战争，并且很可能因此丧命。」</p>
    <p>有趣的是，尽管超人类主义者在法国不受待见，加里斯也在书中对他们表达了谴责或嘲笑，但他们却非常乐观地捍卫自己的主张。超人类主义者认为应当毫无保留地发展增强技术，对人类进行改造——不能止步于眼镜、助听器和心脏起搏器，而是要采用一切可能的技术延长寿命、提升智力和强化身体机能。简而言之，他们支持赛博格的思想，属于赛博格主义者的阵营。他们将和宇宙主义者结盟，避免被地球主义者消灭。</p>
    <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
      <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
    <p>至于赛博格主义者和宇宙主义者之间会发生什么，超人类主义者和加里斯发生了分歧。大多数超人类主义者认为，人类赛博格将与具备超级智能的机械设备共存，不会发生生物学上的结合；而超人类主义者相信，将生物性元素 (特指他们自己) 和电子技术元素深度结合能够增强人类获得长生不死的能力，这才是人类未来的关键。</p>
    <p>加里斯的设想恰好相反：和人工大脑可能取得的成就相比，超人类主义简直无足轻重。在他看来，将生命体和未来的信息技术相融合只是一种幻想：人工大脑将对改造人这样的怪物不屑一顾，它只会毁灭改造人。</p>
    <p>而作为世界超人类主义者协会 (World Transhumanist Association) 联合创始人，博斯特罗姆也不认为人工大脑会对人类 (人工大脑的创造者，最终会成为赛博格) 采取和平友善的态度。他催促人们审视未来的智能产物，将它们视为一种威胁。博斯特罗姆的作品得到了埃隆·马斯克 (Elon Musk)、比尔·盖茨 (Bill Gates) 和李彦宏的推崇，这种看法似乎打动了他们，使他们开始传播恐慌信息 (也就是所谓的人工智能威胁论)。</p>
    <p>在加里斯看来，人工大脑 (具备意识的人工智能，或极其智能的机器) 不会友好地容忍人类甚至赛博格的存在，他说：「这个想法就像是尾巴摇狗一样，显然很荒谬。狗可比它的尾巴大得多，尾巴根本无法摇动狗。但超人类主义者认为人工大脑会和人类保持友好，这就犯了同样的逻辑错误……我认为这种观念是狂妄而天真的。它假设人类足够智能，即便面对一个能力超出人类几十亿倍的个体，也能正确判断它的动机。」</p>
    <p>      <h2 id="section-5"> 其他可能 </h2>
</p>
    <p>加里斯忽略了另一种思潮：世界上所有的个体并不一定要互相竞争，而是相互连接，成为一种全球尺度的超级有机体。这种观点直接排除了「终结者之战」的可能。</p>
    <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
      <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
    <p>这种全球大融合的观点常常被认为是宗教性的。它存在于佛教的哲学中，也出现在天主教耶稣会哲学家德日进 (Pierre Teilhard de Chardin，1881–1955) 的思想中。德日进提出了「智慧圈」，这种「一体性的思想由人类的交流形成，覆盖了地球表面」。</p>
    <p>比利时哲学家弗朗西斯·海利根坚定地认为：超级人工智能将通过互联网传播，形成一个类似超级大脑的存在。他指出：「这个全球化的大脑将克服全球性超级有机体可能遭遇的挑战。它的能力将远远超过我们现有的水平，将具备某些神性的特质：无所不知 (知道我们的一切问题的答案)、无处不在 (存在于任何时间和地点)、无所不能 (能够以最高效的方式生产任何物品或服务)、博爱众生 (致力于为最多的人带来最大的幸福)。」</p>
    <p>比利时布鲁塞尔自由大学的哲学家克莱蒙·维达尔研究宇宙主义，他引用了威廉·斯塔福德 (William Stafford) 的诗句「所有的战争都有两个失败者」，指出暴力往往是非理性的。而斯蒂芬·平克 (Steven Pinker) 详细论述了世界会越来越和平，尽管我们觉得这个过程过于漫长，但它仍然是可被测量和解释的。一方面，无论我们是否愿意，所有人对所有人的相互依赖都使我们彼此产生联系。博弈论和对囚徒困境模型计算模拟的结果都支持这样的分析。这表明，合作才是多个社会和政治团体理性的选择。</p>
    <p>      <h2 id="section-6"> 殊途同归 </h2>
</p>
    <p>「复杂性的伦理」是最后一个论据，可以证明「地球上不同动机的群体最终会结成一个利益共同体」的想法并不荒谬。如果按照这个伦理的预测，所有的智慧生物都会选择为一个普世价值共同体服务，将向着共同的目标行动，不再有发动战争的动机。</p>
    <p>尽管不同的讨论显示可能存在某种共同的方向，但这并不能保证当超级人工智能出现时 (如果它们会出现的话)，将与我们这些或多或少变成赛博格的人类和平结盟，并且在这个过程中没有任何一方试图消灭其他群体。在我看来，我们或许可以坚持一种极其简单的信念：并不是地球上生物性的躯体才具有人性，他们生产和制造的一切事物也应该有，甚至让这些事物得以存在的一切也有。地球在未来演化出的超级集合体会更加智能，内部之间的联系也越来越团结和紧密，尤其是在地球上刚刚出现的几个不同派别之间。这种讨论会永久避免加里斯设想的内部战争，因为战争变成了某种形式的自残甚至自杀行为。</p>
    <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
      <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
    <p>到这里我们已经超出了科幻小说的范畴。目前看来，我们要小心避免抨击任何对这个问题的思考，不要断言它们是愚蠢和不成熟的。AlphaZero 已经证明，我们能够借助机器取得不可思议的成就：人工智能再也不是一个遥远的梦。另一方面，物联网的快速发展将把全世界所有的参与者联系起来，构成一个致密的茧。毫无疑问，它将形成一个全新的结构，所有的事物都依赖于所有的因素。而我们就像我们的人工智能一样，不过是其中的组成部分。</p>
    <div class="container ag ah">
      <div class="fe n el">
<a class="dt du bn bo bp bq br bs bt bu dv dw bx by dx dy" href="https://nei.st/medium/southern-weekly">             <div class="c ff fg ag ah fh el fi fj ce fk fl fm fn fo fp fq fr fs ft fu">
              <div class="bs em en eo ep eq fv ah fw fg ag bm eu fx q fy fz p ac"></div>
            </div>
 </a>
      </div>
    </div>
  </div>
</article>

  </div>

  <hr style="border-top:1px solid #28323C;"/>

<font size=2px>
  文章版权归原作者所有。
</font>

<div style="text-align:center"><img width="1px" src="https://i.imgur.com/RinUcXm.png" alt="二维码分享本站" style="text-align:center"/></div>

  <div id="sametag">
    <h4 style="display: inline-block;">#Nei.st 的其它文章</h4>
    <span>--<a href="https://nodebe4.github.io/oped2/2020-07-30/%E5%A6%82%E4%BD%95%E7%9C%8B%E5%BE%85%E4%B8%AD%E5%9B%BD%E6%B0%91%E4%BC%97%E5%AF%B9%E6%94%BF%E5%BA%9C%E7%9A%84%E6%BB%A1%E6%84%8F%E5%BA%A6%E9%AB%98/">最新</a>-</span>
    <span>-<a href="https://nodebe4.github.io/oped2/2019-07-18/%E5%8D%87%E8%81%8C%E7%9A%84%E8%AF%85%E5%92%92/">最早</a>--</span>
    
      <li>
        <time>2019-10-11</time>
        <a href="https://nodebe4.github.io/oped2/2019-10-11/1975-%E5%B9%B4-%E7%8F%A0%E5%B3%B0%E7%99%BB%E9%A1%B6%E8%80%85%E5%92%8C%E9%82%A3%E4%BA%9B-%E8%B5%B0%E5%88%B0%E4%B8%80%E5%8D%8A%E7%9A%84%E4%BA%BA/">
          1975 年，珠峰登顶者和那些「走到一半的人」
        </a>
      </li>
    
    
      <li>
        <time>2019-10-11</time>
        <a href="https://nodebe4.github.io/oped2/2019-10-11/%E5%A4%9A%E5%B0%91%E4%B8%AA-%E9%98%B3%E6%BE%84%E6%B9%96-%E6%89%8D%E5%A4%9F/">
          多少个「阳澄湖」才够？
        </a>
      </li>
    
    
      <li>
        <time>2019-10-11</time>
        <a href="https://nodebe4.github.io/oped2/2019-10-11/%E4%B8%A4%E6%A1%B6%E6%B2%B9%E7%9A%84%E5%92%96%E5%95%A1%E5%8D%96%E7%BB%99%E8%B0%81/">
          两桶油的咖啡卖给谁？
        </a>
      </li>
    
    
      <li>
        <time>2019-10-10</time>
        <a href="https://nodebe4.github.io/oped2/2019-10-10/%E9%98%BF%E6%A0%B9%E5%BB%B7%E5%B4%A9%E6%BA%83%E5%8F%B2-%E5%85%AB%E6%AC%A1%E8%BF%9D%E7%BA%A6%E7%9A%84%E5%9B%BD%E5%AE%B6/">
          阿根廷崩溃史：八次违约的国家
        </a>
      </li>
    
  </div>


  <hr>
  <div class="pagination">
    
      <span class="prev" >
          <a href="https://nodebe4.github.io/oped2/2019-10-11/%E4%B8%A4%E6%A1%B6%E6%B2%B9%E7%9A%84%E5%92%96%E5%95%A1%E5%8D%96%E7%BB%99%E8%B0%81/">
            前一篇：两桶油的咖啡卖给谁？
          </a>
      </span>
    
    
      <span class="next" >
          <a href="https://nodebe4.github.io/oped2/2019-10-11/%E5%A4%9A%E5%B0%91%E4%B8%AA-%E9%98%B3%E6%BE%84%E6%B9%96-%E6%89%8D%E5%A4%9F/">
            後一篇：多少个「阳澄湖」才够？
          </a>
      </span>
    

    <script>
    /* post pagination keyboard shortcuts */
    document.body.onkeyup = function(e){
      if (e.keyCode == '37') { window.location = 'https://nodebe4.github.io/oped2/2019-10-11/%E4%B8%A4%E6%A1%B6%E6%B2%B9%E7%9A%84%E5%92%96%E5%95%A1%E5%8D%96%E7%BB%99%E8%B0%81/'; } // left arrow key
      if (e.keyCode == '39') { window.location = 'https://nodebe4.github.io/oped2/2019-10-11/%E5%A4%9A%E5%B0%91%E4%B8%AA-%E9%98%B3%E6%BE%84%E6%B9%96-%E6%89%8D%E5%A4%9F/'; } // right arrow key
      if (e.keyCode == '45') { window.location = 'https://nodebe4.github.io/oped2/2019-10-11/%E5%A4%9A%E5%B0%91%E4%B8%AA-%E9%98%B3%E6%BE%84%E6%B9%96-%E6%89%8D%E5%A4%9F/'; } // insert key
      if (e.keyCode == '46') { window.location = 'https://nodebe4.github.io/oped2/2019-10-11/%E4%B8%A4%E6%A1%B6%E6%B2%B9%E7%9A%84%E5%92%96%E5%95%A1%E5%8D%96%E7%BB%99%E8%B0%81/'; } // delete key
    };
    </script>
    <link rel="stylesheet" type="text/css" href="/oped2/assets/css/fab.css" />

<div class="fab-wrapper">
  <div class="fab-wheel">
    
    
    
    <a class="fab-action fab-action-1" title="上一篇(热键 &#8594;)" href="https://nodebe4.github.io/oped2/2019-10-11/%E4%B8%A4%E6%A1%B6%E6%B2%B9%E7%9A%84%E5%92%96%E5%95%A1%E5%8D%96%E7%BB%99%E8%B0%81/">
      <i>后</i>
    </a>
    
    
    <a class="fab-action fab-action-2" title="下一篇(热键 &#8592;)" href="https://nodebe4.github.io/oped2/2019-10-11/%E5%A4%9A%E5%B0%91%E4%B8%AA-%E9%98%B3%E6%BE%84%E6%B9%96-%E6%89%8D%E5%A4%9F/">
      <i>前</i>
    </a>
    
    
    <a class="fab-action fab-action-3" title="<Nei.st>上一篇(热键 ins)" href="https://nodebe4.github.io/oped2/2019-10-11/%E5%A4%9A%E5%B0%91%E4%B8%AA-%E9%98%B3%E6%BE%84%E6%B9%96-%E6%89%8D%E5%A4%9F/">
      <i>左</i>
    </a>
    
    
    <a class="fab-action fab-action-4" title="<Nei.st>下一篇(热键 del)" href="https://nodebe4.github.io/oped2/2019-10-11/%E4%B8%A4%E6%A1%B6%E6%B2%B9%E7%9A%84%E5%92%96%E5%95%A1%E5%8D%96%E7%BB%99%E8%B0%81/">
      <i>右</i>
    </a>
    
  </div>
</div>


  </div>


  

</article>

    </div>

    <div style="z-index:2;">
<script src="/oped2/assets/js/vanilla-back-to-top.min.js"></script>
<script>addBackToTop({
  diameter: 56,
  cornerOffset: 20, // px
  id: 'back-to-top',
  backgroundColor: '#ddd',
  textColor: 'red'
})</script>
</div>


    <div class="wrapper-footer" id="footer">
      <div class="container">
        <footer class="footer">
          <img width="200px" src="https://i.imgur.com/RinUcXm.png" alt="二维码分享本站"/>
<font size=2px>二维码分享本站</font>

<!-- Refer to https://codepen.io/ruandre/pen/howFi -->
<ul class="svg-icon">

  

  

  
  <li><a href="mailto:beauti4@protonmail.com" class="icon-8 email" title="Email"><svg viewBox="0 0 512 512"><path d="M101.3 141.6v228.9h0.3 308.4 0.8V141.6H101.3zM375.7 167.8l-119.7 91.5 -119.6-91.5H375.7zM127.6 194.1l64.1 49.1 -64.1 64.1V194.1zM127.8 344.2l84.9-84.9 43.2 33.1 43-32.9 84.7 84.7L127.8 344.2 127.8 344.2zM384.4 307.8l-64.4-64.4 64.4-49.3V307.8z"/></svg><!--[if lt IE 9]><em>Email</em><![endif]--></a></li>
  

  

  

  
  <li><a href="https://github.com/NodeBE4/oped2" class="icon-13 github" title="GitHub"><svg viewBox="0 0 512 512"><path d="M256 70.7c-102.6 0-185.9 83.2-185.9 185.9 0 82.1 53.3 151.8 127.1 176.4 9.3 1.7 12.3-4 12.3-8.9V389.4c-51.7 11.3-62.5-21.9-62.5-21.9 -8.4-21.5-20.6-27.2-20.6-27.2 -16.9-11.5 1.3-11.3 1.3-11.3 18.7 1.3 28.5 19.2 28.5 19.2 16.6 28.4 43.5 20.2 54.1 15.4 1.7-12 6.5-20.2 11.8-24.9 -41.3-4.7-84.7-20.6-84.7-91.9 0-20.3 7.3-36.9 19.2-49.9 -1.9-4.7-8.3-23.6 1.8-49.2 0 0 15.6-5 51.1 19.1 14.8-4.1 30.7-6.2 46.5-6.3 15.8 0.1 31.7 2.1 46.6 6.3 35.5-24 51.1-19.1 51.1-19.1 10.1 25.6 3.8 44.5 1.8 49.2 11.9 13 19.1 29.6 19.1 49.9 0 71.4-43.5 87.1-84.9 91.7 6.7 5.8 12.8 17.1 12.8 34.4 0 24.9 0 44.9 0 51 0 4.9 3 10.7 12.4 8.9 73.8-24.6 127-94.3 127-176.4C441.9 153.9 358.6 70.7 256 70.7z"/></svg><!--[if lt IE 9]><em>GitHub</em><![endif]--></a></li>
  

  

  

  

  

  
  <li><a href="/oped2/feed.xml" class="icon-21 rss" title="RSS"><svg viewBox="0 0 512 512"><path d="M201.8 347.2c0 20.3-16.5 36.8-36.8 36.8 -20.3 0-36.8-16.5-36.8-36.8s16.5-36.8 36.8-36.8C185.3 310.4 201.8 326.8 201.8 347.2zM128.2 204.7v54.5c68.5 0.7 124 56.3 124.7 124.7h54.5C306.7 285.3 226.9 205.4 128.2 204.7zM128.2 166.6c57.9 0.3 112.3 22.9 153.2 63.9 41 41 63.7 95.5 63.9 153.5h54.5c-0.3-149.9-121.7-271.4-271.6-271.9V166.6L128.2 166.6z"/></svg><!--[if lt IE 9]><em>RSS</em><![endif]--></a></li>
  

  

  

  

  

    
</ul>





<p><span style="color:blue">内容每小时更新一次.</span> Powered by <a href="https://github.com/AWEEKJ/kiko-now">Kiko Now</a> & <a href="https://github.com/gitalk/gitalk">Gitalk</a> & <a href="https://github.com/duty-machine/news">duty-machine</a>, 站务 <a href="https://be4.herokuapp.com">NodeBE4</a>（<span style="color:red">被墙</span>）</p>





        </footer>
      </div>
    </div>

    



  </body>
</html>
