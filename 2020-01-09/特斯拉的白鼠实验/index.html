<!DOCTYPE html>
<html>
  <head>
  <title>特斯拉的白鼠实验 – 觀點2 – 高頻版 git.io/JUJZT</title>

      <meta charset="utf-8" />
    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
    <meta http-equiv='X-UA-Compatible' content='IE=edge'>
    <meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>

    
    <meta name="description" content="
  
    
    
       特斯拉的白鼠实验 
    
  
  
    
    
    Tesla 汽车的 Autopilot 自动驾驶辅助系统可挽救数百万条生命，但在此之前，它可能会让一些人付出生命代价
       
      
        

        
      
      
        
          
            Featured in 
        Bloomberg Businessweek
        , Oct. 14, 2019.
            Photo Illustration by 731. Photograph: AP Photo
          
        
      
    
    在他生命的最后一天，班纳 (Jeremy Banner) 天还没亮就醒了，准备去上班。他驾驶红色的 Tesla Model 3，沿着美国佛罗里达州大沼泽地的边缘朝南行驶。沼泽和农田飞快地从身边掠过，化作一片模糊的绿色影子。
    班纳轻轻敲了一下操纵杆，车内响起轻柔的铃声。他激活了目前市场上最复杂、最具争议性的自动安全功能：Tesla 的 Autopilot 自动驾驶辅助系统。这是一种电脑系统，毋须司机的任何输入即可运行普通公路驾驶的所有功能。当电脑处于控制状态时，这辆汽车可加速、变换车道以及驶离出口，如果发现前方有障碍物，还可以自动煞车。
    Tesla 公司的目标是制造出全球第一辆自动驾驶汽车，从而主导全球汽车市场，它认为 Autopilot 是关键的第一步。顾客们都喜欢它。他们的 Autopilot 已经记录了超过 15 亿英哩的行程，把软件功能推向极限。尽管车主手册警告司机要密切监控汽车行驶状况，但这并没有阻止一些人在车上读书、打盹甚至弹琴。在大多数情况下，这辆车会把他们安全送到目的地。
    但是，在 3 月的那个早晨，班纳的车子未能发现他前面有一辆大货车正横穿公路。班纳也没有发现，他的注意力显然已经涣散了。他以 68 英哩的时速撞上了这辆大货车的侧面，他的汽车顶部像沙丁鱼罐头一样被㓥开。三个孩子的父亲、年仅 50 岁的班纳当场死亡。
    电脑错误和人为错误不同。Autopilot 有闪电般的反应能力，而且它的注意力永远不会减弱，但有时候仍无法发现行车路在线的危险。自 2015 年推出 Autopilot 以来，已知的五宗死亡事故中有四宗都是由这种疏忽造成的。今年 8 月，班纳的家人根据佛罗里达州《非正常死亡法案》(Wrongful Death Act) 起诉 Tesla，发起了产品责任索赔：Tesla 承诺提供一辆安全的汽车，却交付了一辆存有危险缺陷的汽车。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    但是，Autopilot 和历史上几乎所有其他消费产品都不一样，它让我们预视到即将到来的机器人时代会面临哪些令人不安的问题。Tesla 行政总裁马斯克 (Elon Musk) 表示，这项技术可以挽救生命，很多 Tesla 车主都能证明自己的汽车发现了危险，避免了碰撞。也许双方都是对的，  这些电脑系统杀死了一些原本可以存活的司机，但也挽救了更多的生命  。在未来几年中，社会 (尤其是监管机构和法院) 将不得不决定能否接受这样的结果。
    这个问题不再局限于学术范畴。当马斯克决定让更多的人使用 Autopilot 时，相当于在全球的高速公路上展开了一场规模浩大的实验。
    26 岁的软件工程师卡齐 (Omar Qazi) 开着他的黑色 Tesla Model 3，双手离开方向盘，由南向北行驶在洛杉矶的 405 号州际公路上，我就坐在副驾驶的位置上。我们正以大约 50 英哩的时速在公路上行驶，方向盘略微向左偏，从而使汽车在稍稍弯曲的车道上保持居中位置。「这应该是洛杉矶尖峰时段的交通状况，对吧？ 」卡齐说，「它看起来完美无瑕。」Tesla 拥有大批支持者，其中很多人是富裕的、技术迷的男性。卡齐差不多就是这种类型。他的 Twitter 发文充满对马斯克的崇拜之情。在我们 8 月会面之前，他通过电子邮件提前告知了马斯克，并鼓励他和我交谈。马斯克拒绝就本文接受采访，但他在当天回信给这位粉丝。他说：「你的 Twitter 真棒！ 」然后还加了一句警告：「请小心记者。他们会对你甜言蜜语，然后再给你当头一棒。」马斯克把回信抄送给了我。
    卡齐和我在 Tesla 洛杉矶办公室外的充电站碰面，马斯克旗下的太空公司 SpaceX 的一部火箭助推器耸立在附近。卡齐留着胡子，穿着蓝色 Nike 气垫鞋。他立刻向我展示了还处在试验阶段的智能召唤 (Smart Summon) 功能，当时只有一群经过筛选的 Tesla 测试员可以使用这项功能。(卡齐通过推特央求马斯克获得了使用权；这项功能 9 月已向一般用户推出。) 他按下手机上的一个按钮，他的车就从停放点开了出来。卡齐看着车子穿过停车场，向自己缓缓驶来。他笑道：「它现在还没什么用处。」
    但他非常喜欢炫耀这个花招，经常逗留在停车场，就为了等待观众，这一点已经众所周知了。智能召唤只是让人对马斯克所承诺的无人驾驶的未来留下惊鸿一瞥的印象，但是对于道路驾驶而言，Autopilot 现在已经很接近未来了。  Tesla 称，这项技术还不够可靠，人们还不能将注意力转移哪怕一秒钟的时间，所以要求他们把手放在方向盘上。由于美国的大多数州份仍在研究要如何对待无人驾驶汽车，这么做也是为了满足法律要求。对于各州的监管机构来说，Autopilot 只是一种先进的驾驶辅助系统——本质上就是一种增强版的巡航控制系统。Autopilot 还不能应对非快速道路上的路况，比如交通信号灯和停车标志。但是，在它上路的这四年间，已经逐渐承担了更为复杂的任务：平稳并线、避开插队的汽车以及从一条快速路切换到另一条。 
    卡齐说：「它还不能完美地自主驾驶，但是软件的发展速度很快，每隔几周就会更新一次，这辆车行驶起来变得更像是人工驾驶。这太惊人了。」几分钟之后，一辆银色轿车插入我们的车道，这辆 Tesla 平稳地煞车，让前车插了进来。「看到了吗？ 」他问道。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    在我和卡齐会面的那一天，洛杉矶就有一名非法赛车手死亡，他驾驶的万事得 (Mazda) 汽车撞上了一辆停着的货车；一个电单车司机在高乘载车道 (carpool lane，指专供乘载多人之汽车所行驶的车道) 撞上一辆抛锚的货车而身亡；一位骑单车的中学生被一辆肇事后逃逸的汽车拖行了 1500 英呎，身受重伤。
     实际上，开车是大多数成年人做过最危险的事情。去年，美国因车祸死亡的人数是 4 万人，全球是 140 万人。然而我们都对自己的驾驶技术充满了自信。1974 年，以节省能源为由，美国将快速道路限速为每小时 55 英哩。一项研究发现，在实施的第一年，就让快速道路车祸死亡人数至少减少了 3000 人。但人们喜欢开快车，后来国会取消了这个限制。几年前，交通事故开始攀升，专家将这一现象归咎于智能手机带来的干扰。我们还是一边开车一边发消息。 
     无论电脑有什么缺陷，都不会醉酒、疲倦、生气，或在州际公路上行驶时不会想要查看 Instagram 的动态。无人驾驶技术承诺让我们保留以汽车为中心的生活方式，同时将人为错误导致的车祸减少 94%。从这个角度来看，自动驾驶汽车可能成为和青霉素 (penicillin) 以及天花疫苗 (smallpox vaccine) 同一级别的人类救星。 
     卡齐算了一下：他说有朝一日无人驾驶汽车将每天挽救 3000 条生命。按照他的逻辑，任何阻碍这个进程的人手上都沾满了鲜血。他说：「想像一下有人让这个软件推迟了一天面世，这真的会让很多人丧命。」 
    在班纳的致命车祸发生不到两个月，马斯克邀请了大约 100 位投资者和分析师来到 Tesla 位于加州帕罗奥图 (Palo Alto) 的总部，在一个巨大的会议厅里迎接他们。在南非出生和长大的马斯克发迹于美国硅谷，然后开展了一系列大胆的项目：商用火箭、高速隧道、大脑植入物和电动汽车。他的许多仰慕者认为他是一位改变世界的远见卓识之士；他的敌人认为他是虚伪的骗子。在那个 4 月的早晨，马斯克偶尔打断和他同台的 Tesla 科学家发言，自由思考着生活是否也许就是一种电脑仿真状态。
    Tesla 股价已下跌了好几个月。  尽管推出了最畅销的电动汽车 Model 3，公司仍然没有实现盈利，马斯克很快将被迫向投资者募集更多资金。在持续 2.5 小时的展示过程中，马斯克给投资者指出了新的关注点：制造出第一辆真正的无人驾驶汽车。他说，今天在路上行驶的汽车在几个月内就能在当地道路上使用 Autopilot。到 2020 年的某个时候，将不再需要人工监督，在闲置时可以作为无人驾驶的士车，给车主赚钱。马斯克举起双手说：「从经济角度看，购买 Tesla 以外的汽车都是不理智的行为。在三年之内，买别的汽车就会像拥有一匹马一样。」 
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    对于任何关注自动驾驶汽车行业的人来说，马斯克的时间表听起来似乎非常冒险。大约有 36 家公司正在开发这项技术，其中包括通用汽车 (General Motors)、戴姆勒 (Daimler) 和 Uber。许多观察家认为，实力最强的竞争者是从 Google 分拆出来的 Waymo，该公司在这个领域已经努力十多年。这些公司在近期暂不会开始向公众出售无人驾驶汽车。马斯克告诉投资者，Tesla 将超越所有这些企业，这要归功于已经在路上行驶的逾 50 万辆配备了 Autopilot 的 Tesla 汽车。尽管马斯克没有直接使用这些字眼，但他将 Autopilot 描述为一种粗略的产品草稿，它将逐渐变得更加可靠，直到实现真正的无人驾驶。
     硅谷推出智能手机应用程序 (App) 和视频游戏的方式常常是这样的：先向客户发布尚不完善的软件，然后冀望于在使用过程中找出错误、增加功能。但是，这些产品不会夺取人性命。Waymo、通用汽车和其他公司都有粗略的产品草稿，但它们仅仅被安装在几百辆测试车型当中，部署到全美少数几个经过精心挑选的社区，而且几乎总是在专业安全司机的监督下行驶。安全已经成为必要，尤其在去年 Uber 的一辆测试汽车撞死一位行人后。通用汽车的原型车以 35 英哩的最高时速在旧金山丘陵地形的街道上缓慢行驶。 
     另一方面，马斯克正尽快完成他的粗略产品草稿。这使得 Tesla 的工程师能够从客户手中收集海量数据，并利用这些消息根据真实世界的路况来完善 Autopilot。就连那些没有配备 Autopilot 的 Tesla 汽车也参与了这个过程：它们会默默比较人类司机与电脑所做的选择。每隔几周，Tesla 就会完成一个改进后的新版 Autopilot，并将它上传到汽车，这让卡齐和其他车迷感到高兴。 
    马斯克在帕罗奥图表示：「所有人都在不停地训练这个网络。」他把这种良性循环称为「车队学习」(fleet learning)，认为它很像 Google 搜索引擎通过每年接收 1.2 万亿条查找实现改进的方式。他宣布，有朝一日 Autopilot 将变得完美，司机们将不再需要方向盘。 当摩根士丹利 (Morgan Stanley) 的一位分析师向马斯克询问 Autopilot 的安全记录时，他迅速把话题转移到人为驾驶的危险性和利用科技解决这个问题的潜力上。他拿人工操作的旧式电梯和汽车做比较。他说：「这些服务员有时候会感到疲倦，或者喝醉酒，或者出现其他状况，然后他们就会错误操作。所以现在已经没有电梯服务员了。」
     考虑到这是件生死攸关的事情，马斯克有时把无人驾驶汽车说成一场正义运动就不足为奇。他曾经表示，让 Autopilot 退出市场应该「受到道德谴责」。但是，他并不是唯一说这种话的人。第一位因为 Autopilot 而死亡的美国司机是来自俄亥俄州的海军退伍军人布朗 (Joshua Brown)。在他 2016 年发生车祸后，他的家人发表了一份声明，基本上支持 Tesla。他们在声明中写道：「变革总是伴随着风险。我们的儿子对未来的公路安全产生了如此积极的影响，这一点令我们全家感到安慰和自豪。」实际上，布朗已经成为马斯克事业的殉道者。 
    马斯克说，直到司机像电梯服务员一样退出历史舞台前，Autopilot 都是第二选择：它拥有人工驾驶的所有安全性，再加上一层额外的电脑辅助系统。但自动驾驶是一把双刃剑。  当我们把大部份责任交给电脑时，我们自己就会分心走神。我们无法跟踪电脑应该做什么。我们的驾驶技能会生疏。航空史上充斥着人类对飞机自动驾驶功能过度依赖所导致的各种错误。两名美国西北航空 (Northwest Airlines) 的飞机师曾经因为完全走神而飞过头，超过目的地明尼苏达州的明尼阿波利斯 (Minneapolis) 100 英哩。 
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    前海军战斗机飞行员、美国杜克大学普莱特工程学院 (Duke University’s Pratt School of Engineering) 教授卡明斯 (Missy Cummings) 希望 Autopilot 退出市场。她说：「注意力涣散是人类的天性。」Waymo 也开发了类似 Autopilot 的系统，但六年前就弃之不用了。该公司称，太多司机在开车时发短讯、化妆或睡觉。
    同时，电脑会在司机最意想不到的时候出问题，因为有些对它们来说最有挑战性的任务对人类而言不过是小菜一碟。任何有知觉的成年人都能辨别出良性道路特征 (比如高速公路、架空标识以及停在路肩上的汽车) 与危险路况 (比如一辆挡住行车道的大货车) 之间的区别。对于世界上某些最复杂的机械视觉软件而言，做到这一点却出奇地困难。
    Tesla 公司一直拒绝对 Autopilot 设限，因为尽管这会让它更安全，但却降低了方便程度。该公司允许驾车者将 Autopilot 的巡航速度设置在当地限速以上，并允许他们在汽车能检测到车道标记的任何地方打开 Autopilot，尽管用户手册称，该系统的使用应该仅限于设置了进入限制的快速道路。
    对于那些试探过这辆车极限的人，马斯克本人会对他们表示鼓励。去年 12 月，当他在《60 分钟》(60 Minutes) 节目上向斯塔尔 (Lesley Stahl) 展示一辆 Model 3 汽车时，他打开 Autopilot，双手离开方向盘，完全违背了手册的警告。然后到了 5 月份，当一则在自动驾驶状态下拍摄的色情视频在网上疯传后，马斯克开玩笑地回应：「事实证明 Autopilot 的使用方法比我们想像的更多。」考虑到 Autopilot 现在记录的总里程数已经超过 15 亿英哩，确定它的安全记录应该很容易。马斯克宣称，使用 Autopilot 的安全系数大约是不使用的两倍，但是到目前为止他还没有公布可以证明这一论断的数据，他也没有向第三方研究人员证明这一点。Tesla 会公布每个季度 Autopilot 的事故率数据，但由于没有进一步说明这些事故是在什么状况下发生的，安全专家认为这些数据毫无用处。保险行业关于 Tesla 事故索赔数据的一项研究基本上也没有定论。
     在 2016 年的布朗撞车事故后，美国国家公路交通安全管理局 (NHTSA) 对 Autopilot 进行调查，没有发现回收的理由。它做出这项结论的部份依据是有一项调查发现，安装了 Autopilot 的 Tesla 汽车发生撞车事故的机率比没有安装的低 40%。但是，这项发现是创建在一系列可疑计算的基础上。虽然 Tesla 上交了 4.4 万辆汽车的里程记录和碰撞数据，但除了其中的 5700 辆汽车之外，其余车辆的关键数据不是弄丢，就是自相矛盾。在这 5700 辆汽车当中，安装了 Autopilot 的 Tesla 的事故率实际上更高。直到美国马里兰州的独立统计顾问惠特菲尔德 (Randy Whitfield) 于今年指出这些数据，这个缺陷才为人所知。但 NHTSA 表示继续支持原先的发现。对 Autopilot 或其他完全自动驾驶技术进行评估所面临的问题之一是，目前还不清楚社会将会容忍什么样的安全水平。 
     机器人在获准上路前应该做到完美无瑕吗，还是只要比一般司机做得好就行？丰田汽车 (Toyota Motor) 自动驾驶研究部门负责人普拉特 (Gill Pratt) 在 2017 年的一次演讲中说：「对于机器缺陷引起的伤亡事故，人们的容忍度几乎是零。」  要达到人们想要的完美状态，需要持续多年的机器学习，还要在仿真状态和真实测试当中累积远超过目前水平的里程。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
     但是，自相矛盾的是，和较低的标准相比，这样的高标准可能导致更多的死亡事故。在 2017 年为兰德公司 (Rand) 所做的一项调查中，研究人员卡尔拉 (Nidhi Kalra) 和格罗夫 (David Groves) 对这项技术开发过程中的 500 种假设方案进行了评估。在大多数情况下，如果不接受安全性仅略高于人类驾驶的技术，而是等待几乎完美的无人驾驶汽车，则需要付出数以万计的生命作为代价。在国会就无人驾驶汽车政策作证的机器人专家卡尔拉说：「等待这项技术接近完美的人们应该意识到，这种等待并非没有代价。」 
    她论据的关键是对汽车学习方式的见解。我们习惯于将代码想像成人类程序员编写的一系列指令。大多数电脑就是这样工作的，但 Tesla 和其他无人驾驶汽车的开发人员用的不是这种方法。辨别出一辆单车然后预测它要往哪个方向行驶实在太复杂了，没有办法简单地归结为一系列指令。相反，程序员利用机器学习来训练他们的软件。他们可能向它展示几千张从不同角度、不同场景拍摄的不同单车照片。他们可能还会向它展示一些电单车的照片，让它了解这些车的区别。随着时间的推移，机器就会出现自己的规则，对自己的所见进行解释。
    这些机器拥有的经验越多，就会越聪明。卡尔拉认为，在自动驾驶汽车变得完美前一直让它们待在实验室里，这就是有问题。她说，如果人们真的想要最大程度地挽救生命，人们甚至可以在自动驾驶汽车比人工驾驶更危险的时候就让它们上路，以加快它们的学习速度。
     即使人们造出了一辆完美的无人驾驶汽车，人们又要如何得知其完美呢？确定这一点的唯一方法就是让它上路行驶。但是，由于致命事故在统计数据当中很罕见——在美国，每行驶 8600 万英哩大约会发生一宗——因此，必须进行的测试量将是令人难以想像的。在为兰德公司做的另一项研究中，卡尔拉估计，一辆自动驾驶汽车必须无故障地行驶 2.75 亿英哩，才能证明自己发生致命事故的机率不高于人工驾驶，这个里程数需要 100 辆测试车不停行驶 12 年以上才能完成。 
    考虑到所有一切，马斯克的计划听起来就不那么疯狂了：他打算双管齐下，一边改进自己的粗略产品草稿一边进行测试，利用顾客作为自愿试车员在实际道路上进行测试。  实际上，如果不让大量司机暴露在机器人带来的致命危险之下，就不可能提高自动驾驶的安全性。马斯克做出允许 Autopilot 超速并让它在未经批准的道路上行驶的决定也符合这种逻辑。每当司机为了避免事故而从电脑手中抢过控制权时，都是一个潜在的教导时刻——软件可以利用这个机会了解不应该做什么。这是一种经过计算的风险，联邦监管机构可能还没有准备好对这种风险进行评估。说到可能拯救生命但也可能带来致命副作用的产品，美国在这方面的测试已有先例：分阶段临床药物试验。  包括美国卡内基美隆大学 (Carnegie Mellon University) 的哲学教授伦敦 (Alex London) 在内的一些人士，呼吁汽车监管机构作出类似的尝试，允许新技术分阶段投放到公路上，同时密切监控它的安全记录。他说：「即使我的提议不是最好的，我也可以告诉你什么是最糟糕的提议，那就是直接听信系统设计者说的话，尤其是当他们试图把产品卖给你的时候。」
    在我和卡齐的最后一段行程中，我们驱车前往加州兰乔帕第斯 (Rancho Palos Verdes)，一路蜿蜒穿过起伏的棕色山丘和俯瞰太平洋的悬崖峭壁。这条路并不是有进入限制的快速道路，但卡齐再次违背用户手册，打开了 Autopilot。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    当公路延伸到一处陡峭悬崖的周围时，我们靠近了一位正在骑行的单车手。这辆 Tesla 正确判断出他是一位单车手，准备超过他。就在汽车快要和单车平行之前，卡齐踩了煞车，让这名单车手先骑到比较开阔的路段，然后再超过他。他说，他希望电脑也能这么做，但他不愿冒险去验证这一点。
    但是卡齐似乎已经接受了这样一个事实：随着 Tesla 在全球道路上的迅速普及，将会出现更多由 Autopilot 造成的死亡事故。在我们分开之前他告诉我：「最大的噩梦就在前方。通往目标的道路只有一条。那就是穿过地雷区。」
    
      
             
              
            
 
      
    
    
       
        
          
            
            
              
              
            
          
          
            
          
        
      
    
  
  
    
 Bloomberg 
    
  

" />
    <meta property="og:description" content="
  
    
    
       特斯拉的白鼠实验 
    
  
  
    
    
    Tesla 汽车的 Autopilot 自动驾驶辅助系统可挽救数百万条生命，但在此之前，它可能会让一些人付出生命代价
       
      
        

        
      
      
        
          
            Featured in 
        Bloomberg Businessweek
        , Oct. 14, 2019.
            Photo Illustration by 731. Photograph: AP Photo
          
        
      
    
    在他生命的最后一天，班纳 (Jeremy Banner) 天还没亮就醒了，准备去上班。他驾驶红色的 Tesla Model 3，沿着美国佛罗里达州大沼泽地的边缘朝南行驶。沼泽和农田飞快地从身边掠过，化作一片模糊的绿色影子。
    班纳轻轻敲了一下操纵杆，车内响起轻柔的铃声。他激活了目前市场上最复杂、最具争议性的自动安全功能：Tesla 的 Autopilot 自动驾驶辅助系统。这是一种电脑系统，毋须司机的任何输入即可运行普通公路驾驶的所有功能。当电脑处于控制状态时，这辆汽车可加速、变换车道以及驶离出口，如果发现前方有障碍物，还可以自动煞车。
    Tesla 公司的目标是制造出全球第一辆自动驾驶汽车，从而主导全球汽车市场，它认为 Autopilot 是关键的第一步。顾客们都喜欢它。他们的 Autopilot 已经记录了超过 15 亿英哩的行程，把软件功能推向极限。尽管车主手册警告司机要密切监控汽车行驶状况，但这并没有阻止一些人在车上读书、打盹甚至弹琴。在大多数情况下，这辆车会把他们安全送到目的地。
    但是，在 3 月的那个早晨，班纳的车子未能发现他前面有一辆大货车正横穿公路。班纳也没有发现，他的注意力显然已经涣散了。他以 68 英哩的时速撞上了这辆大货车的侧面，他的汽车顶部像沙丁鱼罐头一样被㓥开。三个孩子的父亲、年仅 50 岁的班纳当场死亡。
    电脑错误和人为错误不同。Autopilot 有闪电般的反应能力，而且它的注意力永远不会减弱，但有时候仍无法发现行车路在线的危险。自 2015 年推出 Autopilot 以来，已知的五宗死亡事故中有四宗都是由这种疏忽造成的。今年 8 月，班纳的家人根据佛罗里达州《非正常死亡法案》(Wrongful Death Act) 起诉 Tesla，发起了产品责任索赔：Tesla 承诺提供一辆安全的汽车，却交付了一辆存有危险缺陷的汽车。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    但是，Autopilot 和历史上几乎所有其他消费产品都不一样，它让我们预视到即将到来的机器人时代会面临哪些令人不安的问题。Tesla 行政总裁马斯克 (Elon Musk) 表示，这项技术可以挽救生命，很多 Tesla 车主都能证明自己的汽车发现了危险，避免了碰撞。也许双方都是对的，  这些电脑系统杀死了一些原本可以存活的司机，但也挽救了更多的生命  。在未来几年中，社会 (尤其是监管机构和法院) 将不得不决定能否接受这样的结果。
    这个问题不再局限于学术范畴。当马斯克决定让更多的人使用 Autopilot 时，相当于在全球的高速公路上展开了一场规模浩大的实验。
    26 岁的软件工程师卡齐 (Omar Qazi) 开着他的黑色 Tesla Model 3，双手离开方向盘，由南向北行驶在洛杉矶的 405 号州际公路上，我就坐在副驾驶的位置上。我们正以大约 50 英哩的时速在公路上行驶，方向盘略微向左偏，从而使汽车在稍稍弯曲的车道上保持居中位置。「这应该是洛杉矶尖峰时段的交通状况，对吧？ 」卡齐说，「它看起来完美无瑕。」Tesla 拥有大批支持者，其中很多人是富裕的、技术迷的男性。卡齐差不多就是这种类型。他的 Twitter 发文充满对马斯克的崇拜之情。在我们 8 月会面之前，他通过电子邮件提前告知了马斯克，并鼓励他和我交谈。马斯克拒绝就本文接受采访，但他在当天回信给这位粉丝。他说：「你的 Twitter 真棒！ 」然后还加了一句警告：「请小心记者。他们会对你甜言蜜语，然后再给你当头一棒。」马斯克把回信抄送给了我。
    卡齐和我在 Tesla 洛杉矶办公室外的充电站碰面，马斯克旗下的太空公司 SpaceX 的一部火箭助推器耸立在附近。卡齐留着胡子，穿着蓝色 Nike 气垫鞋。他立刻向我展示了还处在试验阶段的智能召唤 (Smart Summon) 功能，当时只有一群经过筛选的 Tesla 测试员可以使用这项功能。(卡齐通过推特央求马斯克获得了使用权；这项功能 9 月已向一般用户推出。) 他按下手机上的一个按钮，他的车就从停放点开了出来。卡齐看着车子穿过停车场，向自己缓缓驶来。他笑道：「它现在还没什么用处。」
    但他非常喜欢炫耀这个花招，经常逗留在停车场，就为了等待观众，这一点已经众所周知了。智能召唤只是让人对马斯克所承诺的无人驾驶的未来留下惊鸿一瞥的印象，但是对于道路驾驶而言，Autopilot 现在已经很接近未来了。  Tesla 称，这项技术还不够可靠，人们还不能将注意力转移哪怕一秒钟的时间，所以要求他们把手放在方向盘上。由于美国的大多数州份仍在研究要如何对待无人驾驶汽车，这么做也是为了满足法律要求。对于各州的监管机构来说，Autopilot 只是一种先进的驾驶辅助系统——本质上就是一种增强版的巡航控制系统。Autopilot 还不能应对非快速道路上的路况，比如交通信号灯和停车标志。但是，在它上路的这四年间，已经逐渐承担了更为复杂的任务：平稳并线、避开插队的汽车以及从一条快速路切换到另一条。 
    卡齐说：「它还不能完美地自主驾驶，但是软件的发展速度很快，每隔几周就会更新一次，这辆车行驶起来变得更像是人工驾驶。这太惊人了。」几分钟之后，一辆银色轿车插入我们的车道，这辆 Tesla 平稳地煞车，让前车插了进来。「看到了吗？ 」他问道。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    在我和卡齐会面的那一天，洛杉矶就有一名非法赛车手死亡，他驾驶的万事得 (Mazda) 汽车撞上了一辆停着的货车；一个电单车司机在高乘载车道 (carpool lane，指专供乘载多人之汽车所行驶的车道) 撞上一辆抛锚的货车而身亡；一位骑单车的中学生被一辆肇事后逃逸的汽车拖行了 1500 英呎，身受重伤。
     实际上，开车是大多数成年人做过最危险的事情。去年，美国因车祸死亡的人数是 4 万人，全球是 140 万人。然而我们都对自己的驾驶技术充满了自信。1974 年，以节省能源为由，美国将快速道路限速为每小时 55 英哩。一项研究发现，在实施的第一年，就让快速道路车祸死亡人数至少减少了 3000 人。但人们喜欢开快车，后来国会取消了这个限制。几年前，交通事故开始攀升，专家将这一现象归咎于智能手机带来的干扰。我们还是一边开车一边发消息。 
     无论电脑有什么缺陷，都不会醉酒、疲倦、生气，或在州际公路上行驶时不会想要查看 Instagram 的动态。无人驾驶技术承诺让我们保留以汽车为中心的生活方式，同时将人为错误导致的车祸减少 94%。从这个角度来看，自动驾驶汽车可能成为和青霉素 (penicillin) 以及天花疫苗 (smallpox vaccine) 同一级别的人类救星。 
     卡齐算了一下：他说有朝一日无人驾驶汽车将每天挽救 3000 条生命。按照他的逻辑，任何阻碍这个进程的人手上都沾满了鲜血。他说：「想像一下有人让这个软件推迟了一天面世，这真的会让很多人丧命。」 
    在班纳的致命车祸发生不到两个月，马斯克邀请了大约 100 位投资者和分析师来到 Tesla 位于加州帕罗奥图 (Palo Alto) 的总部，在一个巨大的会议厅里迎接他们。在南非出生和长大的马斯克发迹于美国硅谷，然后开展了一系列大胆的项目：商用火箭、高速隧道、大脑植入物和电动汽车。他的许多仰慕者认为他是一位改变世界的远见卓识之士；他的敌人认为他是虚伪的骗子。在那个 4 月的早晨，马斯克偶尔打断和他同台的 Tesla 科学家发言，自由思考着生活是否也许就是一种电脑仿真状态。
    Tesla 股价已下跌了好几个月。  尽管推出了最畅销的电动汽车 Model 3，公司仍然没有实现盈利，马斯克很快将被迫向投资者募集更多资金。在持续 2.5 小时的展示过程中，马斯克给投资者指出了新的关注点：制造出第一辆真正的无人驾驶汽车。他说，今天在路上行驶的汽车在几个月内就能在当地道路上使用 Autopilot。到 2020 年的某个时候，将不再需要人工监督，在闲置时可以作为无人驾驶的士车，给车主赚钱。马斯克举起双手说：「从经济角度看，购买 Tesla 以外的汽车都是不理智的行为。在三年之内，买别的汽车就会像拥有一匹马一样。」 
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    对于任何关注自动驾驶汽车行业的人来说，马斯克的时间表听起来似乎非常冒险。大约有 36 家公司正在开发这项技术，其中包括通用汽车 (General Motors)、戴姆勒 (Daimler) 和 Uber。许多观察家认为，实力最强的竞争者是从 Google 分拆出来的 Waymo，该公司在这个领域已经努力十多年。这些公司在近期暂不会开始向公众出售无人驾驶汽车。马斯克告诉投资者，Tesla 将超越所有这些企业，这要归功于已经在路上行驶的逾 50 万辆配备了 Autopilot 的 Tesla 汽车。尽管马斯克没有直接使用这些字眼，但他将 Autopilot 描述为一种粗略的产品草稿，它将逐渐变得更加可靠，直到实现真正的无人驾驶。
     硅谷推出智能手机应用程序 (App) 和视频游戏的方式常常是这样的：先向客户发布尚不完善的软件，然后冀望于在使用过程中找出错误、增加功能。但是，这些产品不会夺取人性命。Waymo、通用汽车和其他公司都有粗略的产品草稿，但它们仅仅被安装在几百辆测试车型当中，部署到全美少数几个经过精心挑选的社区，而且几乎总是在专业安全司机的监督下行驶。安全已经成为必要，尤其在去年 Uber 的一辆测试汽车撞死一位行人后。通用汽车的原型车以 35 英哩的最高时速在旧金山丘陵地形的街道上缓慢行驶。 
     另一方面，马斯克正尽快完成他的粗略产品草稿。这使得 Tesla 的工程师能够从客户手中收集海量数据，并利用这些消息根据真实世界的路况来完善 Autopilot。就连那些没有配备 Autopilot 的 Tesla 汽车也参与了这个过程：它们会默默比较人类司机与电脑所做的选择。每隔几周，Tesla 就会完成一个改进后的新版 Autopilot，并将它上传到汽车，这让卡齐和其他车迷感到高兴。 
    马斯克在帕罗奥图表示：「所有人都在不停地训练这个网络。」他把这种良性循环称为「车队学习」(fleet learning)，认为它很像 Google 搜索引擎通过每年接收 1.2 万亿条查找实现改进的方式。他宣布，有朝一日 Autopilot 将变得完美，司机们将不再需要方向盘。 当摩根士丹利 (Morgan Stanley) 的一位分析师向马斯克询问 Autopilot 的安全记录时，他迅速把话题转移到人为驾驶的危险性和利用科技解决这个问题的潜力上。他拿人工操作的旧式电梯和汽车做比较。他说：「这些服务员有时候会感到疲倦，或者喝醉酒，或者出现其他状况，然后他们就会错误操作。所以现在已经没有电梯服务员了。」
     考虑到这是件生死攸关的事情，马斯克有时把无人驾驶汽车说成一场正义运动就不足为奇。他曾经表示，让 Autopilot 退出市场应该「受到道德谴责」。但是，他并不是唯一说这种话的人。第一位因为 Autopilot 而死亡的美国司机是来自俄亥俄州的海军退伍军人布朗 (Joshua Brown)。在他 2016 年发生车祸后，他的家人发表了一份声明，基本上支持 Tesla。他们在声明中写道：「变革总是伴随着风险。我们的儿子对未来的公路安全产生了如此积极的影响，这一点令我们全家感到安慰和自豪。」实际上，布朗已经成为马斯克事业的殉道者。 
    马斯克说，直到司机像电梯服务员一样退出历史舞台前，Autopilot 都是第二选择：它拥有人工驾驶的所有安全性，再加上一层额外的电脑辅助系统。但自动驾驶是一把双刃剑。  当我们把大部份责任交给电脑时，我们自己就会分心走神。我们无法跟踪电脑应该做什么。我们的驾驶技能会生疏。航空史上充斥着人类对飞机自动驾驶功能过度依赖所导致的各种错误。两名美国西北航空 (Northwest Airlines) 的飞机师曾经因为完全走神而飞过头，超过目的地明尼苏达州的明尼阿波利斯 (Minneapolis) 100 英哩。 
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    前海军战斗机飞行员、美国杜克大学普莱特工程学院 (Duke University’s Pratt School of Engineering) 教授卡明斯 (Missy Cummings) 希望 Autopilot 退出市场。她说：「注意力涣散是人类的天性。」Waymo 也开发了类似 Autopilot 的系统，但六年前就弃之不用了。该公司称，太多司机在开车时发短讯、化妆或睡觉。
    同时，电脑会在司机最意想不到的时候出问题，因为有些对它们来说最有挑战性的任务对人类而言不过是小菜一碟。任何有知觉的成年人都能辨别出良性道路特征 (比如高速公路、架空标识以及停在路肩上的汽车) 与危险路况 (比如一辆挡住行车道的大货车) 之间的区别。对于世界上某些最复杂的机械视觉软件而言，做到这一点却出奇地困难。
    Tesla 公司一直拒绝对 Autopilot 设限，因为尽管这会让它更安全，但却降低了方便程度。该公司允许驾车者将 Autopilot 的巡航速度设置在当地限速以上，并允许他们在汽车能检测到车道标记的任何地方打开 Autopilot，尽管用户手册称，该系统的使用应该仅限于设置了进入限制的快速道路。
    对于那些试探过这辆车极限的人，马斯克本人会对他们表示鼓励。去年 12 月，当他在《60 分钟》(60 Minutes) 节目上向斯塔尔 (Lesley Stahl) 展示一辆 Model 3 汽车时，他打开 Autopilot，双手离开方向盘，完全违背了手册的警告。然后到了 5 月份，当一则在自动驾驶状态下拍摄的色情视频在网上疯传后，马斯克开玩笑地回应：「事实证明 Autopilot 的使用方法比我们想像的更多。」考虑到 Autopilot 现在记录的总里程数已经超过 15 亿英哩，确定它的安全记录应该很容易。马斯克宣称，使用 Autopilot 的安全系数大约是不使用的两倍，但是到目前为止他还没有公布可以证明这一论断的数据，他也没有向第三方研究人员证明这一点。Tesla 会公布每个季度 Autopilot 的事故率数据，但由于没有进一步说明这些事故是在什么状况下发生的，安全专家认为这些数据毫无用处。保险行业关于 Tesla 事故索赔数据的一项研究基本上也没有定论。
     在 2016 年的布朗撞车事故后，美国国家公路交通安全管理局 (NHTSA) 对 Autopilot 进行调查，没有发现回收的理由。它做出这项结论的部份依据是有一项调查发现，安装了 Autopilot 的 Tesla 汽车发生撞车事故的机率比没有安装的低 40%。但是，这项发现是创建在一系列可疑计算的基础上。虽然 Tesla 上交了 4.4 万辆汽车的里程记录和碰撞数据，但除了其中的 5700 辆汽车之外，其余车辆的关键数据不是弄丢，就是自相矛盾。在这 5700 辆汽车当中，安装了 Autopilot 的 Tesla 的事故率实际上更高。直到美国马里兰州的独立统计顾问惠特菲尔德 (Randy Whitfield) 于今年指出这些数据，这个缺陷才为人所知。但 NHTSA 表示继续支持原先的发现。对 Autopilot 或其他完全自动驾驶技术进行评估所面临的问题之一是，目前还不清楚社会将会容忍什么样的安全水平。 
     机器人在获准上路前应该做到完美无瑕吗，还是只要比一般司机做得好就行？丰田汽车 (Toyota Motor) 自动驾驶研究部门负责人普拉特 (Gill Pratt) 在 2017 年的一次演讲中说：「对于机器缺陷引起的伤亡事故，人们的容忍度几乎是零。」  要达到人们想要的完美状态，需要持续多年的机器学习，还要在仿真状态和真实测试当中累积远超过目前水平的里程。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
     但是，自相矛盾的是，和较低的标准相比，这样的高标准可能导致更多的死亡事故。在 2017 年为兰德公司 (Rand) 所做的一项调查中，研究人员卡尔拉 (Nidhi Kalra) 和格罗夫 (David Groves) 对这项技术开发过程中的 500 种假设方案进行了评估。在大多数情况下，如果不接受安全性仅略高于人类驾驶的技术，而是等待几乎完美的无人驾驶汽车，则需要付出数以万计的生命作为代价。在国会就无人驾驶汽车政策作证的机器人专家卡尔拉说：「等待这项技术接近完美的人们应该意识到，这种等待并非没有代价。」 
    她论据的关键是对汽车学习方式的见解。我们习惯于将代码想像成人类程序员编写的一系列指令。大多数电脑就是这样工作的，但 Tesla 和其他无人驾驶汽车的开发人员用的不是这种方法。辨别出一辆单车然后预测它要往哪个方向行驶实在太复杂了，没有办法简单地归结为一系列指令。相反，程序员利用机器学习来训练他们的软件。他们可能向它展示几千张从不同角度、不同场景拍摄的不同单车照片。他们可能还会向它展示一些电单车的照片，让它了解这些车的区别。随着时间的推移，机器就会出现自己的规则，对自己的所见进行解释。
    这些机器拥有的经验越多，就会越聪明。卡尔拉认为，在自动驾驶汽车变得完美前一直让它们待在实验室里，这就是有问题。她说，如果人们真的想要最大程度地挽救生命，人们甚至可以在自动驾驶汽车比人工驾驶更危险的时候就让它们上路，以加快它们的学习速度。
     即使人们造出了一辆完美的无人驾驶汽车，人们又要如何得知其完美呢？确定这一点的唯一方法就是让它上路行驶。但是，由于致命事故在统计数据当中很罕见——在美国，每行驶 8600 万英哩大约会发生一宗——因此，必须进行的测试量将是令人难以想像的。在为兰德公司做的另一项研究中，卡尔拉估计，一辆自动驾驶汽车必须无故障地行驶 2.75 亿英哩，才能证明自己发生致命事故的机率不高于人工驾驶，这个里程数需要 100 辆测试车不停行驶 12 年以上才能完成。 
    考虑到所有一切，马斯克的计划听起来就不那么疯狂了：他打算双管齐下，一边改进自己的粗略产品草稿一边进行测试，利用顾客作为自愿试车员在实际道路上进行测试。  实际上，如果不让大量司机暴露在机器人带来的致命危险之下，就不可能提高自动驾驶的安全性。马斯克做出允许 Autopilot 超速并让它在未经批准的道路上行驶的决定也符合这种逻辑。每当司机为了避免事故而从电脑手中抢过控制权时，都是一个潜在的教导时刻——软件可以利用这个机会了解不应该做什么。这是一种经过计算的风险，联邦监管机构可能还没有准备好对这种风险进行评估。说到可能拯救生命但也可能带来致命副作用的产品，美国在这方面的测试已有先例：分阶段临床药物试验。  包括美国卡内基美隆大学 (Carnegie Mellon University) 的哲学教授伦敦 (Alex London) 在内的一些人士，呼吁汽车监管机构作出类似的尝试，允许新技术分阶段投放到公路上，同时密切监控它的安全记录。他说：「即使我的提议不是最好的，我也可以告诉你什么是最糟糕的提议，那就是直接听信系统设计者说的话，尤其是当他们试图把产品卖给你的时候。」
    在我和卡齐的最后一段行程中，我们驱车前往加州兰乔帕第斯 (Rancho Palos Verdes)，一路蜿蜒穿过起伏的棕色山丘和俯瞰太平洋的悬崖峭壁。这条路并不是有进入限制的快速道路，但卡齐再次违背用户手册，打开了 Autopilot。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    当公路延伸到一处陡峭悬崖的周围时，我们靠近了一位正在骑行的单车手。这辆 Tesla 正确判断出他是一位单车手，准备超过他。就在汽车快要和单车平行之前，卡齐踩了煞车，让这名单车手先骑到比较开阔的路段，然后再超过他。他说，他希望电脑也能这么做，但他不愿冒险去验证这一点。
    但是卡齐似乎已经接受了这样一个事实：随着 Tesla 在全球道路上的迅速普及，将会出现更多由 Autopilot 造成的死亡事故。在我们分开之前他告诉我：「最大的噩梦就在前方。通往目标的道路只有一条。那就是穿过地雷区。」
    
      
             
              
            
 
      
    
    
       
        
          
            
            
              
              
            
          
          
            
          
        
      
    
  
  
    
 Bloomberg 
    
  

" />
    
    <meta name="author" content="觀點2" />

    
    <meta property="og:title" content="特斯拉的白鼠实验" />
    <meta property="twitter:title" content="特斯拉的白鼠实验" />
    

  <link rel="stylesheet" type="text/css" href="/oped2/style.css" />
  <link rel="alternate" type="application/rss+xml" title="觀點2 - 高頻版 git.io/JUJZT" href="/oped2/feed.xml" />

  <!-- Social Share Kit CSS -->
  <link rel="stylesheet" href="/oped2/assets/css/social-share-kit.css" type="text/css">
  <link rel="stylesheet" href="/oped2/assets/css/font-awesome.min.css" type="text/css">
  <link rel="stylesheet" href="/oped2/assets/css/bootstrap.min.css" type="text/css">
  <script type="text/javascript" src="/oped2/assets/js/jquery-3.5.1.js"></script>
  <script type="text/javascript" src="/oped2/assets/js/page.js"></script>

</head>

  <body>
    <div class="wrapper-masthead">
  <div class="container">
    <header class="masthead clearfix">
      

      <div class="site-info">
        <h1 class="site-name" style="display: inline-block;"><a href="/oped2/">觀點2</a></h1>
        <i class="site-description" style="font-size: 12px;">高頻版 git.io/JUJZT</i>
      </div>

      <nav>
        <span id="search-container" >
          <a href="/oped2/tools"><i class="fa fa-bookmark twitter" title="百宝箱"></i></a>
        <a><i class="fa fa-search" title="限前100結果"></i></a><input type="text" id="search-input" placeholder="標題 作者 來源 日期 (5685)"
          style="margin: 10px 0px 0px 0px; height: 30px;width: auto" title="本站最正確的打開方式">
        </span>
        
        
        <a href="/oped2/categories" style="color: Tomato;"><i class="fa fa-tags" title="分类"></i></a>
        
        
        
        <a href="https://be4.herokuapp.com/" style="color: #003366;"><i class="fa fa-comments" title="论坛"></i></a>
        
        
        
        <a href="/oped2/about"><i class="fa fa-info-circle" title="关于"></i></a>
        
        
        <a title="电脑热键：&larr;上一篇(页), &rarr;下一篇(页), ins同来源新一篇，del同来源旧一篇" onclick="toggle_visibility('help')"><i class="fa fa-question-circle"></i></a>
        <a id="fa-home" href="https://nodebe4.github.io" title="BE4服务列表" onclick="//toggle_visibility('site-list')"><i class="fa fa-home" aria-hidden="true"></i></a>
      </nav>

    </header>
    <div id="site-list" class="tags" style="display: block;text-align: right;border-bottom: 1px solid lightGray;"><noscript><span style="background-color: #e8e8e8;color: #d10000;font-size: 14px;">开启浏览器JavaScript以获取搜索功能和更好的浏览体验</span></noscript></div>
    <p id="help" style="font-size: 14px;display: none;text-align: right;"><span style="color:green;">电脑热键：&larr;上一篇(页), &rarr;下一篇(页), ins同来源新一篇, del同来源旧一篇</span>; <span style="color:orange">对应触屏FAB：上下右左</span>; 轉Markdown<a href="https://euangoddard.github.io/clipboard2markdown/"><i class="fa fa-file-text-o"></i></a></p>
  </div>
</div>

<script type="text/javascript" >
  function toggle_visibility(id){
    var help = document.getElementById(id)
    if (help.style.display=='none'){
      help.style.display='block';
    }else{
      help.style.display='none';
    }
  }

  const url = "https://nodebe4.github.io/sitelist.json"

  document.addEventListener("DOMContentLoaded", function(event){
    // var homebtn = document.getElementById("fa-home")
    // homebtn.removeAttribute("href")
    var content = document.getElementById("site-list");
    content.innerHTML = ''
    var ul = document.createElement("ul")
    ul.classList.add("label")
    content.appendChild(ul)
    var cnt = 0

    $.getJSON(url, function(allsites) {

      allsites.map(item =>{
        var li = document.createElement('li')
        li.classList.add("tag")
        li.id = 'site-' + cnt
        ul.appendChild(li)
        var a0 = document.createElement('a')
        li.appendChild(a0)
        a0.href = item.url[0]
        var span = document.createElement('span')
        a0.appendChild(span)
        span.innerText = item['name']
        // span.style.backgroundColor = item['background-color']
        // span.style.color='#E4CBC3'
        span.style.color = item['background-color']
        span.style['font-size'] = '14px'
        cnt += 1
        // test_alive(li.id, a0.href)
      })
    })
  })

function test_alive(id, url){
  var divstatus = document.getElementById(id)
  const base = 'https://textance.herokuapp.com/title/'
  var fullurl = base + url
  $.ajax({
      url: fullurl,
      complete: function(data) {
        if (data.responseText.includes('502')){
          // divstatus.style.color='#FBB7B7'
          // divstatus.style.color='gray'
          // divstatus.title = "服务器无响应"
          divstatus.parentNode.removeChild(divstatus)
        }else{
          // divstatus.style.color='#B6FAC8'
          divstatus.title = data.responseText
        }
      }
  });
  return divstatus
}
</script>



    <!-- Left & centered positioning -->

<div class="ssk-sticky ssk-right ssk-center ssk-sticky-hide-xs ssk-group ssk-round">
  
    <a href="https://be4news.pythonanywhere.com/archivenow/ia/https%3A%2F%2Fnei.st%2Fmedium%2Fbloomberg%2Fyou-gotta-smasha-fewcars-to-make-an-autonomous-vehicle" class="ssk ssk-link" title="存到互联网档案馆" target="_blank"></a>
    <a href="https://www.facebook.com/sharer.php?u=https://nei.st/medium/bloomberg/you-gotta-smasha-fewcars-to-make-an-autonomous-vehicle" class="ssk ssk-facebook"></a>
    <a href="https://twitter.com/intent/tweet?url=https://nei.st/medium/bloomberg/you-gotta-smasha-fewcars-to-make-an-autonomous-vehicle&text=特斯拉的白鼠实验&hashtags=觀點2" class="ssk ssk-twitter"></a>
    <a href="https://reddit.com/submit?url=https://nei.st/medium/bloomberg/you-gotta-smasha-fewcars-to-make-an-autonomous-vehicle&title=特斯拉的白鼠实验" class="ssk ssk-reddit"></a>
    <a href="https://www.linkedin.com/shareArticle?mini=true&url=https://nei.st/medium/bloomberg/you-gotta-smasha-fewcars-to-make-an-autonomous-vehicle&title=特斯拉的白鼠实验" class="ssk ssk-linkedin"></a>
    <a href="mailto:{email_address}?subject=特斯拉的白鼠实验&body=
  
    
    
       特斯拉的白鼠实验 
    
  
  
    
    
    Tesla 汽车的 Autopilot 自动驾驶辅助系统可挽救数百万条生命，但在此之前，它可能会让一些人付出生命代价
       
      
        

        
      
      
        
          
            Featured in 
        Bloomberg Businessweek
        , Oct. 14, 2019.
            Photo Illustration by 731. Photograph: AP Photo
          
        
      
    
    在他生命的最后一天，班纳 (Jeremy Banner) 天还没亮就醒了，准备去上班。他驾驶红色的 Tesla Model 3，沿着美国佛罗里达州大沼泽地的边缘朝南行驶。沼泽和农田飞快地从身边掠过，化作一片模糊的绿色影子。
    班纳轻轻敲了一下操纵杆，车内响起轻柔的铃声。他激活了目前市场上最复杂、最具争议性的自动安全功能：Tesla 的 Autopilot 自动驾驶辅助系统。这是一种电脑系统，毋须司机的任何输入即可运行普通公路驾驶的所有功能。当电脑处于控制状态时，这辆汽车可加速、变换车道以及驶离出口，如果发现前方有障碍物，还可以自动煞车。
    Tesla 公司的目标是制造出全球第一辆自动驾驶汽车，从而主导全球汽车市场，它认为 Autopilot 是关键的第一步。顾客们都喜欢它。他们的 Autopilot 已经记录了超过 15 亿英哩的行程，把软件功能推向极限。尽管车主手册警告司机要密切监控汽车行驶状况，但这并没有阻止一些人在车上读书、打盹甚至弹琴。在大多数情况下，这辆车会把他们安全送到目的地。
    但是，在 3 月的那个早晨，班纳的车子未能发现他前面有一辆大货车正横穿公路。班纳也没有发现，他的注意力显然已经涣散了。他以 68 英哩的时速撞上了这辆大货车的侧面，他的汽车顶部像沙丁鱼罐头一样被㓥开。三个孩子的父亲、年仅 50 岁的班纳当场死亡。
    电脑错误和人为错误不同。Autopilot 有闪电般的反应能力，而且它的注意力永远不会减弱，但有时候仍无法发现行车路在线的危险。自 2015 年推出 Autopilot 以来，已知的五宗死亡事故中有四宗都是由这种疏忽造成的。今年 8 月，班纳的家人根据佛罗里达州《非正常死亡法案》(Wrongful Death Act) 起诉 Tesla，发起了产品责任索赔：Tesla 承诺提供一辆安全的汽车，却交付了一辆存有危险缺陷的汽车。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    但是，Autopilot 和历史上几乎所有其他消费产品都不一样，它让我们预视到即将到来的机器人时代会面临哪些令人不安的问题。Tesla 行政总裁马斯克 (Elon Musk) 表示，这项技术可以挽救生命，很多 Tesla 车主都能证明自己的汽车发现了危险，避免了碰撞。也许双方都是对的，  这些电脑系统杀死了一些原本可以存活的司机，但也挽救了更多的生命  。在未来几年中，社会 (尤其是监管机构和法院) 将不得不决定能否接受这样的结果。
    这个问题不再局限于学术范畴。当马斯克决定让更多的人使用 Autopilot 时，相当于在全球的高速公路上展开了一场规模浩大的实验。
    26 岁的软件工程师卡齐 (Omar Qazi) 开着他的黑色 Tesla Model 3，双手离开方向盘，由南向北行驶在洛杉矶的 405 号州际公路上，我就坐在副驾驶的位置上。我们正以大约 50 英哩的时速在公路上行驶，方向盘略微向左偏，从而使汽车在稍稍弯曲的车道上保持居中位置。「这应该是洛杉矶尖峰时段的交通状况，对吧？ 」卡齐说，「它看起来完美无瑕。」Tesla 拥有大批支持者，其中很多人是富裕的、技术迷的男性。卡齐差不多就是这种类型。他的 Twitter 发文充满对马斯克的崇拜之情。在我们 8 月会面之前，他通过电子邮件提前告知了马斯克，并鼓励他和我交谈。马斯克拒绝就本文接受采访，但他在当天回信给这位粉丝。他说：「你的 Twitter 真棒！ 」然后还加了一句警告：「请小心记者。他们会对你甜言蜜语，然后再给你当头一棒。」马斯克把回信抄送给了我。
    卡齐和我在 Tesla 洛杉矶办公室外的充电站碰面，马斯克旗下的太空公司 SpaceX 的一部火箭助推器耸立在附近。卡齐留着胡子，穿着蓝色 Nike 气垫鞋。他立刻向我展示了还处在试验阶段的智能召唤 (Smart Summon) 功能，当时只有一群经过筛选的 Tesla 测试员可以使用这项功能。(卡齐通过推特央求马斯克获得了使用权；这项功能 9 月已向一般用户推出。) 他按下手机上的一个按钮，他的车就从停放点开了出来。卡齐看着车子穿过停车场，向自己缓缓驶来。他笑道：「它现在还没什么用处。」
    但他非常喜欢炫耀这个花招，经常逗留在停车场，就为了等待观众，这一点已经众所周知了。智能召唤只是让人对马斯克所承诺的无人驾驶的未来留下惊鸿一瞥的印象，但是对于道路驾驶而言，Autopilot 现在已经很接近未来了。  Tesla 称，这项技术还不够可靠，人们还不能将注意力转移哪怕一秒钟的时间，所以要求他们把手放在方向盘上。由于美国的大多数州份仍在研究要如何对待无人驾驶汽车，这么做也是为了满足法律要求。对于各州的监管机构来说，Autopilot 只是一种先进的驾驶辅助系统——本质上就是一种增强版的巡航控制系统。Autopilot 还不能应对非快速道路上的路况，比如交通信号灯和停车标志。但是，在它上路的这四年间，已经逐渐承担了更为复杂的任务：平稳并线、避开插队的汽车以及从一条快速路切换到另一条。 
    卡齐说：「它还不能完美地自主驾驶，但是软件的发展速度很快，每隔几周就会更新一次，这辆车行驶起来变得更像是人工驾驶。这太惊人了。」几分钟之后，一辆银色轿车插入我们的车道，这辆 Tesla 平稳地煞车，让前车插了进来。「看到了吗？ 」他问道。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    在我和卡齐会面的那一天，洛杉矶就有一名非法赛车手死亡，他驾驶的万事得 (Mazda) 汽车撞上了一辆停着的货车；一个电单车司机在高乘载车道 (carpool lane，指专供乘载多人之汽车所行驶的车道) 撞上一辆抛锚的货车而身亡；一位骑单车的中学生被一辆肇事后逃逸的汽车拖行了 1500 英呎，身受重伤。
     实际上，开车是大多数成年人做过最危险的事情。去年，美国因车祸死亡的人数是 4 万人，全球是 140 万人。然而我们都对自己的驾驶技术充满了自信。1974 年，以节省能源为由，美国将快速道路限速为每小时 55 英哩。一项研究发现，在实施的第一年，就让快速道路车祸死亡人数至少减少了 3000 人。但人们喜欢开快车，后来国会取消了这个限制。几年前，交通事故开始攀升，专家将这一现象归咎于智能手机带来的干扰。我们还是一边开车一边发消息。 
     无论电脑有什么缺陷，都不会醉酒、疲倦、生气，或在州际公路上行驶时不会想要查看 Instagram 的动态。无人驾驶技术承诺让我们保留以汽车为中心的生活方式，同时将人为错误导致的车祸减少 94%。从这个角度来看，自动驾驶汽车可能成为和青霉素 (penicillin) 以及天花疫苗 (smallpox vaccine) 同一级别的人类救星。 
     卡齐算了一下：他说有朝一日无人驾驶汽车将每天挽救 3000 条生命。按照他的逻辑，任何阻碍这个进程的人手上都沾满了鲜血。他说：「想像一下有人让这个软件推迟了一天面世，这真的会让很多人丧命。」 
    在班纳的致命车祸发生不到两个月，马斯克邀请了大约 100 位投资者和分析师来到 Tesla 位于加州帕罗奥图 (Palo Alto) 的总部，在一个巨大的会议厅里迎接他们。在南非出生和长大的马斯克发迹于美国硅谷，然后开展了一系列大胆的项目：商用火箭、高速隧道、大脑植入物和电动汽车。他的许多仰慕者认为他是一位改变世界的远见卓识之士；他的敌人认为他是虚伪的骗子。在那个 4 月的早晨，马斯克偶尔打断和他同台的 Tesla 科学家发言，自由思考着生活是否也许就是一种电脑仿真状态。
    Tesla 股价已下跌了好几个月。  尽管推出了最畅销的电动汽车 Model 3，公司仍然没有实现盈利，马斯克很快将被迫向投资者募集更多资金。在持续 2.5 小时的展示过程中，马斯克给投资者指出了新的关注点：制造出第一辆真正的无人驾驶汽车。他说，今天在路上行驶的汽车在几个月内就能在当地道路上使用 Autopilot。到 2020 年的某个时候，将不再需要人工监督，在闲置时可以作为无人驾驶的士车，给车主赚钱。马斯克举起双手说：「从经济角度看，购买 Tesla 以外的汽车都是不理智的行为。在三年之内，买别的汽车就会像拥有一匹马一样。」 
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    对于任何关注自动驾驶汽车行业的人来说，马斯克的时间表听起来似乎非常冒险。大约有 36 家公司正在开发这项技术，其中包括通用汽车 (General Motors)、戴姆勒 (Daimler) 和 Uber。许多观察家认为，实力最强的竞争者是从 Google 分拆出来的 Waymo，该公司在这个领域已经努力十多年。这些公司在近期暂不会开始向公众出售无人驾驶汽车。马斯克告诉投资者，Tesla 将超越所有这些企业，这要归功于已经在路上行驶的逾 50 万辆配备了 Autopilot 的 Tesla 汽车。尽管马斯克没有直接使用这些字眼，但他将 Autopilot 描述为一种粗略的产品草稿，它将逐渐变得更加可靠，直到实现真正的无人驾驶。
     硅谷推出智能手机应用程序 (App) 和视频游戏的方式常常是这样的：先向客户发布尚不完善的软件，然后冀望于在使用过程中找出错误、增加功能。但是，这些产品不会夺取人性命。Waymo、通用汽车和其他公司都有粗略的产品草稿，但它们仅仅被安装在几百辆测试车型当中，部署到全美少数几个经过精心挑选的社区，而且几乎总是在专业安全司机的监督下行驶。安全已经成为必要，尤其在去年 Uber 的一辆测试汽车撞死一位行人后。通用汽车的原型车以 35 英哩的最高时速在旧金山丘陵地形的街道上缓慢行驶。 
     另一方面，马斯克正尽快完成他的粗略产品草稿。这使得 Tesla 的工程师能够从客户手中收集海量数据，并利用这些消息根据真实世界的路况来完善 Autopilot。就连那些没有配备 Autopilot 的 Tesla 汽车也参与了这个过程：它们会默默比较人类司机与电脑所做的选择。每隔几周，Tesla 就会完成一个改进后的新版 Autopilot，并将它上传到汽车，这让卡齐和其他车迷感到高兴。 
    马斯克在帕罗奥图表示：「所有人都在不停地训练这个网络。」他把这种良性循环称为「车队学习」(fleet learning)，认为它很像 Google 搜索引擎通过每年接收 1.2 万亿条查找实现改进的方式。他宣布，有朝一日 Autopilot 将变得完美，司机们将不再需要方向盘。 当摩根士丹利 (Morgan Stanley) 的一位分析师向马斯克询问 Autopilot 的安全记录时，他迅速把话题转移到人为驾驶的危险性和利用科技解决这个问题的潜力上。他拿人工操作的旧式电梯和汽车做比较。他说：「这些服务员有时候会感到疲倦，或者喝醉酒，或者出现其他状况，然后他们就会错误操作。所以现在已经没有电梯服务员了。」
     考虑到这是件生死攸关的事情，马斯克有时把无人驾驶汽车说成一场正义运动就不足为奇。他曾经表示，让 Autopilot 退出市场应该「受到道德谴责」。但是，他并不是唯一说这种话的人。第一位因为 Autopilot 而死亡的美国司机是来自俄亥俄州的海军退伍军人布朗 (Joshua Brown)。在他 2016 年发生车祸后，他的家人发表了一份声明，基本上支持 Tesla。他们在声明中写道：「变革总是伴随着风险。我们的儿子对未来的公路安全产生了如此积极的影响，这一点令我们全家感到安慰和自豪。」实际上，布朗已经成为马斯克事业的殉道者。 
    马斯克说，直到司机像电梯服务员一样退出历史舞台前，Autopilot 都是第二选择：它拥有人工驾驶的所有安全性，再加上一层额外的电脑辅助系统。但自动驾驶是一把双刃剑。  当我们把大部份责任交给电脑时，我们自己就会分心走神。我们无法跟踪电脑应该做什么。我们的驾驶技能会生疏。航空史上充斥着人类对飞机自动驾驶功能过度依赖所导致的各种错误。两名美国西北航空 (Northwest Airlines) 的飞机师曾经因为完全走神而飞过头，超过目的地明尼苏达州的明尼阿波利斯 (Minneapolis) 100 英哩。 
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    前海军战斗机飞行员、美国杜克大学普莱特工程学院 (Duke University’s Pratt School of Engineering) 教授卡明斯 (Missy Cummings) 希望 Autopilot 退出市场。她说：「注意力涣散是人类的天性。」Waymo 也开发了类似 Autopilot 的系统，但六年前就弃之不用了。该公司称，太多司机在开车时发短讯、化妆或睡觉。
    同时，电脑会在司机最意想不到的时候出问题，因为有些对它们来说最有挑战性的任务对人类而言不过是小菜一碟。任何有知觉的成年人都能辨别出良性道路特征 (比如高速公路、架空标识以及停在路肩上的汽车) 与危险路况 (比如一辆挡住行车道的大货车) 之间的区别。对于世界上某些最复杂的机械视觉软件而言，做到这一点却出奇地困难。
    Tesla 公司一直拒绝对 Autopilot 设限，因为尽管这会让它更安全，但却降低了方便程度。该公司允许驾车者将 Autopilot 的巡航速度设置在当地限速以上，并允许他们在汽车能检测到车道标记的任何地方打开 Autopilot，尽管用户手册称，该系统的使用应该仅限于设置了进入限制的快速道路。
    对于那些试探过这辆车极限的人，马斯克本人会对他们表示鼓励。去年 12 月，当他在《60 分钟》(60 Minutes) 节目上向斯塔尔 (Lesley Stahl) 展示一辆 Model 3 汽车时，他打开 Autopilot，双手离开方向盘，完全违背了手册的警告。然后到了 5 月份，当一则在自动驾驶状态下拍摄的色情视频在网上疯传后，马斯克开玩笑地回应：「事实证明 Autopilot 的使用方法比我们想像的更多。」考虑到 Autopilot 现在记录的总里程数已经超过 15 亿英哩，确定它的安全记录应该很容易。马斯克宣称，使用 Autopilot 的安全系数大约是不使用的两倍，但是到目前为止他还没有公布可以证明这一论断的数据，他也没有向第三方研究人员证明这一点。Tesla 会公布每个季度 Autopilot 的事故率数据，但由于没有进一步说明这些事故是在什么状况下发生的，安全专家认为这些数据毫无用处。保险行业关于 Tesla 事故索赔数据的一项研究基本上也没有定论。
     在 2016 年的布朗撞车事故后，美国国家公路交通安全管理局 (NHTSA) 对 Autopilot 进行调查，没有发现回收的理由。它做出这项结论的部份依据是有一项调查发现，安装了 Autopilot 的 Tesla 汽车发生撞车事故的机率比没有安装的低 40%。但是，这项发现是创建在一系列可疑计算的基础上。虽然 Tesla 上交了 4.4 万辆汽车的里程记录和碰撞数据，但除了其中的 5700 辆汽车之外，其余车辆的关键数据不是弄丢，就是自相矛盾。在这 5700 辆汽车当中，安装了 Autopilot 的 Tesla 的事故率实际上更高。直到美国马里兰州的独立统计顾问惠特菲尔德 (Randy Whitfield) 于今年指出这些数据，这个缺陷才为人所知。但 NHTSA 表示继续支持原先的发现。对 Autopilot 或其他完全自动驾驶技术进行评估所面临的问题之一是，目前还不清楚社会将会容忍什么样的安全水平。 
     机器人在获准上路前应该做到完美无瑕吗，还是只要比一般司机做得好就行？丰田汽车 (Toyota Motor) 自动驾驶研究部门负责人普拉特 (Gill Pratt) 在 2017 年的一次演讲中说：「对于机器缺陷引起的伤亡事故，人们的容忍度几乎是零。」  要达到人们想要的完美状态，需要持续多年的机器学习，还要在仿真状态和真实测试当中累积远超过目前水平的里程。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
     但是，自相矛盾的是，和较低的标准相比，这样的高标准可能导致更多的死亡事故。在 2017 年为兰德公司 (Rand) 所做的一项调查中，研究人员卡尔拉 (Nidhi Kalra) 和格罗夫 (David Groves) 对这项技术开发过程中的 500 种假设方案进行了评估。在大多数情况下，如果不接受安全性仅略高于人类驾驶的技术，而是等待几乎完美的无人驾驶汽车，则需要付出数以万计的生命作为代价。在国会就无人驾驶汽车政策作证的机器人专家卡尔拉说：「等待这项技术接近完美的人们应该意识到，这种等待并非没有代价。」 
    她论据的关键是对汽车学习方式的见解。我们习惯于将代码想像成人类程序员编写的一系列指令。大多数电脑就是这样工作的，但 Tesla 和其他无人驾驶汽车的开发人员用的不是这种方法。辨别出一辆单车然后预测它要往哪个方向行驶实在太复杂了，没有办法简单地归结为一系列指令。相反，程序员利用机器学习来训练他们的软件。他们可能向它展示几千张从不同角度、不同场景拍摄的不同单车照片。他们可能还会向它展示一些电单车的照片，让它了解这些车的区别。随着时间的推移，机器就会出现自己的规则，对自己的所见进行解释。
    这些机器拥有的经验越多，就会越聪明。卡尔拉认为，在自动驾驶汽车变得完美前一直让它们待在实验室里，这就是有问题。她说，如果人们真的想要最大程度地挽救生命，人们甚至可以在自动驾驶汽车比人工驾驶更危险的时候就让它们上路，以加快它们的学习速度。
     即使人们造出了一辆完美的无人驾驶汽车，人们又要如何得知其完美呢？确定这一点的唯一方法就是让它上路行驶。但是，由于致命事故在统计数据当中很罕见——在美国，每行驶 8600 万英哩大约会发生一宗——因此，必须进行的测试量将是令人难以想像的。在为兰德公司做的另一项研究中，卡尔拉估计，一辆自动驾驶汽车必须无故障地行驶 2.75 亿英哩，才能证明自己发生致命事故的机率不高于人工驾驶，这个里程数需要 100 辆测试车不停行驶 12 年以上才能完成。 
    考虑到所有一切，马斯克的计划听起来就不那么疯狂了：他打算双管齐下，一边改进自己的粗略产品草稿一边进行测试，利用顾客作为自愿试车员在实际道路上进行测试。  实际上，如果不让大量司机暴露在机器人带来的致命危险之下，就不可能提高自动驾驶的安全性。马斯克做出允许 Autopilot 超速并让它在未经批准的道路上行驶的决定也符合这种逻辑。每当司机为了避免事故而从电脑手中抢过控制权时，都是一个潜在的教导时刻——软件可以利用这个机会了解不应该做什么。这是一种经过计算的风险，联邦监管机构可能还没有准备好对这种风险进行评估。说到可能拯救生命但也可能带来致命副作用的产品，美国在这方面的测试已有先例：分阶段临床药物试验。  包括美国卡内基美隆大学 (Carnegie Mellon University) 的哲学教授伦敦 (Alex London) 在内的一些人士，呼吁汽车监管机构作出类似的尝试，允许新技术分阶段投放到公路上，同时密切监控它的安全记录。他说：「即使我的提议不是最好的，我也可以告诉你什么是最糟糕的提议，那就是直接听信系统设计者说的话，尤其是当他们试图把产品卖给你的时候。」
    在我和卡齐的最后一段行程中，我们驱车前往加州兰乔帕第斯 (Rancho Palos Verdes)，一路蜿蜒穿过起伏的棕色山丘和俯瞰太平洋的悬崖峭壁。这条路并不是有进入限制的快速道路，但卡齐再次违背用户手册，打开了 Autopilot。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    当公路延伸到一处陡峭悬崖的周围时，我们靠近了一位正在骑行的单车手。这辆 Tesla 正确判断出他是一位单车手，准备超过他。就在汽车快要和单车平行之前，卡齐踩了煞车，让这名单车手先骑到比较开阔的路段，然后再超过他。他说，他希望电脑也能这么做，但他不愿冒险去验证这一点。
    但是卡齐似乎已经接受了这样一个事实：随着 Tesla 在全球道路上的迅速普及，将会出现更多由 Autopilot 造成的死亡事故。在我们分开之前他告诉我：「最大的噩梦就在前方。通往目标的道路只有一条。那就是穿过地雷区。」
    
      
             
              
            
 
      
    
    
       
        
          
            
            
              
              
            
          
          
            
          
        
      
    
  
  
    
 Bloomberg 
    
  

" class="ssk ssk-email"></a>
    <a href="http://pinterest.com/pin/create/link/?url=https://nei.st/medium/bloomberg/you-gotta-smasha-fewcars-to-make-an-autonomous-vehicle" class="ssk ssk-pinterest"></a>
    <a href="https://www.tumblr.com/widgets/share/tool?canonicalUrl=https://nei.st/medium/bloomberg/you-gotta-smasha-fewcars-to-make-an-autonomous-vehicle&title=特斯拉的白鼠实验&caption=
  
    
    
       特斯拉的白鼠实验 
    
  
  
    
    
    Tesla 汽车的 Autopilot 自动驾驶辅助系统可挽救数百万条生命，但在此之前，它可能会让一些人付出生命代价
       
      
        

        
      
      
        
          
            Featured in 
        Bloomberg Businessweek
        , Oct. 14, 2019.
            Photo Illustration by 731. Photograph: AP Photo
          
        
      
    
    在他生命的最后一天，班纳 (Jeremy Banner) 天还没亮就醒了，准备去上班。他驾驶红色的 Tesla Model 3，沿着美国佛罗里达州大沼泽地的边缘朝南行驶。沼泽和农田飞快地从身边掠过，化作一片模糊的绿色影子。
    班纳轻轻敲了一下操纵杆，车内响起轻柔的铃声。他激活了目前市场上最复杂、最具争议性的自动安全功能：Tesla 的 Autopilot 自动驾驶辅助系统。这是一种电脑系统，毋须司机的任何输入即可运行普通公路驾驶的所有功能。当电脑处于控制状态时，这辆汽车可加速、变换车道以及驶离出口，如果发现前方有障碍物，还可以自动煞车。
    Tesla 公司的目标是制造出全球第一辆自动驾驶汽车，从而主导全球汽车市场，它认为 Autopilot 是关键的第一步。顾客们都喜欢它。他们的 Autopilot 已经记录了超过 15 亿英哩的行程，把软件功能推向极限。尽管车主手册警告司机要密切监控汽车行驶状况，但这并没有阻止一些人在车上读书、打盹甚至弹琴。在大多数情况下，这辆车会把他们安全送到目的地。
    但是，在 3 月的那个早晨，班纳的车子未能发现他前面有一辆大货车正横穿公路。班纳也没有发现，他的注意力显然已经涣散了。他以 68 英哩的时速撞上了这辆大货车的侧面，他的汽车顶部像沙丁鱼罐头一样被㓥开。三个孩子的父亲、年仅 50 岁的班纳当场死亡。
    电脑错误和人为错误不同。Autopilot 有闪电般的反应能力，而且它的注意力永远不会减弱，但有时候仍无法发现行车路在线的危险。自 2015 年推出 Autopilot 以来，已知的五宗死亡事故中有四宗都是由这种疏忽造成的。今年 8 月，班纳的家人根据佛罗里达州《非正常死亡法案》(Wrongful Death Act) 起诉 Tesla，发起了产品责任索赔：Tesla 承诺提供一辆安全的汽车，却交付了一辆存有危险缺陷的汽车。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    但是，Autopilot 和历史上几乎所有其他消费产品都不一样，它让我们预视到即将到来的机器人时代会面临哪些令人不安的问题。Tesla 行政总裁马斯克 (Elon Musk) 表示，这项技术可以挽救生命，很多 Tesla 车主都能证明自己的汽车发现了危险，避免了碰撞。也许双方都是对的，  这些电脑系统杀死了一些原本可以存活的司机，但也挽救了更多的生命  。在未来几年中，社会 (尤其是监管机构和法院) 将不得不决定能否接受这样的结果。
    这个问题不再局限于学术范畴。当马斯克决定让更多的人使用 Autopilot 时，相当于在全球的高速公路上展开了一场规模浩大的实验。
    26 岁的软件工程师卡齐 (Omar Qazi) 开着他的黑色 Tesla Model 3，双手离开方向盘，由南向北行驶在洛杉矶的 405 号州际公路上，我就坐在副驾驶的位置上。我们正以大约 50 英哩的时速在公路上行驶，方向盘略微向左偏，从而使汽车在稍稍弯曲的车道上保持居中位置。「这应该是洛杉矶尖峰时段的交通状况，对吧？ 」卡齐说，「它看起来完美无瑕。」Tesla 拥有大批支持者，其中很多人是富裕的、技术迷的男性。卡齐差不多就是这种类型。他的 Twitter 发文充满对马斯克的崇拜之情。在我们 8 月会面之前，他通过电子邮件提前告知了马斯克，并鼓励他和我交谈。马斯克拒绝就本文接受采访，但他在当天回信给这位粉丝。他说：「你的 Twitter 真棒！ 」然后还加了一句警告：「请小心记者。他们会对你甜言蜜语，然后再给你当头一棒。」马斯克把回信抄送给了我。
    卡齐和我在 Tesla 洛杉矶办公室外的充电站碰面，马斯克旗下的太空公司 SpaceX 的一部火箭助推器耸立在附近。卡齐留着胡子，穿着蓝色 Nike 气垫鞋。他立刻向我展示了还处在试验阶段的智能召唤 (Smart Summon) 功能，当时只有一群经过筛选的 Tesla 测试员可以使用这项功能。(卡齐通过推特央求马斯克获得了使用权；这项功能 9 月已向一般用户推出。) 他按下手机上的一个按钮，他的车就从停放点开了出来。卡齐看着车子穿过停车场，向自己缓缓驶来。他笑道：「它现在还没什么用处。」
    但他非常喜欢炫耀这个花招，经常逗留在停车场，就为了等待观众，这一点已经众所周知了。智能召唤只是让人对马斯克所承诺的无人驾驶的未来留下惊鸿一瞥的印象，但是对于道路驾驶而言，Autopilot 现在已经很接近未来了。  Tesla 称，这项技术还不够可靠，人们还不能将注意力转移哪怕一秒钟的时间，所以要求他们把手放在方向盘上。由于美国的大多数州份仍在研究要如何对待无人驾驶汽车，这么做也是为了满足法律要求。对于各州的监管机构来说，Autopilot 只是一种先进的驾驶辅助系统——本质上就是一种增强版的巡航控制系统。Autopilot 还不能应对非快速道路上的路况，比如交通信号灯和停车标志。但是，在它上路的这四年间，已经逐渐承担了更为复杂的任务：平稳并线、避开插队的汽车以及从一条快速路切换到另一条。 
    卡齐说：「它还不能完美地自主驾驶，但是软件的发展速度很快，每隔几周就会更新一次，这辆车行驶起来变得更像是人工驾驶。这太惊人了。」几分钟之后，一辆银色轿车插入我们的车道，这辆 Tesla 平稳地煞车，让前车插了进来。「看到了吗？ 」他问道。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    在我和卡齐会面的那一天，洛杉矶就有一名非法赛车手死亡，他驾驶的万事得 (Mazda) 汽车撞上了一辆停着的货车；一个电单车司机在高乘载车道 (carpool lane，指专供乘载多人之汽车所行驶的车道) 撞上一辆抛锚的货车而身亡；一位骑单车的中学生被一辆肇事后逃逸的汽车拖行了 1500 英呎，身受重伤。
     实际上，开车是大多数成年人做过最危险的事情。去年，美国因车祸死亡的人数是 4 万人，全球是 140 万人。然而我们都对自己的驾驶技术充满了自信。1974 年，以节省能源为由，美国将快速道路限速为每小时 55 英哩。一项研究发现，在实施的第一年，就让快速道路车祸死亡人数至少减少了 3000 人。但人们喜欢开快车，后来国会取消了这个限制。几年前，交通事故开始攀升，专家将这一现象归咎于智能手机带来的干扰。我们还是一边开车一边发消息。 
     无论电脑有什么缺陷，都不会醉酒、疲倦、生气，或在州际公路上行驶时不会想要查看 Instagram 的动态。无人驾驶技术承诺让我们保留以汽车为中心的生活方式，同时将人为错误导致的车祸减少 94%。从这个角度来看，自动驾驶汽车可能成为和青霉素 (penicillin) 以及天花疫苗 (smallpox vaccine) 同一级别的人类救星。 
     卡齐算了一下：他说有朝一日无人驾驶汽车将每天挽救 3000 条生命。按照他的逻辑，任何阻碍这个进程的人手上都沾满了鲜血。他说：「想像一下有人让这个软件推迟了一天面世，这真的会让很多人丧命。」 
    在班纳的致命车祸发生不到两个月，马斯克邀请了大约 100 位投资者和分析师来到 Tesla 位于加州帕罗奥图 (Palo Alto) 的总部，在一个巨大的会议厅里迎接他们。在南非出生和长大的马斯克发迹于美国硅谷，然后开展了一系列大胆的项目：商用火箭、高速隧道、大脑植入物和电动汽车。他的许多仰慕者认为他是一位改变世界的远见卓识之士；他的敌人认为他是虚伪的骗子。在那个 4 月的早晨，马斯克偶尔打断和他同台的 Tesla 科学家发言，自由思考着生活是否也许就是一种电脑仿真状态。
    Tesla 股价已下跌了好几个月。  尽管推出了最畅销的电动汽车 Model 3，公司仍然没有实现盈利，马斯克很快将被迫向投资者募集更多资金。在持续 2.5 小时的展示过程中，马斯克给投资者指出了新的关注点：制造出第一辆真正的无人驾驶汽车。他说，今天在路上行驶的汽车在几个月内就能在当地道路上使用 Autopilot。到 2020 年的某个时候，将不再需要人工监督，在闲置时可以作为无人驾驶的士车，给车主赚钱。马斯克举起双手说：「从经济角度看，购买 Tesla 以外的汽车都是不理智的行为。在三年之内，买别的汽车就会像拥有一匹马一样。」 
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    对于任何关注自动驾驶汽车行业的人来说，马斯克的时间表听起来似乎非常冒险。大约有 36 家公司正在开发这项技术，其中包括通用汽车 (General Motors)、戴姆勒 (Daimler) 和 Uber。许多观察家认为，实力最强的竞争者是从 Google 分拆出来的 Waymo，该公司在这个领域已经努力十多年。这些公司在近期暂不会开始向公众出售无人驾驶汽车。马斯克告诉投资者，Tesla 将超越所有这些企业，这要归功于已经在路上行驶的逾 50 万辆配备了 Autopilot 的 Tesla 汽车。尽管马斯克没有直接使用这些字眼，但他将 Autopilot 描述为一种粗略的产品草稿，它将逐渐变得更加可靠，直到实现真正的无人驾驶。
     硅谷推出智能手机应用程序 (App) 和视频游戏的方式常常是这样的：先向客户发布尚不完善的软件，然后冀望于在使用过程中找出错误、增加功能。但是，这些产品不会夺取人性命。Waymo、通用汽车和其他公司都有粗略的产品草稿，但它们仅仅被安装在几百辆测试车型当中，部署到全美少数几个经过精心挑选的社区，而且几乎总是在专业安全司机的监督下行驶。安全已经成为必要，尤其在去年 Uber 的一辆测试汽车撞死一位行人后。通用汽车的原型车以 35 英哩的最高时速在旧金山丘陵地形的街道上缓慢行驶。 
     另一方面，马斯克正尽快完成他的粗略产品草稿。这使得 Tesla 的工程师能够从客户手中收集海量数据，并利用这些消息根据真实世界的路况来完善 Autopilot。就连那些没有配备 Autopilot 的 Tesla 汽车也参与了这个过程：它们会默默比较人类司机与电脑所做的选择。每隔几周，Tesla 就会完成一个改进后的新版 Autopilot，并将它上传到汽车，这让卡齐和其他车迷感到高兴。 
    马斯克在帕罗奥图表示：「所有人都在不停地训练这个网络。」他把这种良性循环称为「车队学习」(fleet learning)，认为它很像 Google 搜索引擎通过每年接收 1.2 万亿条查找实现改进的方式。他宣布，有朝一日 Autopilot 将变得完美，司机们将不再需要方向盘。 当摩根士丹利 (Morgan Stanley) 的一位分析师向马斯克询问 Autopilot 的安全记录时，他迅速把话题转移到人为驾驶的危险性和利用科技解决这个问题的潜力上。他拿人工操作的旧式电梯和汽车做比较。他说：「这些服务员有时候会感到疲倦，或者喝醉酒，或者出现其他状况，然后他们就会错误操作。所以现在已经没有电梯服务员了。」
     考虑到这是件生死攸关的事情，马斯克有时把无人驾驶汽车说成一场正义运动就不足为奇。他曾经表示，让 Autopilot 退出市场应该「受到道德谴责」。但是，他并不是唯一说这种话的人。第一位因为 Autopilot 而死亡的美国司机是来自俄亥俄州的海军退伍军人布朗 (Joshua Brown)。在他 2016 年发生车祸后，他的家人发表了一份声明，基本上支持 Tesla。他们在声明中写道：「变革总是伴随着风险。我们的儿子对未来的公路安全产生了如此积极的影响，这一点令我们全家感到安慰和自豪。」实际上，布朗已经成为马斯克事业的殉道者。 
    马斯克说，直到司机像电梯服务员一样退出历史舞台前，Autopilot 都是第二选择：它拥有人工驾驶的所有安全性，再加上一层额外的电脑辅助系统。但自动驾驶是一把双刃剑。  当我们把大部份责任交给电脑时，我们自己就会分心走神。我们无法跟踪电脑应该做什么。我们的驾驶技能会生疏。航空史上充斥着人类对飞机自动驾驶功能过度依赖所导致的各种错误。两名美国西北航空 (Northwest Airlines) 的飞机师曾经因为完全走神而飞过头，超过目的地明尼苏达州的明尼阿波利斯 (Minneapolis) 100 英哩。 
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    前海军战斗机飞行员、美国杜克大学普莱特工程学院 (Duke University’s Pratt School of Engineering) 教授卡明斯 (Missy Cummings) 希望 Autopilot 退出市场。她说：「注意力涣散是人类的天性。」Waymo 也开发了类似 Autopilot 的系统，但六年前就弃之不用了。该公司称，太多司机在开车时发短讯、化妆或睡觉。
    同时，电脑会在司机最意想不到的时候出问题，因为有些对它们来说最有挑战性的任务对人类而言不过是小菜一碟。任何有知觉的成年人都能辨别出良性道路特征 (比如高速公路、架空标识以及停在路肩上的汽车) 与危险路况 (比如一辆挡住行车道的大货车) 之间的区别。对于世界上某些最复杂的机械视觉软件而言，做到这一点却出奇地困难。
    Tesla 公司一直拒绝对 Autopilot 设限，因为尽管这会让它更安全，但却降低了方便程度。该公司允许驾车者将 Autopilot 的巡航速度设置在当地限速以上，并允许他们在汽车能检测到车道标记的任何地方打开 Autopilot，尽管用户手册称，该系统的使用应该仅限于设置了进入限制的快速道路。
    对于那些试探过这辆车极限的人，马斯克本人会对他们表示鼓励。去年 12 月，当他在《60 分钟》(60 Minutes) 节目上向斯塔尔 (Lesley Stahl) 展示一辆 Model 3 汽车时，他打开 Autopilot，双手离开方向盘，完全违背了手册的警告。然后到了 5 月份，当一则在自动驾驶状态下拍摄的色情视频在网上疯传后，马斯克开玩笑地回应：「事实证明 Autopilot 的使用方法比我们想像的更多。」考虑到 Autopilot 现在记录的总里程数已经超过 15 亿英哩，确定它的安全记录应该很容易。马斯克宣称，使用 Autopilot 的安全系数大约是不使用的两倍，但是到目前为止他还没有公布可以证明这一论断的数据，他也没有向第三方研究人员证明这一点。Tesla 会公布每个季度 Autopilot 的事故率数据，但由于没有进一步说明这些事故是在什么状况下发生的，安全专家认为这些数据毫无用处。保险行业关于 Tesla 事故索赔数据的一项研究基本上也没有定论。
     在 2016 年的布朗撞车事故后，美国国家公路交通安全管理局 (NHTSA) 对 Autopilot 进行调查，没有发现回收的理由。它做出这项结论的部份依据是有一项调查发现，安装了 Autopilot 的 Tesla 汽车发生撞车事故的机率比没有安装的低 40%。但是，这项发现是创建在一系列可疑计算的基础上。虽然 Tesla 上交了 4.4 万辆汽车的里程记录和碰撞数据，但除了其中的 5700 辆汽车之外，其余车辆的关键数据不是弄丢，就是自相矛盾。在这 5700 辆汽车当中，安装了 Autopilot 的 Tesla 的事故率实际上更高。直到美国马里兰州的独立统计顾问惠特菲尔德 (Randy Whitfield) 于今年指出这些数据，这个缺陷才为人所知。但 NHTSA 表示继续支持原先的发现。对 Autopilot 或其他完全自动驾驶技术进行评估所面临的问题之一是，目前还不清楚社会将会容忍什么样的安全水平。 
     机器人在获准上路前应该做到完美无瑕吗，还是只要比一般司机做得好就行？丰田汽车 (Toyota Motor) 自动驾驶研究部门负责人普拉特 (Gill Pratt) 在 2017 年的一次演讲中说：「对于机器缺陷引起的伤亡事故，人们的容忍度几乎是零。」  要达到人们想要的完美状态，需要持续多年的机器学习，还要在仿真状态和真实测试当中累积远超过目前水平的里程。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
     但是，自相矛盾的是，和较低的标准相比，这样的高标准可能导致更多的死亡事故。在 2017 年为兰德公司 (Rand) 所做的一项调查中，研究人员卡尔拉 (Nidhi Kalra) 和格罗夫 (David Groves) 对这项技术开发过程中的 500 种假设方案进行了评估。在大多数情况下，如果不接受安全性仅略高于人类驾驶的技术，而是等待几乎完美的无人驾驶汽车，则需要付出数以万计的生命作为代价。在国会就无人驾驶汽车政策作证的机器人专家卡尔拉说：「等待这项技术接近完美的人们应该意识到，这种等待并非没有代价。」 
    她论据的关键是对汽车学习方式的见解。我们习惯于将代码想像成人类程序员编写的一系列指令。大多数电脑就是这样工作的，但 Tesla 和其他无人驾驶汽车的开发人员用的不是这种方法。辨别出一辆单车然后预测它要往哪个方向行驶实在太复杂了，没有办法简单地归结为一系列指令。相反，程序员利用机器学习来训练他们的软件。他们可能向它展示几千张从不同角度、不同场景拍摄的不同单车照片。他们可能还会向它展示一些电单车的照片，让它了解这些车的区别。随着时间的推移，机器就会出现自己的规则，对自己的所见进行解释。
    这些机器拥有的经验越多，就会越聪明。卡尔拉认为，在自动驾驶汽车变得完美前一直让它们待在实验室里，这就是有问题。她说，如果人们真的想要最大程度地挽救生命，人们甚至可以在自动驾驶汽车比人工驾驶更危险的时候就让它们上路，以加快它们的学习速度。
     即使人们造出了一辆完美的无人驾驶汽车，人们又要如何得知其完美呢？确定这一点的唯一方法就是让它上路行驶。但是，由于致命事故在统计数据当中很罕见——在美国，每行驶 8600 万英哩大约会发生一宗——因此，必须进行的测试量将是令人难以想像的。在为兰德公司做的另一项研究中，卡尔拉估计，一辆自动驾驶汽车必须无故障地行驶 2.75 亿英哩，才能证明自己发生致命事故的机率不高于人工驾驶，这个里程数需要 100 辆测试车不停行驶 12 年以上才能完成。 
    考虑到所有一切，马斯克的计划听起来就不那么疯狂了：他打算双管齐下，一边改进自己的粗略产品草稿一边进行测试，利用顾客作为自愿试车员在实际道路上进行测试。  实际上，如果不让大量司机暴露在机器人带来的致命危险之下，就不可能提高自动驾驶的安全性。马斯克做出允许 Autopilot 超速并让它在未经批准的道路上行驶的决定也符合这种逻辑。每当司机为了避免事故而从电脑手中抢过控制权时，都是一个潜在的教导时刻——软件可以利用这个机会了解不应该做什么。这是一种经过计算的风险，联邦监管机构可能还没有准备好对这种风险进行评估。说到可能拯救生命但也可能带来致命副作用的产品，美国在这方面的测试已有先例：分阶段临床药物试验。  包括美国卡内基美隆大学 (Carnegie Mellon University) 的哲学教授伦敦 (Alex London) 在内的一些人士，呼吁汽车监管机构作出类似的尝试，允许新技术分阶段投放到公路上，同时密切监控它的安全记录。他说：「即使我的提议不是最好的，我也可以告诉你什么是最糟糕的提议，那就是直接听信系统设计者说的话，尤其是当他们试图把产品卖给你的时候。」
    在我和卡齐的最后一段行程中，我们驱车前往加州兰乔帕第斯 (Rancho Palos Verdes)，一路蜿蜒穿过起伏的棕色山丘和俯瞰太平洋的悬崖峭壁。这条路并不是有进入限制的快速道路，但卡齐再次违背用户手册，打开了 Autopilot。
    
      
        
          
            
            
              
              
            
          
          
            
          
        
      
    
    当公路延伸到一处陡峭悬崖的周围时，我们靠近了一位正在骑行的单车手。这辆 Tesla 正确判断出他是一位单车手，准备超过他。就在汽车快要和单车平行之前，卡齐踩了煞车，让这名单车手先骑到比较开阔的路段，然后再超过他。他说，他希望电脑也能这么做，但他不愿冒险去验证这一点。
    但是卡齐似乎已经接受了这样一个事实：随着 Tesla 在全球道路上的迅速普及，将会出现更多由 Autopilot 造成的死亡事故。在我们分开之前他告诉我：「最大的噩梦就在前方。通往目标的道路只有一条。那就是穿过地雷区。」
    
      
             
              
            
 
      
    
    
       
        
          
            
            
              
              
            
          
          
            
          
        
      
    
  
  
    
 Bloomberg 
    
  

&tags=觀點2" class="ssk ssk-tumblr"></a>
    <a href="https://buffer.com/add?text=特斯拉的白鼠实验&url=https://nei.st/medium/bloomberg/you-gotta-smasha-fewcars-to-make-an-autonomous-vehicle" class="ssk ssk-buffer"></a>
</div>


    <div id="main" role="main" class="container">
      
  <!-- Html Elements for Search -->
  <ul id="results-container" class="searched" style="color: #2980B9;"></ul>

  <script src="/oped2/assets/js/simple-jekyll-search.min.js"></script>

  <!-- Configuration -->
  <script>
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('results-container'),
    json: '/oped2/search.json',
    searchResultTemplate: '<li><a href="{url}" title="{desc}">{title}</a><time>{date}</time><a class="tag">{category}</a></li>',
    noResultsText: '没找到',
    limit: 100,
    fuzzy: false,
    exclude: ['Welcome']
  })

  </script>

      







  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
    


  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
  
  

  
    



<article class="post">
  <h1>特斯拉的白鼠实验</h1>
  <!-- Look the author details up from the site config. -->
  

  <div>
    <span class="date">
      2020-01-09
    </span>

    <!-- Output author details if some exist. -->
    
      
    


    <ul class="tag">
      <li>
        <a href="https://nodebe4.github.io/oped2/categories/#Nei.st">
          Nei.st
        </a>
      </li>
    </ul>

    
        <span>
            <!-- Personal Info. -->
            <a href="https://nei.st/medium/bloomberg/you-gotta-smasha-fewcars-to-make-an-autonomous-vehicle" style="font-size:14px;">原文</a>
        </span>
    

    <span style="float: right;" title="Nei.st的其它文章">
      <a style="font-size: 14px;" rel="nofollow" href="#sametag" class="tags">#Nei.st 的其它文章</a>
    </span>

  </div>

  <div class="entry">
    
    
    
    <article class="post-6755 post type-post status-publish format-standard hentry category-bloomberg" id="post-6755">
  <header class="page-header medium Archives">
    <div class="page-header__image"></div>
    <div class="page-header__content">
      <h1 class="page-title text-align-center" id="section"> 特斯拉的白鼠实验 </h1>
    </div>
  </header>
  <div class="entry-content aesop-entry-content" id="post-6755-content">
    <link as="font" crossorigin="anonymous" href="//cdn.jsdelivr.net/gh/0nd1jyU39XQ/_/glyph/font-face/0uIzqoZjSuJfvSBnvgXTcApMtcVhMcpr.woff" rel="preload" type="font/woff" />
    <link as="font" crossorigin="anonymous" href="//cdn.jsdelivr.net/gh/0nd1jyU39XQ/_/glyph/font-face/1sTnSLZWDKucPX6SAk.woff" rel="preload" type="font/woff" />
    <p class="blog-post__description">Tesla 汽车的 Autopilot 自动驾驶辅助系统可挽救数百万条生命，但在此之前，它可能会让一些人付出生命代价</p>
 <span id="more-6755"> </span>     <div class="container img component-image">
      <div class="aspectRatioPlaceholder" style="padding-bottom:133.33333333333331%;height: 0;">
        <div class="progressiveMedia" data-height="2000" data-width="1500">
<img alt="" class="progressiveMedia-image" data-src="https://cdn.jsdelivr.net/gh/0nd1jyU39XQ/_/img/1/e52bf525ly1g82bc7nkwmj215o1jkayl.jpg" src="https://cdn.jsdelivr.net/gh/0nd1jyU39XQ/_/img/1/e52bf525ly1g82bc7nkwmj215o1jkayl.jpg" />
        </div>
      </div>
      <div class="aesop-image-component">
        <figure class="aesop-image-component-image aesop-component-align-center aesop-image-component-caption-left">
          <figcaption class="aesop-image-component-caption">
            <p class="aesop-cap-description">Featured in <em>
        Bloomberg Businessweek
       </em> , Oct. 14, 2019.</p>
            <p class="aesop-cap-cred">Photo Illustration by 731. Photograph: AP Photo</p>
          </figcaption>
        </figure>
      </div>
    </div>
    <p>在他生命的最后一天，班纳 (Jeremy Banner) 天还没亮就醒了，准备去上班。他驾驶红色的 Tesla Model 3，沿着美国佛罗里达州大沼泽地的边缘朝南行驶。沼泽和农田飞快地从身边掠过，化作一片模糊的绿色影子。</p>
    <p>班纳轻轻敲了一下操纵杆，车内响起轻柔的铃声。他激活了目前市场上最复杂、最具争议性的自动安全功能：Tesla 的 Autopilot 自动驾驶辅助系统。这是一种电脑系统，毋须司机的任何输入即可运行普通公路驾驶的所有功能。当电脑处于控制状态时，这辆汽车可加速、变换车道以及驶离出口，如果发现前方有障碍物，还可以自动煞车。</p>
    <p>Tesla 公司的目标是制造出全球第一辆自动驾驶汽车，从而主导全球汽车市场，它认为 Autopilot 是关键的第一步。顾客们都喜欢它。他们的 Autopilot 已经记录了超过 15 亿英哩的行程，把软件功能推向极限。尽管车主手册警告司机要密切监控汽车行驶状况，但这并没有阻止一些人在车上读书、打盹甚至弹琴。在大多数情况下，这辆车会把他们安全送到目的地。</p>
    <p>但是，在 3 月的那个早晨，班纳的车子未能发现他前面有一辆大货车正横穿公路。班纳也没有发现，他的注意力显然已经涣散了。他以 68 英哩的时速撞上了这辆大货车的侧面，他的汽车顶部像沙丁鱼罐头一样被㓥开。三个孩子的父亲、年仅 50 岁的班纳当场死亡。</p>
    <p>电脑错误和人为错误不同。Autopilot 有闪电般的反应能力，而且它的注意力永远不会减弱，但有时候仍无法发现行车路在线的危险。自 2015 年推出 Autopilot 以来，已知的五宗死亡事故中有四宗都是由这种疏忽造成的。今年 8 月，班纳的家人根据佛罗里达州《非正常死亡法案》(Wrongful Death Act) 起诉 Tesla，发起了产品责任索赔：Tesla 承诺提供一辆安全的汽车，却交付了一辆存有危险缺陷的汽车。</p>
    <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
      <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
    <p>但是，Autopilot 和历史上几乎所有其他消费产品都不一样，它让我们预视到即将到来的机器人时代会面临哪些令人不安的问题。Tesla 行政总裁马斯克 (Elon Musk) 表示，这项技术可以挽救生命，很多 Tesla 车主都能证明自己的汽车发现了危险，避免了碰撞。也许双方都是对的， <span class="markup--p"> 这些电脑系统杀死了一些原本可以存活的司机，但也挽救了更多的生命 </span> 。在未来几年中，社会 (尤其是监管机构和法院) 将不得不决定能否接受这样的结果。</p>
    <p>这个问题不再局限于学术范畴。当马斯克决定让更多的人使用 Autopilot 时，相当于在全球的高速公路上展开了一场规模浩大的实验。</p>
    <p>26 岁的软件工程师卡齐 (Omar Qazi) 开着他的黑色 Tesla Model 3，双手离开方向盘，由南向北行驶在洛杉矶的 405 号州际公路上，我就坐在副驾驶的位置上。我们正以大约 50 英哩的时速在公路上行驶，方向盘略微向左偏，从而使汽车在稍稍弯曲的车道上保持居中位置。「这应该是洛杉矶尖峰时段的交通状况，对吧？ 」卡齐说，「它看起来完美无瑕。」Tesla 拥有大批支持者，其中很多人是富裕的、技术迷的男性。卡齐差不多就是这种类型。他的 Twitter 发文充满对马斯克的崇拜之情。在我们 8 月会面之前，他通过电子邮件提前告知了马斯克，并鼓励他和我交谈。马斯克拒绝就本文接受采访，但他在当天回信给这位粉丝。他说：「你的 Twitter 真棒！ 」然后还加了一句警告：「请小心记者。他们会对你甜言蜜语，然后再给你当头一棒。」马斯克把回信抄送给了我。</p>
    <p>卡齐和我在 Tesla 洛杉矶办公室外的充电站碰面，马斯克旗下的太空公司 SpaceX 的一部火箭助推器耸立在附近。卡齐留着胡子，穿着蓝色 Nike 气垫鞋。他立刻向我展示了还处在试验阶段的智能召唤 (Smart Summon) 功能，当时只有一群经过筛选的 Tesla 测试员可以使用这项功能。(卡齐通过推特央求马斯克获得了使用权；这项功能 9 月已向一般用户推出。) 他按下手机上的一个按钮，他的车就从停放点开了出来。卡齐看着车子穿过停车场，向自己缓缓驶来。他笑道：「它现在还没什么用处。」</p>
    <p>但他非常喜欢炫耀这个花招，经常逗留在停车场，就为了等待观众，这一点已经众所周知了。智能召唤只是让人对马斯克所承诺的无人驾驶的未来留下惊鸿一瞥的印象，但是对于道路驾驶而言，Autopilot 现在已经很接近未来了。 <span class="markup--p"> Tesla 称，这项技术还不够可靠，人们还不能将注意力转移哪怕一秒钟的时间，所以要求他们把手放在方向盘上。由于美国的大多数州份仍在研究要如何对待无人驾驶汽车，这么做也是为了满足法律要求。对于各州的监管机构来说，Autopilot 只是一种先进的驾驶辅助系统——本质上就是一种增强版的巡航控制系统。Autopilot 还不能应对非快速道路上的路况，比如交通信号灯和停车标志。但是，在它上路的这四年间，已经逐渐承担了更为复杂的任务：平稳并线、避开插队的汽车以及从一条快速路切换到另一条。 </span></p>
    <p>卡齐说：「它还不能完美地自主驾驶，但是软件的发展速度很快，每隔几周就会更新一次，这辆车行驶起来变得更像是人工驾驶。这太惊人了。」几分钟之后，一辆银色轿车插入我们的车道，这辆 Tesla 平稳地煞车，让前车插了进来。「看到了吗？ 」他问道。</p>
    <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
      <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
    <p>在我和卡齐会面的那一天，洛杉矶就有一名非法赛车手死亡，他驾驶的万事得 (Mazda) 汽车撞上了一辆停着的货车；一个电单车司机在高乘载车道 (carpool lane，指专供乘载多人之汽车所行驶的车道) 撞上一辆抛锚的货车而身亡；一位骑单车的中学生被一辆肇事后逃逸的汽车拖行了 1500 英呎，身受重伤。</p>
    <p><span class="markup--p"> 实际上，开车是大多数成年人做过最危险的事情。去年，美国因车祸死亡的人数是 4 万人，全球是 140 万人。然而我们都对自己的驾驶技术充满了自信。1974 年，以节省能源为由，美国将快速道路限速为每小时 55 英哩。一项研究发现，在实施的第一年，就让快速道路车祸死亡人数至少减少了 3000 人。但人们喜欢开快车，后来国会取消了这个限制。几年前，交通事故开始攀升，专家将这一现象归咎于智能手机带来的干扰。我们还是一边开车一边发消息。 </span></p>
    <p><span class="markup--p"> 无论电脑有什么缺陷，都不会醉酒、疲倦、生气，或在州际公路上行驶时不会想要查看 Instagram 的动态。无人驾驶技术承诺让我们保留以汽车为中心的生活方式，同时将人为错误导致的车祸减少 94%。从这个角度来看，自动驾驶汽车可能成为和青霉素 (penicillin) 以及天花疫苗 (smallpox vaccine) 同一级别的人类救星。 </span></p>
    <p><span class="markup--p"> 卡齐算了一下：他说有朝一日无人驾驶汽车将每天挽救 3000 条生命。按照他的逻辑，任何阻碍这个进程的人手上都沾满了鲜血。他说：「想像一下有人让这个软件推迟了一天面世，这真的会让很多人丧命。」 </span></p>
    <p>在班纳的致命车祸发生不到两个月，马斯克邀请了大约 100 位投资者和分析师来到 Tesla 位于加州帕罗奥图 (Palo Alto) 的总部，在一个巨大的会议厅里迎接他们。在南非出生和长大的马斯克发迹于美国硅谷，然后开展了一系列大胆的项目：商用火箭、高速隧道、大脑植入物和电动汽车。他的许多仰慕者认为他是一位改变世界的远见卓识之士；他的敌人认为他是虚伪的骗子。在那个 4 月的早晨，马斯克偶尔打断和他同台的 Tesla 科学家发言，自由思考着生活是否也许就是一种电脑仿真状态。</p>
    <p>Tesla 股价已下跌了好几个月。 <span class="markup--p"> 尽管推出了最畅销的电动汽车 Model 3，公司仍然没有实现盈利，马斯克很快将被迫向投资者募集更多资金。在持续 2.5 小时的展示过程中，马斯克给投资者指出了新的关注点：制造出第一辆真正的无人驾驶汽车。他说，今天在路上行驶的汽车在几个月内就能在当地道路上使用 Autopilot。到 2020 年的某个时候，将不再需要人工监督，在闲置时可以作为无人驾驶的士车，给车主赚钱。马斯克举起双手说：「从经济角度看，购买 Tesla 以外的汽车都是不理智的行为。在三年之内，买别的汽车就会像拥有一匹马一样。」 </span></p>
    <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
      <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
    <p>对于任何关注自动驾驶汽车行业的人来说，马斯克的时间表听起来似乎非常冒险。大约有 36 家公司正在开发这项技术，其中包括通用汽车 (General Motors)、戴姆勒 (Daimler) 和 Uber。许多观察家认为，实力最强的竞争者是从 Google 分拆出来的 Waymo，该公司在这个领域已经努力十多年。这些公司在近期暂不会开始向公众出售无人驾驶汽车。马斯克告诉投资者，Tesla 将超越所有这些企业，这要归功于已经在路上行驶的逾 50 万辆配备了 Autopilot 的 Tesla 汽车。尽管马斯克没有直接使用这些字眼，但他将 Autopilot 描述为一种粗略的产品草稿，它将逐渐变得更加可靠，直到实现真正的无人驾驶。</p>
    <p><span class="markup--p"> 硅谷推出智能手机应用程序 (App) 和视频游戏的方式常常是这样的：先向客户发布尚不完善的软件，然后冀望于在使用过程中找出错误、增加功能。但是，这些产品不会夺取人性命。Waymo、通用汽车和其他公司都有粗略的产品草稿，但它们仅仅被安装在几百辆测试车型当中，部署到全美少数几个经过精心挑选的社区，而且几乎总是在专业安全司机的监督下行驶。安全已经成为必要，尤其在去年 Uber 的一辆测试汽车撞死一位行人后。通用汽车的原型车以 35 英哩的最高时速在旧金山丘陵地形的街道上缓慢行驶。 </span></p>
    <p><span class="markup--p"> 另一方面，马斯克正尽快完成他的粗略产品草稿。这使得 Tesla 的工程师能够从客户手中收集海量数据，并利用这些消息根据真实世界的路况来完善 Autopilot。就连那些没有配备 Autopilot 的 Tesla 汽车也参与了这个过程：它们会默默比较人类司机与电脑所做的选择。每隔几周，Tesla 就会完成一个改进后的新版 Autopilot，并将它上传到汽车，这让卡齐和其他车迷感到高兴。 </span></p>
    <p>马斯克在帕罗奥图表示：「所有人都在不停地训练这个网络。」他把这种良性循环称为「车队学习」(fleet learning)，认为它很像 Google 搜索引擎通过每年接收 1.2 万亿条查找实现改进的方式。他宣布，有朝一日 Autopilot 将变得完美，司机们将不再需要方向盘。 当摩根士丹利 (Morgan Stanley) 的一位分析师向马斯克询问 Autopilot 的安全记录时，他迅速把话题转移到人为驾驶的危险性和利用科技解决这个问题的潜力上。他拿人工操作的旧式电梯和汽车做比较。他说：「这些服务员有时候会感到疲倦，或者喝醉酒，或者出现其他状况，然后他们就会错误操作。所以现在已经没有电梯服务员了。」</p>
    <p><span class="markup--p"> 考虑到这是件生死攸关的事情，马斯克有时把无人驾驶汽车说成一场正义运动就不足为奇。他曾经表示，让 Autopilot 退出市场应该「受到道德谴责」。但是，他并不是唯一说这种话的人。第一位因为 Autopilot 而死亡的美国司机是来自俄亥俄州的海军退伍军人布朗 (Joshua Brown)。在他 2016 年发生车祸后，他的家人发表了一份声明，基本上支持 Tesla。他们在声明中写道：「变革总是伴随着风险。我们的儿子对未来的公路安全产生了如此积极的影响，这一点令我们全家感到安慰和自豪。」实际上，布朗已经成为马斯克事业的殉道者。 </span></p>
    <p>马斯克说，直到司机像电梯服务员一样退出历史舞台前，Autopilot 都是第二选择：它拥有人工驾驶的所有安全性，再加上一层额外的电脑辅助系统。但自动驾驶是一把双刃剑。 <span class="markup--p"> 当我们把大部份责任交给电脑时，我们自己就会分心走神。我们无法跟踪电脑应该做什么。我们的驾驶技能会生疏。航空史上充斥着人类对飞机自动驾驶功能过度依赖所导致的各种错误。两名美国西北航空 (Northwest Airlines) 的飞机师曾经因为完全走神而飞过头，超过目的地明尼苏达州的明尼阿波利斯 (Minneapolis) 100 英哩。 </span></p>
    <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
      <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
    <p>前海军战斗机飞行员、美国杜克大学普莱特工程学院 (Duke University’s Pratt School of Engineering) 教授卡明斯 (Missy Cummings) 希望 Autopilot 退出市场。她说：「注意力涣散是人类的天性。」Waymo 也开发了类似 Autopilot 的系统，但六年前就弃之不用了。该公司称，太多司机在开车时发短讯、化妆或睡觉。</p>
    <p>同时，电脑会在司机最意想不到的时候出问题，因为有些对它们来说最有挑战性的任务对人类而言不过是小菜一碟。任何有知觉的成年人都能辨别出良性道路特征 (比如高速公路、架空标识以及停在路肩上的汽车) 与危险路况 (比如一辆挡住行车道的大货车) 之间的区别。对于世界上某些最复杂的机械视觉软件而言，做到这一点却出奇地困难。</p>
    <p>Tesla 公司一直拒绝对 Autopilot 设限，因为尽管这会让它更安全，但却降低了方便程度。该公司允许驾车者将 Autopilot 的巡航速度设置在当地限速以上，并允许他们在汽车能检测到车道标记的任何地方打开 Autopilot，尽管用户手册称，该系统的使用应该仅限于设置了进入限制的快速道路。</p>
    <p>对于那些试探过这辆车极限的人，马斯克本人会对他们表示鼓励。去年 12 月，当他在《60 分钟》(60 Minutes) 节目上向斯塔尔 (Lesley Stahl) 展示一辆 Model 3 汽车时，他打开 Autopilot，双手离开方向盘，完全违背了手册的警告。然后到了 5 月份，当一则在自动驾驶状态下拍摄的色情视频在网上疯传后，马斯克开玩笑地回应：「事实证明 Autopilot 的使用方法比我们想像的更多。」考虑到 Autopilot 现在记录的总里程数已经超过 15 亿英哩，确定它的安全记录应该很容易。马斯克宣称，使用 Autopilot 的安全系数大约是不使用的两倍，但是到目前为止他还没有公布可以证明这一论断的数据，他也没有向第三方研究人员证明这一点。Tesla 会公布每个季度 Autopilot 的事故率数据，但由于没有进一步说明这些事故是在什么状况下发生的，安全专家认为这些数据毫无用处。保险行业关于 Tesla 事故索赔数据的一项研究基本上也没有定论。</p>
    <p><span class="markup--p"> 在 2016 年的布朗撞车事故后，美国国家公路交通安全管理局 (NHTSA) 对 Autopilot 进行调查，没有发现回收的理由。它做出这项结论的部份依据是有一项调查发现，安装了 Autopilot 的 Tesla 汽车发生撞车事故的机率比没有安装的低 40%。但是，这项发现是创建在一系列可疑计算的基础上。虽然 Tesla 上交了 4.4 万辆汽车的里程记录和碰撞数据，但除了其中的 5700 辆汽车之外，其余车辆的关键数据不是弄丢，就是自相矛盾。在这 5700 辆汽车当中，安装了 Autopilot 的 Tesla 的事故率实际上更高。直到美国马里兰州的独立统计顾问惠特菲尔德 (Randy Whitfield) 于今年指出这些数据，这个缺陷才为人所知。但 NHTSA 表示继续支持原先的发现。对 Autopilot 或其他完全自动驾驶技术进行评估所面临的问题之一是，目前还不清楚社会将会容忍什么样的安全水平。 </span></p>
    <p><span class="markup--p"> 机器人在获准上路前应该做到完美无瑕吗，还是只要比一般司机做得好就行？丰田汽车 (Toyota Motor) 自动驾驶研究部门负责人普拉特 (Gill Pratt) 在 2017 年的一次演讲中说：「对于机器缺陷引起的伤亡事故，人们的容忍度几乎是零。」 </span> 要达到人们想要的完美状态，需要持续多年的机器学习，还要在仿真状态和真实测试当中累积远超过目前水平的里程。</p>
    <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
      <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
    <p><span class="markup--p"> 但是，自相矛盾的是，和较低的标准相比，这样的高标准可能导致更多的死亡事故。在 2017 年为兰德公司 (Rand) 所做的一项调查中，研究人员卡尔拉 (Nidhi Kalra) 和格罗夫 (David Groves) 对这项技术开发过程中的 500 种假设方案进行了评估。在大多数情况下，如果不接受安全性仅略高于人类驾驶的技术，而是等待几乎完美的无人驾驶汽车，则需要付出数以万计的生命作为代价。在国会就无人驾驶汽车政策作证的机器人专家卡尔拉说：「等待这项技术接近完美的人们应该意识到，这种等待并非没有代价。」 </span></p>
    <p>她论据的关键是对汽车学习方式的见解。我们习惯于将代码想像成人类程序员编写的一系列指令。大多数电脑就是这样工作的，但 Tesla 和其他无人驾驶汽车的开发人员用的不是这种方法。辨别出一辆单车然后预测它要往哪个方向行驶实在太复杂了，没有办法简单地归结为一系列指令。相反，程序员利用机器学习来训练他们的软件。他们可能向它展示几千张从不同角度、不同场景拍摄的不同单车照片。他们可能还会向它展示一些电单车的照片，让它了解这些车的区别。随着时间的推移，机器就会出现自己的规则，对自己的所见进行解释。</p>
    <p>这些机器拥有的经验越多，就会越聪明。卡尔拉认为，在自动驾驶汽车变得完美前一直让它们待在实验室里，这就是有问题。她说，如果人们真的想要最大程度地挽救生命，人们甚至可以在自动驾驶汽车比人工驾驶更危险的时候就让它们上路，以加快它们的学习速度。</p>
    <p><span class="markup--p"> 即使人们造出了一辆完美的无人驾驶汽车，人们又要如何得知其完美呢？确定这一点的唯一方法就是让它上路行驶。但是，由于致命事故在统计数据当中很罕见——在美国，每行驶 8600 万英哩大约会发生一宗——因此，必须进行的测试量将是令人难以想像的。在为兰德公司做的另一项研究中，卡尔拉估计，一辆自动驾驶汽车必须无故障地行驶 2.75 亿英哩，才能证明自己发生致命事故的机率不高于人工驾驶，这个里程数需要 100 辆测试车不停行驶 12 年以上才能完成。 </span></p>
    <p>考虑到所有一切，马斯克的计划听起来就不那么疯狂了：他打算双管齐下，一边改进自己的粗略产品草稿一边进行测试，利用顾客作为自愿试车员在实际道路上进行测试。 <span class="markup--p"> 实际上，如果不让大量司机暴露在机器人带来的致命危险之下，就不可能提高自动驾驶的安全性。马斯克做出允许 Autopilot 超速并让它在未经批准的道路上行驶的决定也符合这种逻辑。每当司机为了避免事故而从电脑手中抢过控制权时，都是一个潜在的教导时刻——软件可以利用这个机会了解不应该做什么。这是一种经过计算的风险，联邦监管机构可能还没有准备好对这种风险进行评估。说到可能拯救生命但也可能带来致命副作用的产品，美国在这方面的测试已有先例：分阶段临床药物试验。 </span> 包括美国卡内基美隆大学 (Carnegie Mellon University) 的哲学教授伦敦 (Alex London) 在内的一些人士，呼吁汽车监管机构作出类似的尝试，允许新技术分阶段投放到公路上，同时密切监控它的安全记录。他说：「即使我的提议不是最好的，我也可以告诉你什么是最糟糕的提议，那就是直接听信系统设计者说的话，尤其是当他们试图把产品卖给你的时候。」</p>
    <p>在我和卡齐的最后一段行程中，我们驱车前往加州兰乔帕第斯 (Rancho Palos Verdes)，一路蜿蜒穿过起伏的棕色山丘和俯瞰太平洋的悬崖峭壁。这条路并不是有进入限制的快速道路，但卡齐再次违背用户手册，打开了 Autopilot。</p>
    <div class="code-block code-block-1" style="margin: 8px 0; clear: both;">
      <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
    <p>当公路延伸到一处陡峭悬崖的周围时，我们靠近了一位正在骑行的单车手。这辆 Tesla 正确判断出他是一位单车手，准备超过他。就在汽车快要和单车平行之前，卡齐踩了煞车，让这名单车手先骑到比较开阔的路段，然后再超过他。他说，他希望电脑也能这么做，但他不愿冒险去验证这一点。</p>
    <p>但是卡齐似乎已经接受了这样一个事实：随着 Tesla 在全球道路上的迅速普及，将会出现更多由 Autopilot 造成的死亡事故。在我们分开之前他告诉我：「最大的噩梦就在前方。通往目标的道路只有一条。那就是穿过地雷区。」</p>
    <div class="container qyoLgsBMfk2RyP6PZqEQUQ">
      <div class="TA9FsqtAclEQEnnC">
<a class="q9pBoz6iftkg" href="https://nei.st/medium/bloomberg-businessweek?source=https://www.bloomberg.com/news/features/2019-10-09/tesla-s-autopilot-could-save-the-lives-of-millions-but-it-will-kill-some-people-first">             <div class="ISq0AssRMiRdK46s31e1tA">
              <div class="VBC0sS11TRzyNj7ur4DqLQ"></div>
            </div>
 </a>
      </div>
    </div>
    <div class="code-block code-block-2" style="margin: 8px 0; clear: both;">
<br />       <div class="container ads_KbHEVhh8Rw">
        <div class="card card--blog post-sidebar">
          <div class="card-body">
            <div class="logo_ngcontent-kty-0"></div>
            <div class="iframe-blocker U6XAMK63Vh00WqvF2BacIQ">
              <div class="background-h60B"></div>
              <div class="WumZiPCS4MeMw4pxQ"></div>
            </div>
          </div>
          <div class="card-footer">
            <div class="card-footer-wrapper" layout="row bottom-left"></div>
          </div>
        </div>
      </div>
    </div>
  </div>
  <footer class="entry-footer">
    <div class="categories icon-link">
<a href="https://nei.st/category/medium/bloomberg" rel="category tag"> Bloomberg </a>
    </div>
  </footer>
</article>


  </div>

  <hr style="border-top:1px solid #28323C;"/>

<font size=2px>
  文章版权归原作者所有。
</font>

<div style="text-align:center"><img width="1px" src="https://i.imgur.com/RinUcXm.png" alt="二维码分享本站" style="text-align:center"/></div>

  <div id="sametag">
    <h4 style="display: inline-block;">#Nei.st 的其它文章</h4>
    <span>--<a href="https://nodebe4.github.io/oped2/2020-07-30/%E5%A6%82%E4%BD%95%E7%9C%8B%E5%BE%85%E4%B8%AD%E5%9B%BD%E6%B0%91%E4%BC%97%E5%AF%B9%E6%94%BF%E5%BA%9C%E7%9A%84%E6%BB%A1%E6%84%8F%E5%BA%A6%E9%AB%98/">最新</a>-</span>
    <span>-<a href="https://nodebe4.github.io/oped2/2019-07-18/%E5%8D%87%E8%81%8C%E7%9A%84%E8%AF%85%E5%92%92/">最早</a>--</span>
    
      <li>
        <time>2020-01-09</time>
        <a href="https://nodebe4.github.io/oped2/2020-01-09/%E5%8F%A4%E4%BB%A3%E4%B8%AD%E5%9B%BD%E7%9A%84-%E4%BC%9F%E5%93%A5/">
          古代中国的「伟哥」
        </a>
      </li>
    
    
      <li>
        <time>2020-01-09</time>
        <a href="https://nodebe4.github.io/oped2/2020-01-09/%E8%94%9A%E6%9D%A5-%E5%9B%9B%E7%99%BE%E4%BA%BF%E9%80%A0%E8%BD%A6%E8%AE%B0/">
          蔚来：四百亿造车记
        </a>
      </li>
    
    
      <li>
        <time>2020-01-09</time>
        <a href="https://nodebe4.github.io/oped2/2020-01-09/%E7%BA%A6%E4%B8%8D%E4%B8%8A%E7%9A%84%E7%96%AB%E8%8B%97-%E8%A2%AB%E4%BD%8E%E4%BC%B0%E7%9A%84%E5%A8%81%E8%83%81/">
          约不上的疫苗，被低估的威胁
        </a>
      </li>
    
    
      <li>
        <time>2020-01-09</time>
        <a href="https://nodebe4.github.io/oped2/2020-01-09/%E9%99%88%E5%AF%85%E6%81%AA%E5%AF%B9%E4%BB%8A%E6%97%A5%E5%8E%86%E5%8F%B2%E5%AD%A6%E7%9A%84%E6%84%8F%E4%B9%89/">
          陈寅恪对今日历史学的意义
        </a>
      </li>
    
  </div>


  <hr>
  <div class="pagination">
    
      <span class="prev" >
          <a href="https://nodebe4.github.io/oped2/2020-01-09/%E7%BA%A6%E4%B8%8D%E4%B8%8A%E7%9A%84%E7%96%AB%E8%8B%97-%E8%A2%AB%E4%BD%8E%E4%BC%B0%E7%9A%84%E5%A8%81%E8%83%81/">
            前一篇：约不上的疫苗，被低估的威胁
          </a>
      </span>
    
    
      <span class="next" >
          <a href="https://nodebe4.github.io/oped2/2020-01-09/%E8%94%9A%E6%9D%A5-%E5%9B%9B%E7%99%BE%E4%BA%BF%E9%80%A0%E8%BD%A6%E8%AE%B0/">
            後一篇：蔚来：四百亿造车记
          </a>
      </span>
    

    <script>
    /* post pagination keyboard shortcuts */
    document.body.onkeyup = function(e){
      if (e.keyCode == '37') { window.location = 'https://nodebe4.github.io/oped2/2020-01-09/%E7%BA%A6%E4%B8%8D%E4%B8%8A%E7%9A%84%E7%96%AB%E8%8B%97-%E8%A2%AB%E4%BD%8E%E4%BC%B0%E7%9A%84%E5%A8%81%E8%83%81/'; } // left arrow key
      if (e.keyCode == '39') { window.location = 'https://nodebe4.github.io/oped2/2020-01-09/%E8%94%9A%E6%9D%A5-%E5%9B%9B%E7%99%BE%E4%BA%BF%E9%80%A0%E8%BD%A6%E8%AE%B0/'; } // right arrow key
      if (e.keyCode == '45') { window.location = 'https://nodebe4.github.io/oped2/2020-01-09/%E8%94%9A%E6%9D%A5-%E5%9B%9B%E7%99%BE%E4%BA%BF%E9%80%A0%E8%BD%A6%E8%AE%B0/'; } // insert key
      if (e.keyCode == '46') { window.location = 'https://nodebe4.github.io/oped2/2020-01-09/%E7%BA%A6%E4%B8%8D%E4%B8%8A%E7%9A%84%E7%96%AB%E8%8B%97-%E8%A2%AB%E4%BD%8E%E4%BC%B0%E7%9A%84%E5%A8%81%E8%83%81/'; } // delete key
    };
    </script>
    <link rel="stylesheet" type="text/css" href="/oped2/assets/css/fab.css" />

<div class="fab-wrapper">
  <div class="fab-wheel">
    
    
    
    <a class="fab-action fab-action-1" title="上一篇(热键 &#8594;)" href="https://nodebe4.github.io/oped2/2020-01-09/%E7%BA%A6%E4%B8%8D%E4%B8%8A%E7%9A%84%E7%96%AB%E8%8B%97-%E8%A2%AB%E4%BD%8E%E4%BC%B0%E7%9A%84%E5%A8%81%E8%83%81/">
      <i>后</i>
    </a>
    
    
    <a class="fab-action fab-action-2" title="下一篇(热键 &#8592;)" href="https://nodebe4.github.io/oped2/2020-01-09/%E8%94%9A%E6%9D%A5-%E5%9B%9B%E7%99%BE%E4%BA%BF%E9%80%A0%E8%BD%A6%E8%AE%B0/">
      <i>前</i>
    </a>
    
    
    <a class="fab-action fab-action-3" title="<Nei.st>上一篇(热键 ins)" href="https://nodebe4.github.io/oped2/2020-01-09/%E8%94%9A%E6%9D%A5-%E5%9B%9B%E7%99%BE%E4%BA%BF%E9%80%A0%E8%BD%A6%E8%AE%B0/">
      <i>左</i>
    </a>
    
    
    <a class="fab-action fab-action-4" title="<Nei.st>下一篇(热键 del)" href="https://nodebe4.github.io/oped2/2020-01-09/%E7%BA%A6%E4%B8%8D%E4%B8%8A%E7%9A%84%E7%96%AB%E8%8B%97-%E8%A2%AB%E4%BD%8E%E4%BC%B0%E7%9A%84%E5%A8%81%E8%83%81/">
      <i>右</i>
    </a>
    
  </div>
</div>


  </div>


  

</article>

    </div>

    <div style="z-index:2;">
<script src="/oped2/assets/js/vanilla-back-to-top.min.js"></script>
<script>addBackToTop({
  diameter: 56,
  cornerOffset: 20, // px
  id: 'back-to-top',
  backgroundColor: '#ddd',
  textColor: 'red'
})</script>
</div>


    <div class="wrapper-footer" id="footer">
      <div class="container">
        <footer class="footer">
          <img width="200px" src="https://i.imgur.com/RinUcXm.png" alt="二维码分享本站"/>
<font size=2px>二维码分享本站</font>

<!-- Refer to https://codepen.io/ruandre/pen/howFi -->
<ul class="svg-icon">

  

  

  
  <li><a href="mailto:beauti4@protonmail.com" class="icon-8 email" title="Email"><svg viewBox="0 0 512 512"><path d="M101.3 141.6v228.9h0.3 308.4 0.8V141.6H101.3zM375.7 167.8l-119.7 91.5 -119.6-91.5H375.7zM127.6 194.1l64.1 49.1 -64.1 64.1V194.1zM127.8 344.2l84.9-84.9 43.2 33.1 43-32.9 84.7 84.7L127.8 344.2 127.8 344.2zM384.4 307.8l-64.4-64.4 64.4-49.3V307.8z"/></svg><!--[if lt IE 9]><em>Email</em><![endif]--></a></li>
  

  

  

  
  <li><a href="https://github.com/NodeBE4/oped2" class="icon-13 github" title="GitHub"><svg viewBox="0 0 512 512"><path d="M256 70.7c-102.6 0-185.9 83.2-185.9 185.9 0 82.1 53.3 151.8 127.1 176.4 9.3 1.7 12.3-4 12.3-8.9V389.4c-51.7 11.3-62.5-21.9-62.5-21.9 -8.4-21.5-20.6-27.2-20.6-27.2 -16.9-11.5 1.3-11.3 1.3-11.3 18.7 1.3 28.5 19.2 28.5 19.2 16.6 28.4 43.5 20.2 54.1 15.4 1.7-12 6.5-20.2 11.8-24.9 -41.3-4.7-84.7-20.6-84.7-91.9 0-20.3 7.3-36.9 19.2-49.9 -1.9-4.7-8.3-23.6 1.8-49.2 0 0 15.6-5 51.1 19.1 14.8-4.1 30.7-6.2 46.5-6.3 15.8 0.1 31.7 2.1 46.6 6.3 35.5-24 51.1-19.1 51.1-19.1 10.1 25.6 3.8 44.5 1.8 49.2 11.9 13 19.1 29.6 19.1 49.9 0 71.4-43.5 87.1-84.9 91.7 6.7 5.8 12.8 17.1 12.8 34.4 0 24.9 0 44.9 0 51 0 4.9 3 10.7 12.4 8.9 73.8-24.6 127-94.3 127-176.4C441.9 153.9 358.6 70.7 256 70.7z"/></svg><!--[if lt IE 9]><em>GitHub</em><![endif]--></a></li>
  

  

  

  

  

  
  <li><a href="/oped2/feed.xml" class="icon-21 rss" title="RSS"><svg viewBox="0 0 512 512"><path d="M201.8 347.2c0 20.3-16.5 36.8-36.8 36.8 -20.3 0-36.8-16.5-36.8-36.8s16.5-36.8 36.8-36.8C185.3 310.4 201.8 326.8 201.8 347.2zM128.2 204.7v54.5c68.5 0.7 124 56.3 124.7 124.7h54.5C306.7 285.3 226.9 205.4 128.2 204.7zM128.2 166.6c57.9 0.3 112.3 22.9 153.2 63.9 41 41 63.7 95.5 63.9 153.5h54.5c-0.3-149.9-121.7-271.4-271.6-271.9V166.6L128.2 166.6z"/></svg><!--[if lt IE 9]><em>RSS</em><![endif]--></a></li>
  

  

  

  

  

    
</ul>





<p><span style="color:blue">内容每小时更新一次.</span> Powered by <a href="https://github.com/AWEEKJ/kiko-now">Kiko Now</a> & <a href="https://github.com/gitalk/gitalk">Gitalk</a> & <a href="https://github.com/duty-machine/news">duty-machine</a>, 站务 <a href="https://be4.herokuapp.com">NodeBE4</a>（<span style="color:red">被墙</span>）</p>





        </footer>
      </div>
    </div>

    



  </body>
</html>
